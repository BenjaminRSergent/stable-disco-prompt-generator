{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74a04ba8-2de2-4eb6-8282-81f95e404705",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext tensorboard\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import clip\n",
    "\n",
    "import importlib\n",
    "\n",
    "import contextlib\n",
    "\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('../..'))\n",
    "sys.path.insert(0, os.path.abspath('../../..'))\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "from utils import get_default_path\n",
    "from utils import Stopwatch\n",
    "import time\n",
    "\n",
    "import datetime\n",
    "\n",
    "\n",
    "import ai.stabledisco as sd\n",
    "import ai.torchmodules as torchmodules\n",
    "import ai.torchmodules.data as torchdata\n",
    "import ai.torchmodules.utils as torchutils\n",
    "import ai.stabledisco.utils as sdutils\n",
    "import ai.stabledisco.data as sddata\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "from clip.clip import _tokenizer as clip_tokenizer\n",
    "import ai.stabledisco.decoderpipeline as decoderpipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72e9ddd9-3c9b-4836-8b78-472c24ee32fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def parse_loss(training_log_lines):\n",
    "    losses = []\n",
    "    learning_rates = []\n",
    "\n",
    "    for line in training_log_lines:\n",
    "        matches = re.findall(fr\"(?<=loss )\\d+\\.\\d+\", line)\n",
    "        for match in matches:\n",
    "            losses.append(float(match))\n",
    "            \n",
    "        matches = re.finditer(fr\"(?<=Learning rate: \\[)\\d+\\.\\d+(e-?\\d+)?(?=])\", line)\n",
    "        for match in matches:\n",
    "            learning_rates.append(float(match.group(0)))\n",
    "        \n",
    "    return losses, learning_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c944b4d3-f98c-4d31-b05c-64b587bde6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_log_lines = \"\"\"\n",
    "Starting training\n",
    "Starting epoch 0\n",
    "  200/1094375 batches | batch/sec  5.50 | rem mins  3315 | loss 2.21064 | ppl   9.1215\n",
    "Learning rate: [5.2269590353915435e-05]\n",
    "  400/1094375 batches | batch/sec  6.03 | rem mins  3025 | loss 2.20873 | ppl   9.1042\n",
    "Learning rate: [5.3050860699497475e-05]\n",
    "  600/1094375 batches | batch/sec  6.01 | rem mins  3031 | loss 2.20916 | ppl   9.1081\n",
    "Learning rate: [5.383213104507931e-05]\n",
    "  800/1094375 batches | batch/sec  6.04 | rem mins  3016 | loss 2.19019 | ppl   8.9369\n",
    "Learning rate: [5.4613401390661154e-05]\n",
    " 1000/1094375 batches | batch/sec  6.07 | rem mins  3000 | loss 2.10745 | ppl   8.2272\n",
    "Learning rate: [5.53946717362432e-05]\n",
    " 1200/1094375 batches | batch/sec  6.00 | rem mins  3036 | loss 2.18994 | ppl   8.9347\n",
    "Learning rate: [5.6175942081825036e-05]\n",
    " 1400/1094375 batches | batch/sec  6.03 | rem mins  3023 | loss 2.12183 | ppl   8.3464\n",
    "Learning rate: [5.695721242740688e-05]\n",
    " 1600/1094375 batches | batch/sec  6.09 | rem mins  2991 | loss 2.18095 | ppl   8.8548\n",
    "Learning rate: [5.7738482772988926e-05]\n",
    " 1800/1094375 batches | batch/sec  6.06 | rem mins  3007 | loss 2.15989 | ppl   8.6702\n",
    "Learning rate: [5.851975311857076e-05]\n",
    " 2000/1094375 batches | batch/sec  6.02 | rem mins  3025 | loss 2.13358 | ppl   8.4450\n",
    "Learning rate: [5.93010234641528e-05]\n",
    " 2200/1094375 batches | batch/sec  6.02 | rem mins  3025 | loss 2.09773 | ppl   8.1476\n",
    "Learning rate: [6.0082293809734644e-05]\n",
    " 2400/1094375 batches | batch/sec  6.00 | rem mins  3031 | loss 2.09831 | ppl   8.1524\n",
    "Learning rate: [6.086356415531649e-05]\n",
    " 2600/1094375 batches | batch/sec  6.04 | rem mins  3010 | loss 2.08473 | ppl   8.0424\n",
    "Learning rate: [6.164483450089853e-05]\n",
    " 2800/1094375 batches | batch/sec  6.06 | rem mins  3001 | loss 2.10851 | ppl   8.2360\n",
    "Learning rate: [6.242610484648038e-05]\n",
    " 3000/1094375 batches | batch/sec  6.00 | rem mins  3029 | loss 2.09885 | ppl   8.1568\n",
    "Learning rate: [6.320737519206221e-05]\n",
    " 3200/1094375 batches | batch/sec  6.06 | rem mins  3000 | loss 2.10401 | ppl   8.1990\n",
    "Learning rate: [6.398864553764425e-05]\n",
    " 3400/1094375 batches | batch/sec  6.00 | rem mins  3030 | loss 2.08425 | ppl   8.0385\n",
    "Learning rate: [6.476991588322609e-05]\n",
    " 3600/1094375 batches | batch/sec  6.06 | rem mins  3001 | loss 2.09481 | ppl   8.1239\n",
    "Learning rate: [6.555118622880813e-05]\n",
    " 3800/1094375 batches | batch/sec  6.06 | rem mins  3002 | loss 2.06801 | ppl   7.9091\n",
    "Learning rate: [6.633245657438998e-05]\n",
    " 4400/1094375 batches | batch/sec  6.02 | rem mins  3016 | loss 2.04541 | ppl   7.7323\n",
    "Learning rate: [6.86762676111357e-05]\n",
    " 4600/1094375 batches | batch/sec  6.04 | rem mins  3005 | loss 2.05948 | ppl   7.8419\n",
    "Learning rate: [6.945753795671754e-05]\n",
    " 4800/1094375 batches | batch/sec  6.04 | rem mins  3007 | loss 2.04716 | ppl   7.7458\n",
    "Learning rate: [7.023880830229958e-05]\n",
    " 5000/1094375 batches | batch/sec  6.04 | rem mins  3006 | loss 2.00302 | ppl   7.4114\n",
    "Learning rate: [7.102007864788143e-05]\n",
    " 5200/1094375 batches | batch/sec  6.10 | rem mins  2976 | loss 2.04586 | ppl   7.7358\n",
    "Learning rate: [7.180134899346347e-05]\n",
    " 5400/1094375 batches | batch/sec  6.03 | rem mins  3012 | loss 2.05192 | ppl   7.7828\n",
    "Learning rate: [7.25826193390453e-05]\n",
    " 5600/1094375 batches | batch/sec  6.01 | rem mins  3020 | loss 2.04752 | ppl   7.7486\n",
    "Learning rate: [7.336388968462715e-05]\n",
    " 5800/1094375 batches | batch/sec  6.05 | rem mins  2997 | loss 2.06977 | ppl   7.9230\n",
    "Learning rate: [7.414516003020919e-05]\n",
    " 6000/1094375 batches | batch/sec  6.01 | rem mins  3019 | loss 2.00659 | ppl   7.4379\n",
    "Learning rate: [7.492643037579103e-05]\n",
    " 6200/1094375 batches | batch/sec  6.06 | rem mins  2995 | loss 1.98977 | ppl   7.3138\n",
    "Learning rate: [7.570770072137288e-05]\n",
    " 6400/1094375 batches | batch/sec  6.03 | rem mins  3010 | loss 2.01843 | ppl   7.5265\n",
    "Learning rate: [7.648897106695492e-05]\n",
    " 6600/1094375 batches | batch/sec  6.04 | rem mins  3000 | loss 1.98719 | ppl   7.2950\n",
    "Learning rate: [7.727024141253675e-05]\n",
    " 6800/1094375 batches | batch/sec  6.08 | rem mins  2983 | loss 1.95080 | ppl   7.0343\n",
    "Learning rate: [7.80515117581188e-05]\n",
    " 7000/1094375 batches | batch/sec  6.07 | rem mins  2986 | loss 2.03436 | ppl   7.6474\n",
    "Learning rate: [7.883278210370064e-05]\n",
    " 7200/1094375 batches | batch/sec  6.03 | rem mins  3004 | loss 1.97413 | ppl   7.2003\n",
    "Learning rate: [7.961405244928248e-05]\n",
    " 7400/1094375 batches | batch/sec  6.09 | rem mins  2976 | loss 1.98217 | ppl   7.2585\n",
    "Learning rate: [8.039532279486452e-05]\n",
    " 7600/1094375 batches | batch/sec  6.01 | rem mins  3014 | loss 1.97551 | ppl   7.2103\n",
    "Learning rate: [8.117659314044637e-05]\n",
    " 7800/1094375 batches | batch/sec  6.02 | rem mins  3011 | loss 2.03884 | ppl   7.6817\n",
    "Learning rate: [8.19578634860282e-05]\n",
    " 8000/1094375 batches | batch/sec  6.04 | rem mins  3000 | loss 1.96854 | ppl   7.1602\n",
    "Learning rate: [8.273913383161024e-05]\n",
    " 8200/1094375 batches | batch/sec  6.04 | rem mins  2997 | loss 1.95671 | ppl   7.0760\n",
    "Learning rate: [8.352040417719208e-05]\n",
    " 8400/1094375 batches | batch/sec  6.05 | rem mins  2993 | loss 1.97431 | ppl   7.2016\n",
    "Learning rate: [8.430167452277412e-05]\n",
    " 8600/1094375 batches | batch/sec  6.09 | rem mins  2973 | loss 1.98936 | ppl   7.3109\n",
    "Learning rate: [8.508294486835597e-05]\n",
    " 8800/1094375 batches | batch/sec  6.02 | rem mins  3004 | loss 1.99694 | ppl   7.3665\n",
    "Learning rate: [8.586421521393782e-05]\n",
    " 9000/1094375 batches | batch/sec  6.04 | rem mins  2996 | loss 1.96982 | ppl   7.1694\n",
    "Learning rate: [8.664548555951986e-05]\n",
    " 9200/1094375 batches | batch/sec  6.04 | rem mins  2996 | loss 1.97087 | ppl   7.1769\n",
    "Learning rate: [8.74267559051017e-05]\n",
    " 9400/1094375 batches | batch/sec  6.05 | rem mins  2988 | loss 1.96717 | ppl   7.1504\n",
    "Learning rate: [8.820802625068353e-05]\n",
    " 9600/1094375 batches | batch/sec  6.04 | rem mins  2993 | loss 1.96870 | ppl   7.1614\n",
    "Learning rate: [8.898929659626557e-05]\n",
    " 9800/1094375 batches | batch/sec  6.10 | rem mins  2964 | loss 1.88421 | ppl   6.5812\n",
    "Learning rate: [8.977056694184742e-05]\n",
    "10000/1094375 batches | batch/sec  6.05 | rem mins  2989 | loss 1.95331 | ppl   7.0520\n",
    "Learning rate: [9.055183728742927e-05]\n",
    "10200/1094375 batches | batch/sec  6.08 | rem mins  2974 | loss 1.90418 | ppl   6.7139\n",
    "Learning rate: [9.133310763301131e-05]\n",
    "10400/1094375 batches | batch/sec  6.03 | rem mins  2997 | loss 1.90973 | ppl   6.7512\n",
    "Learning rate: [9.211437797859315e-05]\n",
    "10600/1094375 batches | batch/sec  6.03 | rem mins  2995 | loss 1.94469 | ppl   6.9915\n",
    "Learning rate: [9.289564832417519e-05]\n",
    "10800/1094375 batches | batch/sec  6.13 | rem mins  2947 | loss 1.88414 | ppl   6.5807\n",
    "Learning rate: [9.367691866975702e-05]\n",
    "11000/1094375 batches | batch/sec  6.04 | rem mins  2990 | loss 1.95173 | ppl   7.0409\n",
    "Learning rate: [9.445818901533887e-05]\n",
    "11200/1094375 batches | batch/sec  6.06 | rem mins  2981 | loss 1.90058 | ppl   6.6898\n",
    "Learning rate: [9.523945936092091e-05]\n",
    "11400/1094375 batches | batch/sec  6.05 | rem mins  2985 | loss 1.92056 | ppl   6.8248\n",
    "Learning rate: [9.602072970650276e-05]\n",
    "11600/1094375 batches | batch/sec  6.02 | rem mins  2996 | loss 1.93534 | ppl   6.9264\n",
    "Learning rate: [9.68020000520848e-05]\n",
    "11800/1094375 batches | batch/sec  6.03 | rem mins  2994 | loss 1.91260 | ppl   6.7707\n",
    "Learning rate: [9.758327039766664e-05]\n",
    "12000/1094375 batches | batch/sec  6.01 | rem mins  3001 | loss 1.90748 | ppl   6.7361\n",
    "Learning rate: [9.836454074324847e-05]\n",
    "12200/1094375 batches | batch/sec  6.05 | rem mins  2981 | loss 1.91697 | ppl   6.8003\n",
    "Learning rate: [9.914581108883051e-05]\n",
    "12400/1094375 batches | batch/sec  6.05 | rem mins  2983 | loss 1.88180 | ppl   6.5653\n",
    "Learning rate: [9.992708143441236e-05]\n",
    "12600/1094375 batches | batch/sec  6.04 | rem mins  2983 | loss 1.88811 | ppl   6.6068\n",
    "Learning rate: [0.0001007083517799942]\n",
    "12800/1094375 batches | batch/sec  6.02 | rem mins  2996 | loss 1.86936 | ppl   6.4842\n",
    "Learning rate: [0.00010148962212557624]\n",
    "13000/1094375 batches | batch/sec  6.04 | rem mins  2984 | loss 1.87374 | ppl   6.5126\n",
    "Learning rate: [0.00010227089247115807]\n",
    "13200/1094375 batches | batch/sec  6.07 | rem mins  2969 | loss 1.82664 | ppl   6.2130\n",
    "Learning rate: [0.00010305216281673992]\n",
    "13400/1094375 batches | batch/sec  6.03 | rem mins  2989 | loss 1.85998 | ppl   6.4236\n",
    "Learning rate: [0.00010383343316232196]\n",
    "13600/1094375 batches | batch/sec  6.04 | rem mins  2984 | loss 1.90186 | ppl   6.6984\n",
    "Learning rate: [0.00010461470350790381]\n",
    "13800/1094375 batches | batch/sec  6.01 | rem mins  2994 | loss 1.87266 | ppl   6.5056\n",
    "Learning rate: [0.00010539597385348585]\n",
    "14000/1094375 batches | batch/sec  6.02 | rem mins  2993 | loss 1.87012 | ppl   6.4891\n",
    "Learning rate: [0.00010617724419906769]\n",
    "14200/1094375 batches | batch/sec  6.01 | rem mins  2995 | loss 1.86910 | ppl   6.4825\n",
    "Learning rate: [0.00010695851454464952]\n",
    "14400/1094375 batches | batch/sec  6.06 | rem mins  2969 | loss 1.85738 | ppl   6.4070\n",
    "Learning rate: [0.00010773978489023156]\n",
    "14600/1094375 batches | batch/sec  6.05 | rem mins  2973 | loss 1.88094 | ppl   6.5597\n",
    "Learning rate: [0.00010852105523581341]\n",
    "14800/1094375 batches | batch/sec  6.08 | rem mins  2962 | loss 1.89406 | ppl   6.6463\n",
    "Learning rate: [0.00010930232558139545]\n",
    "15000/1094375 batches | batch/sec  6.02 | rem mins  2988 | loss 1.87972 | ppl   6.5517\n",
    "Learning rate: [0.0001100835959269773]\n",
    "15600/1094375 batches | batch/sec  6.06 | rem mins  2968 | loss 1.83238 | ppl   6.2487\n",
    "Learning rate: [0.00011242740696372301]\n",
    "15800/1094375 batches | batch/sec  6.06 | rem mins  2966 | loss 1.84731 | ppl   6.3427\n",
    "Learning rate: [0.00011320867730930486]\n",
    "16000/1094375 batches | batch/sec  6.05 | rem mins  2972 | loss 1.85458 | ppl   6.3890\n",
    "Learning rate: [0.0001139899476548869]\n",
    "16200/1094375 batches | batch/sec  6.08 | rem mins  2957 | loss 1.86522 | ppl   6.4574\n",
    "Learning rate: [0.00011477121800046875]\n",
    "16400/1094375 batches | batch/sec  6.07 | rem mins  2958 | loss 1.82106 | ppl   6.1784\n",
    "Learning rate: [0.00011555248834605058]\n",
    "16600/1094375 batches | batch/sec  6.05 | rem mins  2969 | loss 1.83132 | ppl   6.2421\n",
    "Learning rate: [0.00011633375869163262]\n",
    "16800/1094375 batches | batch/sec  6.02 | rem mins  2984 | loss 1.82209 | ppl   6.1848\n",
    "Learning rate: [0.00011711502903721447]\n",
    "17000/1094375 batches | batch/sec  6.01 | rem mins  2990 | loss 1.84740 | ppl   6.3433\n",
    "Learning rate: [0.0001178962993827965]\n",
    "17200/1094375 batches | batch/sec  6.05 | rem mins  2967 | loss 1.79080 | ppl   5.9943\n",
    "Learning rate: [0.00011867756972837835]\n",
    "17400/1094375 batches | batch/sec  6.02 | rem mins  2981 | loss 1.79783 | ppl   6.0365\n",
    "Learning rate: [0.0001194588400739602]\n",
    "17600/1094375 batches | batch/sec  6.06 | rem mins  2963 | loss 1.82053 | ppl   6.1751\n",
    "Learning rate: [0.00012024011041954224]\n",
    "17800/1094375 batches | batch/sec  6.05 | rem mins  2965 | loss 1.83568 | ppl   6.2694\n",
    "Learning rate: [0.00012102138076512407]\n",
    "18000/1094375 batches | batch/sec  6.02 | rem mins  2981 | loss 1.82705 | ppl   6.2156\n",
    "Learning rate: [0.00012180265111070592]\n",
    "18200/1094375 batches | batch/sec  6.03 | rem mins  2974 | loss 1.78422 | ppl   5.9549\n",
    "Learning rate: [0.00012258392145628796]\n",
    "18400/1094375 batches | batch/sec  6.01 | rem mins  2983 | loss 1.81588 | ppl   6.1465\n",
    "Learning rate: [0.0001233651918018698]\n",
    "18600/1094375 batches | batch/sec  6.00 | rem mins  2989 | loss 1.77226 | ppl   5.8841\n",
    "Learning rate: [0.00012414646214745185]\n",
    "18800/1094375 batches | batch/sec  6.02 | rem mins  2979 | loss 1.77351 | ppl   5.8915\n",
    "Learning rate: [0.0001249277324930337]\n",
    "19000/1094375 batches | batch/sec  6.07 | rem mins  2950 | loss 1.80973 | ppl   6.1088\n",
    "Learning rate: [0.00012570900283861552]\n",
    "19200/1094375 batches | batch/sec  6.08 | rem mins  2948 | loss 1.78906 | ppl   5.9838\n",
    "Learning rate: [0.00012649027318419756]\n",
    "19400/1094375 batches | batch/sec  6.05 | rem mins  2960 | loss 1.78805 | ppl   5.9778\n",
    "Learning rate: [0.0001272715435297794]\n",
    "19600/1094375 batches | batch/sec  6.08 | rem mins  2948 | loss 1.76814 | ppl   5.8600\n",
    "Learning rate: [0.00012805281387536126]\n",
    "19800/1094375 batches | batch/sec  6.05 | rem mins  2960 | loss 1.80467 | ppl   6.0780\n",
    "Learning rate: [0.0001288340842209433]\n",
    "20000/1094375 batches | batch/sec  6.05 | rem mins  2959 | loss 1.78066 | ppl   5.9338\n",
    "Learning rate: [0.00012961535456652512]\n",
    "20200/1094375 batches | batch/sec  6.06 | rem mins  2952 | loss 1.76265 | ppl   5.8279\n",
    "Learning rate: [0.00013039662491210719]\n",
    "20400/1094375 batches | batch/sec  6.01 | rem mins  2981 | loss 1.77424 | ppl   5.8958\n",
    "Learning rate: [0.000131177895257689]\n",
    "20600/1094375 batches | batch/sec  6.03 | rem mins  2966 | loss 1.78043 | ppl   5.9324\n",
    "Learning rate: [0.00013195916560327086]\n",
    "20800/1094375 batches | batch/sec  6.04 | rem mins  2961 | loss 1.78917 | ppl   5.9845\n",
    "Learning rate: [0.0001327404359488529]\n",
    "21000/1094375 batches | batch/sec  6.02 | rem mins  2971 | loss 1.78498 | ppl   5.9595\n",
    "Learning rate: [0.00013352170629443475]\n",
    "21200/1094375 batches | batch/sec  6.04 | rem mins  2961 | loss 1.78841 | ppl   5.9800\n",
    "Learning rate: [0.00013430297664001657]\n",
    "21800/1094375 batches | batch/sec  6.05 | rem mins  2954 | loss 1.74742 | ppl   5.7398\n",
    "Learning rate: [0.0001366467876767625]\n",
    "22000/1094375 batches | batch/sec  6.03 | rem mins  2965 | loss 1.71974 | ppl   5.5831\n",
    "Learning rate: [0.00013742805802234435]\n",
    "22200/1094375 batches | batch/sec  6.05 | rem mins  2952 | loss 1.73452 | ppl   5.6662\n",
    "Learning rate: [0.0001382093283679262]\n",
    "22400/1094375 batches | batch/sec  6.10 | rem mins  2930 | loss 1.76847 | ppl   5.8619\n",
    "Learning rate: [0.00013899059871350824]\n",
    "22600/1094375 batches | batch/sec  6.08 | rem mins  2939 | loss 1.73723 | ppl   5.6816\n",
    "Learning rate: [0.00013977186905909006]\n",
    "22800/1094375 batches | batch/sec  6.05 | rem mins  2954 | loss 1.72579 | ppl   5.6169\n",
    "Learning rate: [0.0001405531394046719]\n",
    "23000/1094375 batches | batch/sec  6.02 | rem mins  2967 | loss 1.68955 | ppl   5.4170\n",
    "Learning rate: [0.00014133440975025395]\n",
    "23200/1094375 batches | batch/sec  6.05 | rem mins  2953 | loss 1.72485 | ppl   5.6117\n",
    "Learning rate: [0.0001421156800958358]\n",
    "23400/1094375 batches | batch/sec  6.03 | rem mins  2959 | loss 1.71498 | ppl   5.5565\n",
    "Learning rate: [0.00014289695044141784]\n",
    "23600/1094375 batches | batch/sec  6.03 | rem mins  2961 | loss 1.73139 | ppl   5.6485\n",
    "Learning rate: [0.0001436782207869997]\n",
    "23800/1094375 batches | batch/sec  6.01 | rem mins  2967 | loss 1.70354 | ppl   5.4933\n",
    "Learning rate: [0.0001444594911325815]\n",
    "24000/1094375 batches | batch/sec  6.00 | rem mins  2973 | loss 1.73712 | ppl   5.6810\n",
    "Learning rate: [0.00014524076147816355]\n",
    "24200/1094375 batches | batch/sec  6.04 | rem mins  2955 | loss 1.68377 | ppl   5.3858\n",
    "Learning rate: [0.0001460220318237454]\n",
    "24400/1094375 batches | batch/sec  6.01 | rem mins  2968 | loss 1.69258 | ppl   5.4335\n",
    "Learning rate: [0.00014680330216932725]\n",
    "24600/1094375 batches | batch/sec  6.03 | rem mins  2957 | loss 1.69628 | ppl   5.4536\n",
    "Learning rate: [0.0001475845725149093]\n",
    "24800/1094375 batches | batch/sec  6.02 | rem mins  2961 | loss 1.72446 | ppl   5.6095\n",
    "Learning rate: [0.00014836584286049114]\n",
    "25000/1094375 batches | batch/sec  6.05 | rem mins  2946 | loss 1.68108 | ppl   5.3714\n",
    "Learning rate: [0.00014914711320607318]\n",
    "25200/1094375 batches | batch/sec  6.06 | rem mins  2939 | loss 1.73720 | ppl   5.6814\n",
    "Learning rate: [0.000149928383551655]\n",
    "25400/1094375 batches | batch/sec  6.03 | rem mins  2955 | loss 1.70100 | ppl   5.4794\n",
    "Learning rate: [0.00015070965389723685]\n",
    "25600/1094375 batches | batch/sec  6.04 | rem mins  2948 | loss 1.72769 | ppl   5.6276\n",
    "Learning rate: [0.0001514909242428189]\n",
    "25800/1094375 batches | batch/sec  6.04 | rem mins  2948 | loss 1.71396 | ppl   5.5509\n",
    "Learning rate: [0.00015227219458840074]\n",
    "26000/1094375 batches | batch/sec  6.07 | rem mins  2932 | loss 1.71049 | ppl   5.5317\n",
    "Learning rate: [0.00015305346493398256]\n",
    "26200/1094375 batches | batch/sec  6.06 | rem mins  2938 | loss 1.68541 | ppl   5.3947\n",
    "Learning rate: [0.00015383473527956463]\n",
    "26400/1094375 batches | batch/sec  6.05 | rem mins  2942 | loss 1.68925 | ppl   5.4154\n",
    "Learning rate: [0.00015461600562514645]\n",
    "26600/1094375 batches | batch/sec  6.06 | rem mins  2938 | loss 1.71457 | ppl   5.5543\n",
    "Learning rate: [0.0001553972759707285]\n",
    "26800/1094375 batches | batch/sec  6.07 | rem mins  2932 | loss 1.65565 | ppl   5.2365\n",
    "Learning rate: [0.00015617854631631034]\n",
    "27000/1094375 batches | batch/sec  6.02 | rem mins  2955 | loss 1.70451 | ppl   5.4987\n",
    "Learning rate: [0.0001569598166618922]\n",
    "27600/1094375 batches | batch/sec  6.03 | rem mins  2950 | loss 1.70957 | ppl   5.5266\n",
    "Learning rate: [0.0001593036276986379]\n",
    "27800/1094375 batches | batch/sec  6.03 | rem mins  2947 | loss 1.68190 | ppl   5.3758\n",
    "Learning rate: [0.00016008489804421994]\n",
    "28000/1094375 batches | batch/sec  6.02 | rem mins  2952 | loss 1.68185 | ppl   5.3755\n",
    "Learning rate: [0.0001608661683898018]\n",
    "28200/1094375 batches | batch/sec  6.05 | rem mins  2936 | loss 1.70306 | ppl   5.4907\n",
    "Learning rate: [0.00016164743873538364]\n",
    "28400/1094375 batches | batch/sec  6.06 | rem mins  2933 | loss 1.66359 | ppl   5.2782\n",
    "Learning rate: [0.00016242870908096568]\n",
    "28600/1094375 batches | batch/sec  6.03 | rem mins  2946 | loss 1.71144 | ppl   5.5369\n",
    "Learning rate: [0.0001632099794265475]\n",
    "28800/1094375 batches | batch/sec  6.01 | rem mins  2957 | loss 1.66626 | ppl   5.2923\n",
    "Learning rate: [0.00016399124977212954]\n",
    "29000/1094375 batches | batch/sec  6.04 | rem mins  2938 | loss 1.62471 | ppl   5.0770\n",
    "Learning rate: [0.0001647725201177114]\n",
    "29200/1094375 batches | batch/sec  6.03 | rem mins  2945 | loss 1.63032 | ppl   5.1055\n",
    "Learning rate: [0.00016555379046329324]\n",
    "29400/1094375 batches | batch/sec  6.02 | rem mins  2949 | loss 1.69606 | ppl   5.4524\n",
    "Learning rate: [0.00016633506080887528]\n",
    "29600/1094375 batches | batch/sec  6.00 | rem mins  2959 | loss 1.67495 | ppl   5.3385\n",
    "Learning rate: [0.00016711633115445713]\n",
    "29800/1094375 batches | batch/sec  6.04 | rem mins  2937 | loss 1.67307 | ppl   5.3285\n",
    "Learning rate: [0.00016789760150003917]\n",
    "30000/1094375 batches | batch/sec  5.97 | rem mins  2969 | loss 1.63744 | ppl   5.1420\n",
    "Learning rate: [0.000168678871845621]\n",
    "30200/1094375 batches | batch/sec  5.99 | rem mins  2963 | loss 1.64118 | ppl   5.1613\n",
    "Learning rate: [0.00016946014219120284]\n",
    "30400/1094375 batches | batch/sec  6.05 | rem mins  2930 | loss 1.64467 | ppl   5.1793\n",
    "Learning rate: [0.00017024141253678488]\n",
    "30600/1094375 batches | batch/sec  6.05 | rem mins  2932 | loss 1.66008 | ppl   5.2597\n",
    "Learning rate: [0.00017102268288236673]\n",
    "30800/1094375 batches | batch/sec  6.03 | rem mins  2938 | loss 1.67321 | ppl   5.3292\n",
    "Learning rate: [0.00017180395322794856]\n",
    "31000/1094375 batches | batch/sec  6.05 | rem mins  2932 | loss 1.66567 | ppl   5.2892\n",
    "Learning rate: [0.0001725852235735306]\n",
    "31200/1094375 batches | batch/sec  6.06 | rem mins  2926 | loss 1.67743 | ppl   5.3518\n",
    "Learning rate: [0.00017336649391911244]\n",
    "31400/1094375 batches | batch/sec  6.04 | rem mins  2932 | loss 1.65282 | ppl   5.2217\n",
    "Learning rate: [0.0001741477642646943]\n",
    "31600/1094375 batches | batch/sec  6.07 | rem mins  2919 | loss 1.63422 | ppl   5.1255\n",
    "Learning rate: [0.00017492903461027633]\n",
    "31800/1094375 batches | batch/sec  6.08 | rem mins  2913 | loss 1.67964 | ppl   5.3636\n",
    "Learning rate: [0.00017571030495585816]\n",
    "32000/1094375 batches | batch/sec  6.05 | rem mins  2928 | loss 1.62211 | ppl   5.0637\n",
    "Learning rate: [0.00017649157530144022]\n",
    "32200/1094375 batches | batch/sec  6.01 | rem mins  2945 | loss 1.61408 | ppl   5.0233\n",
    "Learning rate: [0.00017727284564702205]\n",
    "32400/1094375 batches | batch/sec  6.03 | rem mins  2937 | loss 1.63047 | ppl   5.1063\n",
    "Learning rate: [0.0001780541159926039]\n",
    "32600/1094375 batches | batch/sec  6.03 | rem mins  2933 | loss 1.65102 | ppl   5.2123\n",
    "Learning rate: [0.00017883538633818593]\n",
    "32800/1094375 batches | batch/sec  6.02 | rem mins  2937 | loss 1.63995 | ppl   5.1549\n",
    "Learning rate: [0.00017961665668376778]\n",
    "33000/1094375 batches | batch/sec  6.05 | rem mins  2923 | loss 1.62265 | ppl   5.0665\n",
    "Learning rate: [0.00018039792702934982]\n",
    "33200/1094375 batches | batch/sec  6.03 | rem mins  2932 | loss 1.61453 | ppl   5.0255\n",
    "Learning rate: [0.00018117919737493165]\n",
    "33400/1094375 batches | batch/sec  6.05 | rem mins  2923 | loss 1.61925 | ppl   5.0493\n",
    "Learning rate: [0.0001819604677205135]\n",
    "33600/1094375 batches | batch/sec  6.06 | rem mins  2916 | loss 1.62944 | ppl   5.1010\n",
    "Learning rate: [0.00018274173806609554]\n",
    "33800/1094375 batches | batch/sec  6.09 | rem mins  2905 | loss 1.63438 | ppl   5.1263\n",
    "Learning rate: [0.00018352300841167739]\n",
    "34000/1094375 batches | batch/sec  6.02 | rem mins  2938 | loss 1.65798 | ppl   5.2487\n",
    "Learning rate: [0.00018430427875725924]\n",
    "34200/1094375 batches | batch/sec  6.03 | rem mins  2930 | loss 1.64302 | ppl   5.1708\n",
    "Learning rate: [0.00018508554910284127]\n",
    "34400/1094375 batches | batch/sec  6.05 | rem mins  2922 | loss 1.63545 | ppl   5.1318\n",
    "Learning rate: [0.0001858668194484231]\n",
    "34600/1094375 batches | batch/sec  6.08 | rem mins  2906 | loss 1.62981 | ppl   5.1029\n",
    "Learning rate: [0.00018664808979400495]\n",
    "34800/1094375 batches | batch/sec  6.07 | rem mins  2911 | loss 1.61979 | ppl   5.0520\n",
    "Learning rate: [0.00018742936013958699]\n",
    "35000/1094375 batches | batch/sec  6.04 | rem mins  2923 | loss 1.63577 | ppl   5.1334\n",
    "Learning rate: [0.00018821063048516884]\n",
    "35200/1094375 batches | batch/sec  6.01 | rem mins  2936 | loss 1.60019 | ppl   4.9540\n",
    "Learning rate: [0.00018899190083075088]\n",
    "35400/1094375 batches | batch/sec  6.06 | rem mins  2910 | loss 1.63039 | ppl   5.1059\n",
    "Learning rate: [0.00018977317117633273]\n",
    "35600/1094375 batches | batch/sec  6.00 | rem mins  2941 | loss 1.64584 | ppl   5.1854\n",
    "Learning rate: [0.00019055444152191455]\n",
    "35800/1094375 batches | batch/sec  6.03 | rem mins  2924 | loss 1.59836 | ppl   4.9449\n",
    "Learning rate: [0.0001913357118674966]\n",
    "36000/1094375 batches | batch/sec  6.07 | rem mins  2904 | loss 1.59425 | ppl   4.9246\n",
    "Learning rate: [0.00019211698221307844]\n",
    "36200/1094375 batches | batch/sec  5.99 | rem mins  2942 | loss 1.63967 | ppl   5.1535\n",
    "Learning rate: [0.00019289825255866048]\n",
    "36400/1094375 batches | batch/sec  6.02 | rem mins  2927 | loss 1.63132 | ppl   5.1106\n",
    "Learning rate: [0.00019367952290424233]\n",
    "36600/1094375 batches | batch/sec  6.04 | rem mins  2921 | loss 1.62641 | ppl   5.0856\n",
    "Learning rate: [0.00019446079324982415]\n",
    "36800/1094375 batches | batch/sec  6.03 | rem mins  2924 | loss 1.60414 | ppl   4.9736\n",
    "Learning rate: [0.00019524206359540622]\n",
    "37000/1094375 batches | batch/sec  6.04 | rem mins  2919 | loss 1.64169 | ppl   5.1639\n",
    "Learning rate: [0.00019602333394098804]\n",
    "37200/1094375 batches | batch/sec  6.04 | rem mins  2918 | loss 1.61601 | ppl   5.0330\n",
    "Learning rate: [0.0001968046042865699]\n",
    "37400/1094375 batches | batch/sec  6.01 | rem mins  2933 | loss 1.60205 | ppl   4.9632\n",
    "Learning rate: [0.00019758587463215193]\n",
    "37600/1094375 batches | batch/sec  6.02 | rem mins  2926 | loss 1.62435 | ppl   5.0751\n",
    "Learning rate: [0.00019836714497773378]\n",
    "37800/1094375 batches | batch/sec  6.00 | rem mins  2933 | loss 1.58298 | ppl   4.8694\n",
    "Learning rate: [0.0001991484153233156]\n",
    "38000/1094375 batches | batch/sec  6.00 | rem mins  2933 | loss 1.60981 | ppl   5.0019\n",
    "Learning rate: [0.00019992968566889764]\n",
    "38200/1094375 batches | batch/sec  6.04 | rem mins  2916 | loss 1.58149 | ppl   4.8622\n",
    "Learning rate: [0.0002007109560144795]\n",
    "38400/1094375 batches | batch/sec  6.07 | rem mins  2902 | loss 1.60118 | ppl   4.9589\n",
    "Learning rate: [0.00020149222636006153]\n",
    "38600/1094375 batches | batch/sec  6.01 | rem mins  2929 | loss 1.59515 | ppl   4.9291\n",
    "Learning rate: [0.00020227349670564338]\n",
    "38800/1094375 batches | batch/sec  6.06 | rem mins  2905 | loss 1.59961 | ppl   4.9511\n",
    "Learning rate: [0.00020305476705122523]\n",
    "39000/1094375 batches | batch/sec  6.01 | rem mins  2925 | loss 1.59313 | ppl   4.9191\n",
    "Learning rate: [0.00020383603739680727]\n",
    "39200/1094375 batches | batch/sec  6.05 | rem mins  2908 | loss 1.59916 | ppl   4.9489\n",
    "Learning rate: [0.0002046173077423891]\n",
    "39400/1094375 batches | batch/sec  6.03 | rem mins  2914 | loss 1.56634 | ppl   4.7891\n",
    "Learning rate: [0.00020539857808797113]\n",
    "39600/1094375 batches | batch/sec  6.03 | rem mins  2917 | loss 1.55814 | ppl   4.7500\n",
    "Learning rate: [0.00020617984843355298]\n",
    "39800/1094375 batches | batch/sec  6.07 | rem mins  2897 | loss 1.61993 | ppl   5.0527\n",
    "Learning rate: [0.00020696111877913483]\n",
    "40000/1094375 batches | batch/sec  6.01 | rem mins  2923 | loss 1.61025 | ppl   5.0041\n",
    "Learning rate: [0.00020774238912471687]\n",
    "40200/1094375 batches | batch/sec  6.04 | rem mins  2910 | loss 1.57950 | ppl   4.8525\n",
    "Learning rate: [0.00020852365947029872]\n",
    "40400/1094375 batches | batch/sec  5.99 | rem mins  2934 | loss 1.55779 | ppl   4.7483\n",
    "Learning rate: [0.00020930492981588054]\n",
    "40600/1094375 batches | batch/sec  6.01 | rem mins  2921 | loss 1.58574 | ppl   4.8829\n",
    "Learning rate: [0.00021008620016146258]\n",
    "40800/1094375 batches | batch/sec  6.04 | rem mins  2908 | loss 1.55746 | ppl   4.7468\n",
    "Learning rate: [0.00021086747050704443]\n",
    "41000/1094375 batches | batch/sec  6.02 | rem mins  2917 | loss 1.58356 | ppl   4.8723\n",
    "Learning rate: [0.00021164874085262628]\n",
    "41200/1094375 batches | batch/sec  6.03 | rem mins  2911 | loss 1.57928 | ppl   4.8515\n",
    "Learning rate: [0.00021243001119820832]\n",
    "41400/1094375 batches | batch/sec  6.03 | rem mins  2912 | loss 1.61234 | ppl   5.0145\n",
    "Learning rate: [0.00021321128154379017]\n",
    "41600/1094375 batches | batch/sec  6.04 | rem mins  2907 | loss 1.59957 | ppl   4.9509\n",
    "Learning rate: [0.0002139925518893722]\n",
    "41800/1094375 batches | batch/sec  6.05 | rem mins  2898 | loss 1.59192 | ppl   4.9132\n",
    "Learning rate: [0.00021477382223495403]\n",
    "42000/1094375 batches | batch/sec  6.03 | rem mins  2910 | loss 1.52170 | ppl   4.5800\n",
    "Learning rate: [0.00021555509258053588]\n",
    "42200/1094375 batches | batch/sec  6.07 | rem mins  2887 | loss 1.57864 | ppl   4.8483\n",
    "Learning rate: [0.00021633636292611792]\n",
    "42400/1094375 batches | batch/sec  6.07 | rem mins  2888 | loss 1.53387 | ppl   4.6361\n",
    "Learning rate: [0.00021711763327169977]\n",
    "42600/1094375 batches | batch/sec  6.06 | rem mins  2891 | loss 1.56142 | ppl   4.7656\n",
    "Learning rate: [0.0002178989036172816]\n",
    "42800/1094375 batches | batch/sec  6.05 | rem mins  2895 | loss 1.55436 | ppl   4.7321\n",
    "Learning rate: [0.00021868017396286366]\n",
    "43000/1094375 batches | batch/sec  6.05 | rem mins  2896 | loss 1.54287 | ppl   4.6780\n",
    "Learning rate: [0.00021946144430844548]\n",
    "43200/1094375 batches | batch/sec  6.04 | rem mins  2899 | loss 1.55440 | ppl   4.7322\n",
    "Learning rate: [0.00022024271465402733]\n",
    "43400/1094375 batches | batch/sec  6.09 | rem mins  2877 | loss 1.57626 | ppl   4.8368\n",
    "Learning rate: [0.00022102398499960937]\n",
    "43600/1094375 batches | batch/sec  6.01 | rem mins  2913 | loss 1.55548 | ppl   4.7374\n",
    "Learning rate: [0.00022180525534519122]\n",
    "43800/1094375 batches | batch/sec  6.00 | rem mins  2917 | loss 1.54963 | ppl   4.7097\n",
    "Learning rate: [0.00022258652569077326]\n",
    "44000/1094375 batches | batch/sec  6.05 | rem mins  2893 | loss 1.52968 | ppl   4.6167\n",
    "Learning rate: [0.00022336779603635508]\n",
    "44200/1094375 batches | batch/sec  6.03 | rem mins  2901 | loss 1.49190 | ppl   4.4455\n",
    "Learning rate: [0.00022414906638193693]\n",
    "44400/1094375 batches | batch/sec  6.05 | rem mins  2894 | loss 1.52532 | ppl   4.5966\n",
    "Learning rate: [0.00022493033672751897]\n",
    "44600/1094375 batches | batch/sec  6.04 | rem mins  2895 | loss 1.56981 | ppl   4.8057\n",
    "Learning rate: [0.00022571160707310082]\n",
    "44800/1094375 batches | batch/sec  6.04 | rem mins  2899 | loss 1.61436 | ppl   5.0247\n",
    "Learning rate: [0.00022649287741868286]\n",
    "45000/1094375 batches | batch/sec  6.06 | rem mins  2885 | loss 1.56064 | ppl   4.7619\n",
    "Learning rate: [0.0002272741477642647]\n",
    "45200/1094375 batches | batch/sec  6.06 | rem mins  2887 | loss 1.57303 | ppl   4.8212\n",
    "Learning rate: [0.00022805541810984653]\n",
    "45400/1094375 batches | batch/sec  6.07 | rem mins  2882 | loss 1.50571 | ppl   4.5074\n",
    "Learning rate: [0.00022883668845542857]\n",
    "45600/1094375 batches | batch/sec  6.06 | rem mins  2884 | loss 1.55710 | ppl   4.7450\n",
    "Learning rate: [0.00022961795880101042]\n",
    "45800/1094375 batches | batch/sec  6.03 | rem mins  2898 | loss 1.55629 | ppl   4.7412\n",
    "Learning rate: [0.00023039922914659227]\n",
    "46000/1094375 batches | batch/sec  6.06 | rem mins  2881 | loss 1.58107 | ppl   4.8601\n",
    "Learning rate: [0.0002311804994921743]\n",
    "46200/1094375 batches | batch/sec  6.04 | rem mins  2892 | loss 1.57753 | ppl   4.8430\n",
    "Learning rate: [0.00023196176983775616]\n",
    "46400/1094375 batches | batch/sec  6.03 | rem mins  2899 | loss 1.55553 | ppl   4.7376\n",
    "Learning rate: [0.00023274304018333798]\n",
    "46600/1094375 batches | batch/sec  6.02 | rem mins  2902 | loss 1.54708 | ppl   4.6977\n",
    "Learning rate: [0.00023352431052892002]\n",
    "46800/1094375 batches | batch/sec  6.06 | rem mins  2882 | loss 1.51052 | ppl   4.5291\n",
    "Learning rate: [0.00023430558087450187]\n",
    "47000/1094375 batches | batch/sec  6.05 | rem mins  2883 | loss 1.56000 | ppl   4.7588\n",
    "Learning rate: [0.0002350868512200839]\n",
    "47200/1094375 batches | batch/sec  6.01 | rem mins  2902 | loss 1.52991 | ppl   4.6178\n",
    "Learning rate: [0.00023586812156566576]\n",
    "47400/1094375 batches | batch/sec  6.09 | rem mins  2864 | loss 1.53941 | ppl   4.6619\n",
    "Learning rate: [0.00023664939191124759]\n",
    "47600/1094375 batches | batch/sec  6.06 | rem mins  2877 | loss 1.49168 | ppl   4.4445\n",
    "Learning rate: [0.00023743066225682965]\n",
    "47800/1094375 batches | batch/sec  6.07 | rem mins  2876 | loss 1.57684 | ppl   4.8396\n",
    "Learning rate: [0.00023821193260241147]\n",
    "48000/1094375 batches | batch/sec  6.03 | rem mins  2894 | loss 1.53994 | ppl   4.6643\n",
    "Learning rate: [0.00023899320294799351]\n",
    "48200/1094375 batches | batch/sec  6.04 | rem mins  2885 | loss 1.52828 | ppl   4.6103\n",
    "Learning rate: [0.00023977447329357536]\n",
    "48400/1094375 batches | batch/sec  6.06 | rem mins  2875 | loss 1.52444 | ppl   4.5926\n",
    "Learning rate: [0.00024055574363915721]\n",
    "48600/1094375 batches | batch/sec  6.06 | rem mins  2874 | loss 1.50733 | ppl   4.5147\n",
    "Learning rate: [0.00024133701398473925]\n",
    "48800/1094375 batches | batch/sec  6.05 | rem mins  2881 | loss 1.53084 | ppl   4.6221\n",
    "Learning rate: [0.00024211828433032108]\n",
    "49000/1094375 batches | batch/sec  6.03 | rem mins  2892 | loss 1.52485 | ppl   4.5944\n",
    "Learning rate: [0.00024289955467590293]\n",
    "49200/1094375 batches | batch/sec  5.99 | rem mins  2907 | loss 1.51104 | ppl   4.5314\n",
    "Learning rate: [0.00024368082502148497]\n",
    "49400/1094375 batches | batch/sec  6.03 | rem mins  2887 | loss 1.51043 | ppl   4.5287\n",
    "Learning rate: [0.0002444620953670668]\n",
    "49600/1094375 batches | batch/sec  6.04 | rem mins  2881 | loss 1.51271 | ppl   4.5390\n",
    "Learning rate: [0.00024524336571264866]\n",
    "49800/1094375 batches | batch/sec  6.04 | rem mins  2883 | loss 1.50573 | ppl   4.5074\n",
    "Learning rate: [0.00024602463605823073]\n",
    "50000/1094375 batches | batch/sec  6.04 | rem mins  2881 | loss 1.52548 | ppl   4.5973\n",
    "Learning rate: [0.0002468059064038125]\n",
    "50200/1094375 batches | batch/sec  5.99 | rem mins  2908 | loss 1.51178 | ppl   4.5348\n",
    "Learning rate: [0.0002475871767493946]\n",
    "50400/1094375 batches | batch/sec  6.02 | rem mins  2888 | loss 1.48500 | ppl   4.4150\n",
    "Learning rate: [0.00024836844709497644]\n",
    "50600/1094375 batches | batch/sec  6.05 | rem mins  2875 | loss 1.51905 | ppl   4.5679\n",
    "Learning rate: [0.0002491497174405583]\n",
    "50800/1094375 batches | batch/sec  6.01 | rem mins  2895 | loss 1.49325 | ppl   4.4516\n",
    "Learning rate: [0.0002499309877861403]\n",
    "51000/1094375 batches | batch/sec  6.01 | rem mins  2893 | loss 1.51744 | ppl   4.5605\n",
    "Learning rate: [0.00025071225813172215]\n",
    "51200/1094375 batches | batch/sec  6.00 | rem mins  2895 | loss 1.53364 | ppl   4.6350\n",
    "Learning rate: [0.0002514935284773042]\n",
    "51400/1094375 batches | batch/sec  6.07 | rem mins  2866 | loss 1.50366 | ppl   4.4981\n",
    "Learning rate: [0.000252274798822886]\n",
    "51600/1094375 batches | batch/sec  6.02 | rem mins  2887 | loss 1.53226 | ppl   4.6286\n",
    "Learning rate: [0.00025305606916846787]\n",
    "51800/1094375 batches | batch/sec  6.05 | rem mins  2874 | loss 1.52424 | ppl   4.5916\n",
    "Learning rate: [0.00025383733951404993]\n",
    "52000/1094375 batches | batch/sec  6.03 | rem mins  2881 | loss 1.52797 | ppl   4.6088\n",
    "Learning rate: [0.0002546186098596318]\n",
    "52200/1094375 batches | batch/sec  6.02 | rem mins  2887 | loss 1.55449 | ppl   4.7327\n",
    "Learning rate: [0.00025539988020521363]\n",
    "52400/1094375 batches | batch/sec  6.04 | rem mins  2874 | loss 1.48459 | ppl   4.4131\n",
    "Learning rate: [0.00025618115055079565]\n",
    "52600/1094375 batches | batch/sec  6.07 | rem mins  2860 | loss 1.52115 | ppl   4.5775\n",
    "Learning rate: [0.0002569624208963775]\n",
    "52800/1094375 batches | batch/sec  6.06 | rem mins  2863 | loss 1.51885 | ppl   4.5670\n",
    "Learning rate: [0.00025774369124195934]\n",
    "53000/1094375 batches | batch/sec  6.04 | rem mins  2874 | loss 1.51243 | ppl   4.5377\n",
    "Learning rate: [0.00025852496158754136]\n",
    "53200/1094375 batches | batch/sec  6.05 | rem mins  2867 | loss 1.53234 | ppl   4.6290\n",
    "Learning rate: [0.0002593062319331232]\n",
    "53400/1094375 batches | batch/sec  6.04 | rem mins  2874 | loss 1.46488 | ppl   4.3270\n",
    "Learning rate: [0.0002600875022787053]\n",
    "53600/1094375 batches | batch/sec  6.05 | rem mins  2867 | loss 1.47903 | ppl   4.3887\n",
    "Learning rate: [0.0002608687726242871]\n",
    "53800/1094375 batches | batch/sec  6.05 | rem mins  2866 | loss 1.50396 | ppl   4.4995\n",
    "Learning rate: [0.0002616500429698689]\n",
    "54000/1094375 batches | batch/sec  6.04 | rem mins  2873 | loss 1.49551 | ppl   4.4616\n",
    "Learning rate: [0.000262431313315451]\n",
    "54200/1094375 batches | batch/sec  6.00 | rem mins  2888 | loss 1.52736 | ppl   4.6060\n",
    "Learning rate: [0.00026321258366103283]\n",
    "54400/1094375 batches | batch/sec  5.99 | rem mins  2892 | loss 1.50162 | ppl   4.4890\n",
    "Learning rate: [0.00026399385400661485]\n",
    "54600/1094375 batches | batch/sec  6.07 | rem mins  2857 | loss 1.51333 | ppl   4.5418\n",
    "Learning rate: [0.0002647751243521967]\n",
    "54800/1094375 batches | batch/sec  6.09 | rem mins  2844 | loss 1.52055 | ppl   4.5747\n",
    "Learning rate: [0.00026555639469777855]\n",
    "55000/1094375 batches | batch/sec  6.07 | rem mins  2856 | loss 1.48168 | ppl   4.4003\n",
    "Learning rate: [0.0002663376650433606]\n",
    "55200/1094375 batches | batch/sec  6.01 | rem mins  2880 | loss 1.52465 | ppl   4.5935\n",
    "Learning rate: [0.0002671189353889424]\n",
    "55400/1094375 batches | batch/sec  5.98 | rem mins  2897 | loss 1.48095 | ppl   4.3971\n",
    "Learning rate: [0.00026790020573452426]\n",
    "55600/1094375 batches | batch/sec  6.04 | rem mins  2864 | loss 1.46761 | ppl   4.3388\n",
    "Learning rate: [0.0002686814760801063]\n",
    "55800/1094375 batches | batch/sec  6.05 | rem mins  2862 | loss 1.50652 | ppl   4.5110\n",
    "Learning rate: [0.0002694627464256882]\n",
    "56000/1094375 batches | batch/sec  6.07 | rem mins  2853 | loss 1.49871 | ppl   4.4759\n",
    "Learning rate: [0.00027024401677126997]\n",
    "56200/1094375 batches | batch/sec  6.05 | rem mins  2859 | loss 1.46319 | ppl   4.3197\n",
    "Learning rate: [0.00027102528711685204]\n",
    "56400/1094375 batches | batch/sec  6.04 | rem mins  2864 | loss 1.51008 | ppl   4.5271\n",
    "Learning rate: [0.0002718065574624339]\n",
    "56600/1094375 batches | batch/sec  6.04 | rem mins  2864 | loss 1.48633 | ppl   4.4209\n",
    "Learning rate: [0.0002725878278080159]\n",
    "56800/1094375 batches | batch/sec  6.04 | rem mins  2861 | loss 1.49235 | ppl   4.4475\n",
    "Learning rate: [0.00027336909815359775]\n",
    "57000/1094375 batches | batch/sec  6.05 | rem mins  2859 | loss 1.48019 | ppl   4.3938\n",
    "Learning rate: [0.0002741503684991796]\n",
    "57200/1094375 batches | batch/sec  5.99 | rem mins  2884 | loss 1.47415 | ppl   4.3673\n",
    "Learning rate: [0.00027493163884476167]\n",
    "57400/1094375 batches | batch/sec  6.02 | rem mins  2873 | loss 1.45128 | ppl   4.2686\n",
    "Learning rate: [0.00027571290919034346]\n",
    "57600/1094375 batches | batch/sec  6.06 | rem mins  2853 | loss 1.48865 | ppl   4.4311\n",
    "Learning rate: [0.00027649417953592553]\n",
    "57800/1094375 batches | batch/sec  6.05 | rem mins  2853 | loss 1.48858 | ppl   4.4308\n",
    "Learning rate: [0.0002772754498815074]\n",
    "58000/1094375 batches | batch/sec  6.04 | rem mins  2862 | loss 1.45812 | ppl   4.2979\n",
    "Learning rate: [0.0002780567202270892]\n",
    "58200/1094375 batches | batch/sec  6.05 | rem mins  2854 | loss 1.44313 | ppl   4.2339\n",
    "Learning rate: [0.000278837990572671]\n",
    "58400/1094375 batches | batch/sec  6.02 | rem mins  2867 | loss 1.48684 | ppl   4.4231\n",
    "Learning rate: [0.0002796192609182531]\n",
    "58600/1094375 batches | batch/sec  6.05 | rem mins  2853 | loss 1.48334 | ppl   4.4076\n",
    "Learning rate: [0.00028040053126383494]\n",
    "58800/1094375 batches | batch/sec  6.03 | rem mins  2863 | loss 1.49219 | ppl   4.4468\n",
    "Learning rate: [0.00028118180160941695]\n",
    "59000/1094375 batches | batch/sec  6.01 | rem mins  2872 | loss 1.50780 | ppl   4.5168\n",
    "Learning rate: [0.0002819630719549988]\n",
    "59200/1094375 batches | batch/sec  6.05 | rem mins  2853 | loss 1.47428 | ppl   4.3679\n",
    "Learning rate: [0.00028274434230058065]\n",
    "59400/1094375 batches | batch/sec  6.01 | rem mins  2868 | loss 1.52006 | ppl   4.5725\n",
    "Learning rate: [0.0002835256126461627]\n",
    "59600/1094375 batches | batch/sec  6.00 | rem mins  2873 | loss 1.45656 | ppl   4.2912\n",
    "Learning rate: [0.0002843068829917445]\n",
    "60600/1094375 batches | batch/sec  6.08 | rem mins  2835 | loss 1.46985 | ppl   4.3486\n",
    "Learning rate: [0.00028821323471965414]\n",
    "60800/1094375 batches | batch/sec  6.02 | rem mins  2861 | loss 1.42423 | ppl   4.1546\n",
    "Learning rate: [0.0002889945050652362]\n",
    "61000/1094375 batches | batch/sec  6.04 | rem mins  2849 | loss 1.43322 | ppl   4.1922\n",
    "Learning rate: [0.000289775775410818]\n",
    "61200/1094375 batches | batch/sec  6.05 | rem mins  2845 | loss 1.47159 | ppl   4.3562\n",
    "Learning rate: [0.00029055704575639985]\n",
    "61400/1094375 batches | batch/sec  6.05 | rem mins  2847 | loss 1.49152 | ppl   4.4438\n",
    "Learning rate: [0.0002913383161019817]\n",
    "61600/1094375 batches | batch/sec  6.02 | rem mins  2857 | loss 1.45507 | ppl   4.2848\n",
    "Learning rate: [0.00029211958644756377]\n",
    "61800/1094375 batches | batch/sec  6.04 | rem mins  2848 | loss 1.45228 | ppl   4.2729\n",
    "Learning rate: [0.0002929008567931456]\n",
    "62000/1094375 batches | batch/sec  6.03 | rem mins  2853 | loss 1.46243 | ppl   4.3164\n",
    "Learning rate: [0.00029368212713872763]\n",
    "62200/1094375 batches | batch/sec  6.02 | rem mins  2857 | loss 1.48625 | ppl   4.4205\n",
    "Learning rate: [0.0002944633974843095]\n",
    "62400/1094375 batches | batch/sec  6.06 | rem mins  2840 | loss 1.47940 | ppl   4.3903\n",
    "Learning rate: [0.00029524466782989133]\n",
    "62600/1094375 batches | batch/sec  6.05 | rem mins  2844 | loss 1.43555 | ppl   4.2019\n",
    "Learning rate: [0.0002960259381754734]\n",
    "62800/1094375 batches | batch/sec  6.06 | rem mins  2836 | loss 1.51167 | ppl   4.5343\n",
    "Learning rate: [0.0002968072085210552]\n",
    "63000/1094375 batches | batch/sec  6.02 | rem mins  2854 | loss 1.45096 | ppl   4.2672\n",
    "Learning rate: [0.00029758847886663726]\n",
    "63200/1094375 batches | batch/sec  6.00 | rem mins  2866 | loss 1.42428 | ppl   4.1549\n",
    "Learning rate: [0.0002983697492122191]\n",
    "63400/1094375 batches | batch/sec  6.09 | rem mins  2823 | loss 1.46328 | ppl   4.3201\n",
    "Learning rate: [0.00029915101955780096]\n",
    "63600/1094375 batches | batch/sec  6.03 | rem mins  2851 | loss 1.44018 | ppl   4.2215\n",
    "Learning rate: [0.00029993228990338297]\n",
    "63800/1094375 batches | batch/sec  5.99 | rem mins  2870 | loss 1.47669 | ppl   4.3784\n",
    "Learning rate: [0.0003007135602489648]\n",
    "64000/1094375 batches | batch/sec  5.99 | rem mins  2866 | loss 1.47392 | ppl   4.3663\n",
    "Learning rate: [0.0003014948305945469]\n",
    "64200/1094375 batches | batch/sec  5.98 | rem mins  2872 | loss 1.46488 | ppl   4.3270\n",
    "Learning rate: [0.0003022761009401287]\n",
    "64400/1094375 batches | batch/sec  6.00 | rem mins  2860 | loss 1.40921 | ppl   4.0927\n",
    "Learning rate: [0.00030305737128571053]\n",
    "64600/1094375 batches | batch/sec  6.04 | rem mins  2844 | loss 1.45777 | ppl   4.2964\n",
    "Learning rate: [0.0003038386416312924]\n",
    "64800/1094375 batches | batch/sec  6.05 | rem mins  2837 | loss 1.43603 | ppl   4.2040\n",
    "Learning rate: [0.00030461991197687445]\n",
    "65000/1094375 batches | batch/sec  5.99 | rem mins  2865 | loss 1.47192 | ppl   4.3576\n",
    "Learning rate: [0.00030540118232245624]\n",
    "65200/1094375 batches | batch/sec  6.00 | rem mins  2861 | loss 1.45069 | ppl   4.2661\n",
    "Learning rate: [0.0003061824526680383]\n",
    "65400/1094375 batches | batch/sec  6.03 | rem mins  2845 | loss 1.45048 | ppl   4.2651\n",
    "Learning rate: [0.00030696372301362016]\n",
    "65600/1094375 batches | batch/sec  6.05 | rem mins  2835 | loss 1.43341 | ppl   4.1930\n",
    "Learning rate: [0.000307744993359202]\n",
    "65800/1094375 batches | batch/sec  6.04 | rem mins  2839 | loss 1.42723 | ppl   4.1672\n",
    "Learning rate: [0.000308526263704784]\n",
    "66000/1094375 batches | batch/sec  6.02 | rem mins  2848 | loss 1.45986 | ppl   4.3054\n",
    "Learning rate: [0.00030930753405036587]\n",
    "66200/1094375 batches | batch/sec  6.06 | rem mins  2829 | loss 1.44042 | ppl   4.2225\n",
    "Learning rate: [0.00031008880439594794]\n",
    "66400/1094375 batches | batch/sec  6.05 | rem mins  2832 | loss 1.44890 | ppl   4.2584\n",
    "Learning rate: [0.00031087007474152973]\n",
    "66600/1094375 batches | batch/sec  6.07 | rem mins  2824 | loss 1.48214 | ppl   4.4023\n",
    "Learning rate: [0.0003116513450871116]\n",
    "66800/1094375 batches | batch/sec  6.05 | rem mins  2830 | loss 1.45274 | ppl   4.2748\n",
    "Learning rate: [0.00031243261543269365]\n",
    "67000/1094375 batches | batch/sec  6.05 | rem mins  2832 | loss 1.45926 | ppl   4.3028\n",
    "Learning rate: [0.0003132138857782755]\n",
    "67200/1094375 batches | batch/sec  6.03 | rem mins  2840 | loss 1.44156 | ppl   4.2273\n",
    "Learning rate: [0.0003139951561238575]\n",
    "67400/1094375 batches | batch/sec  6.04 | rem mins  2832 | loss 1.42322 | ppl   4.1505\n",
    "Learning rate: [0.00031477642646943936]\n",
    "67600/1094375 batches | batch/sec  6.01 | rem mins  2845 | loss 1.46756 | ppl   4.3386\n",
    "Learning rate: [0.0003155576968150212]\n",
    "67800/1094375 batches | batch/sec  6.06 | rem mins  2825 | loss 1.43182 | ppl   4.1863\n",
    "Learning rate: [0.00031633896716060306]\n",
    "68000/1094375 batches | batch/sec  6.04 | rem mins  2830 | loss 1.40411 | ppl   4.0719\n",
    "Learning rate: [0.0003171202375061851]\n",
    "68200/1094375 batches | batch/sec  6.03 | rem mins  2838 | loss 1.41219 | ppl   4.1049\n",
    "Learning rate: [0.0003179015078517669]\n",
    "68400/1094375 batches | batch/sec  6.04 | rem mins  2833 | loss 1.41922 | ppl   4.1339\n",
    "Learning rate: [0.000318682778197349]\n",
    "68600/1094375 batches | batch/sec  6.06 | rem mins  2822 | loss 1.44449 | ppl   4.2397\n",
    "Learning rate: [0.00031946404854293084]\n",
    "68800/1094375 batches | batch/sec  6.01 | rem mins  2846 | loss 1.44282 | ppl   4.2326\n",
    "Learning rate: [0.00032024531888851264]\n",
    "69000/1094375 batches | batch/sec  6.08 | rem mins  2813 | loss 1.44453 | ppl   4.2398\n",
    "Learning rate: [0.0003210265892340947]\n",
    "69200/1094375 batches | batch/sec  6.06 | rem mins  2820 | loss 1.48369 | ppl   4.4092\n",
    "Learning rate: [0.00032180785957967655]\n",
    "69400/1094375 batches | batch/sec  6.02 | rem mins  2839 | loss 1.41593 | ppl   4.1203\n",
    "Learning rate: [0.00032258912992525856]\n",
    "69600/1094375 batches | batch/sec  6.03 | rem mins  2833 | loss 1.46261 | ppl   4.3172\n",
    "Learning rate: [0.0003233704002708404]\n",
    "69800/1094375 batches | batch/sec  6.05 | rem mins  2822 | loss 1.43912 | ppl   4.2170\n",
    "Learning rate: [0.00032415167061642226]\n",
    "70000/1094375 batches | batch/sec  6.05 | rem mins  2824 | loss 1.41187 | ppl   4.1036\n",
    "Learning rate: [0.00032493294096200433]\n",
    "70200/1094375 batches | batch/sec  6.05 | rem mins  2823 | loss 1.43094 | ppl   4.1826\n",
    "Learning rate: [0.0003257142113075861]\n",
    "70400/1094375 batches | batch/sec  6.02 | rem mins  2833 | loss 1.40145 | ppl   4.0611\n",
    "Learning rate: [0.0003264954816531682]\n",
    "70600/1094375 batches | batch/sec  6.06 | rem mins  2816 | loss 1.44338 | ppl   4.2350\n",
    "Learning rate: [0.00032727675199875004]\n",
    "70800/1094375 batches | batch/sec  6.06 | rem mins  2814 | loss 1.42772 | ppl   4.1692\n",
    "Learning rate: [0.0003280580223443319]\n",
    "71000/1094375 batches | batch/sec  6.00 | rem mins  2843 | loss 1.43030 | ppl   4.1800\n",
    "Learning rate: [0.0003288392926899137]\n",
    "71200/1094375 batches | batch/sec  5.98 | rem mins  2852 | loss 1.40568 | ppl   4.0783\n",
    "Learning rate: [0.00032962056303549575]\n",
    "71400/1094375 batches | batch/sec  6.07 | rem mins  2810 | loss 1.41734 | ppl   4.1261\n",
    "Learning rate: [0.0003304018333810776]\n",
    "71600/1094375 batches | batch/sec  6.04 | rem mins  2823 | loss 1.44267 | ppl   4.2320\n",
    "Learning rate: [0.0003311831037266596]\n",
    "71800/1094375 batches | batch/sec  6.03 | rem mins  2829 | loss 1.42182 | ppl   4.1447\n",
    "Learning rate: [0.00033196437407224147]\n",
    "72000/1094375 batches | batch/sec  6.00 | rem mins  2839 | loss 1.44008 | ppl   4.2210\n",
    "Learning rate: [0.0003327456444178233]\n",
    "72200/1094375 batches | batch/sec  6.03 | rem mins  2823 | loss 1.40123 | ppl   4.0602\n",
    "Learning rate: [0.0003335269147634054]\n",
    "72400/1094375 batches | batch/sec  5.99 | rem mins  2845 | loss 1.44087 | ppl   4.2244\n",
    "Learning rate: [0.0003343081851089872]\n",
    "72600/1094375 batches | batch/sec  6.01 | rem mins  2831 | loss 1.41780 | ppl   4.1280\n",
    "Learning rate: [0.00033508945545456924]\n",
    "72800/1094375 batches | batch/sec  6.05 | rem mins  2815 | loss 1.36881 | ppl   3.9307\n",
    "Learning rate: [0.0003358707258001511]\n",
    "73000/1094375 batches | batch/sec  6.03 | rem mins  2822 | loss 1.38680 | ppl   4.0020\n",
    "Learning rate: [0.00033665199614573294]\n",
    "73200/1094375 batches | batch/sec  6.04 | rem mins  2817 | loss 1.44311 | ppl   4.2339\n",
    "Learning rate: [0.0003374332664913148]\n",
    "73400/1094375 batches | batch/sec  6.07 | rem mins  2802 | loss 1.38608 | ppl   3.9992\n",
    "Learning rate: [0.0003382145368368968]\n",
    "73600/1094375 batches | batch/sec  6.06 | rem mins  2810 | loss 1.43409 | ppl   4.1958\n",
    "Learning rate: [0.00033899580718247866]\n",
    "73800/1094375 batches | batch/sec  6.07 | rem mins  2801 | loss 1.44372 | ppl   4.2364\n",
    "Learning rate: [0.00033977707752806067]\n",
    "74000/1094375 batches | batch/sec  6.04 | rem mins  2818 | loss 1.42011 | ppl   4.1376\n",
    "Learning rate: [0.0003405583478736425]\n",
    "74200/1094375 batches | batch/sec  6.02 | rem mins  2823 | loss 1.44689 | ppl   4.2499\n",
    "Learning rate: [0.00034133961821922437]\n",
    "74400/1094375 batches | batch/sec  6.01 | rem mins  2826 | loss 1.43176 | ppl   4.1860\n",
    "Learning rate: [0.00034212088856480643]\n",
    "74600/1094375 batches | batch/sec  6.05 | rem mins  2810 | loss 1.43676 | ppl   4.2070\n",
    "Learning rate: [0.0003429021589103883]\n",
    "74800/1094375 batches | batch/sec  6.03 | rem mins  2819 | loss 1.41555 | ppl   4.1188\n",
    "Learning rate: [0.0003436834292559703]\n",
    "75000/1094375 batches | batch/sec  6.02 | rem mins  2822 | loss 1.42176 | ppl   4.1444\n",
    "Learning rate: [0.00034446469960155215]\n",
    "75200/1094375 batches | batch/sec  6.04 | rem mins  2813 | loss 1.44677 | ppl   4.2494\n",
    "Learning rate: [0.000345245969947134]\n",
    "75400/1094375 batches | batch/sec  6.01 | rem mins  2826 | loss 1.40269 | ppl   4.0661\n",
    "Learning rate: [0.000346027240292716]\n",
    "75600/1094375 batches | batch/sec  6.02 | rem mins  2821 | loss 1.39446 | ppl   4.0328\n",
    "Learning rate: [0.00034680851063829786]\n",
    "75800/1094375 batches | batch/sec  6.02 | rem mins  2820 | loss 1.41919 | ppl   4.1338\n",
    "Learning rate: [0.0003475897809838799]\n",
    "76000/1094375 batches | batch/sec  6.08 | rem mins  2791 | loss 1.42647 | ppl   4.1640\n",
    "Learning rate: [0.0003483710513294618]\n",
    "76200/1094375 batches | batch/sec  6.06 | rem mins  2801 | loss 1.40502 | ppl   4.0756\n",
    "Learning rate: [0.00034915232167504357]\n",
    "76400/1094375 batches | batch/sec  6.02 | rem mins  2818 | loss 1.43495 | ppl   4.1994\n",
    "Learning rate: [0.0003499335920206254]\n",
    "76600/1094375 batches | batch/sec  6.02 | rem mins  2820 | loss 1.41068 | ppl   4.0988\n",
    "Learning rate: [0.0003507148623662075]\n",
    "76800/1094375 batches | batch/sec  6.07 | rem mins  2796 | loss 1.39365 | ppl   4.0295\n",
    "Learning rate: [0.00035149613271178934]\n",
    "77000/1094375 batches | batch/sec  6.02 | rem mins  2815 | loss 1.39833 | ppl   4.0485\n",
    "Learning rate: [0.00035227740305737135]\n",
    "77200/1094375 batches | batch/sec  6.06 | rem mins  2797 | loss 1.42148 | ppl   4.1433\n",
    "Learning rate: [0.0003530586734029532]\n",
    "77400/1094375 batches | batch/sec  6.01 | rem mins  2820 | loss 1.42167 | ppl   4.1440\n",
    "Learning rate: [0.00035383994374853505]\n",
    "77600/1094375 batches | batch/sec  6.00 | rem mins  2826 | loss 1.36526 | ppl   3.9168\n",
    "Learning rate: [0.00035462121409411706]\n",
    "77800/1094375 batches | batch/sec  6.01 | rem mins  2819 | loss 1.40412 | ppl   4.0720\n",
    "Learning rate: [0.0003554024844396989]\n",
    "78000/1094375 batches | batch/sec  6.04 | rem mins  2803 | loss 1.39839 | ppl   4.0487\n",
    "Learning rate: [0.000356183754785281]\n",
    "78200/1094375 batches | batch/sec  6.01 | rem mins  2819 | loss 1.39513 | ppl   4.0355\n",
    "Learning rate: [0.0003569650251308628]\n",
    "78400/1094375 batches | batch/sec  6.02 | rem mins  2812 | loss 1.38583 | ppl   3.9981\n",
    "Learning rate: [0.0003577462954764446]\n",
    "78600/1094375 batches | batch/sec  6.04 | rem mins  2801 | loss 1.42504 | ppl   4.1580\n",
    "Learning rate: [0.0003585275658220267]\n",
    "78800/1094375 batches | batch/sec  6.01 | rem mins  2815 | loss 1.40441 | ppl   4.0731\n",
    "Learning rate: [0.00035930883616760854]\n",
    "79000/1094375 batches | batch/sec  6.07 | rem mins  2789 | loss 1.40547 | ppl   4.0775\n",
    "Learning rate: [0.00036009010651319055]\n",
    "79200/1094375 batches | batch/sec  6.00 | rem mins  2820 | loss 1.42045 | ppl   4.1390\n",
    "Learning rate: [0.0003608713768587724]\n",
    "79400/1094375 batches | batch/sec  5.99 | rem mins  2822 | loss 1.44769 | ppl   4.2533\n",
    "Learning rate: [0.00036165264720435425]\n",
    "79600/1094375 batches | batch/sec  6.06 | rem mins  2792 | loss 1.40875 | ppl   4.0908\n",
    "Learning rate: [0.0003624339175499361]\n",
    "79800/1094375 batches | batch/sec  6.00 | rem mins  2817 | loss 1.40730 | ppl   4.0849\n",
    "Learning rate: [0.0003632151878955181]\n",
    "80000/1094375 batches | batch/sec  6.02 | rem mins  2807 | loss 1.40929 | ppl   4.0930\n",
    "Learning rate: [0.00036399645824109996]\n",
    "80200/1094375 batches | batch/sec  6.03 | rem mins  2804 | loss 1.40055 | ppl   4.0574\n",
    "Learning rate: [0.00036477772858668203]\n",
    "80400/1094375 batches | batch/sec  6.07 | rem mins  2786 | loss 1.39356 | ppl   4.0292\n",
    "Learning rate: [0.0003655589989322639]\n",
    "80600/1094375 batches | batch/sec  6.01 | rem mins  2813 | loss 1.37047 | ppl   3.9372\n",
    "Learning rate: [0.00036634026927784573]\n",
    "80800/1094375 batches | batch/sec  6.03 | rem mins  2803 | loss 1.39822 | ppl   4.0480\n",
    "Learning rate: [0.00036712153962342774]\n",
    "81000/1094375 batches | batch/sec  6.08 | rem mins  2780 | loss 1.41106 | ppl   4.1003\n",
    "Learning rate: [0.0003679028099690096]\n",
    "81200/1094375 batches | batch/sec  6.02 | rem mins  2805 | loss 1.40478 | ppl   4.0746\n",
    "Learning rate: [0.0003686840803145916]\n",
    "81400/1094375 batches | batch/sec  6.06 | rem mins  2786 | loss 1.40310 | ppl   4.0678\n",
    "Learning rate: [0.00036946535066017345]\n",
    "81600/1094375 batches | batch/sec  6.04 | rem mins  2793 | loss 1.34848 | ppl   3.8516\n",
    "Learning rate: [0.0003702466210057553]\n",
    "81800/1094375 batches | batch/sec  6.05 | rem mins  2791 | loss 1.39055 | ppl   4.0170\n",
    "Learning rate: [0.00037102789135133737]\n",
    "82000/1094375 batches | batch/sec  6.04 | rem mins  2793 | loss 1.37480 | ppl   3.9543\n",
    "Learning rate: [0.00037180916169691916]\n",
    "82200/1094375 batches | batch/sec  6.02 | rem mins  2804 | loss 1.37505 | ppl   3.9553\n",
    "Learning rate: [0.00037259043204250123]\n",
    "82400/1094375 batches | batch/sec  6.01 | rem mins  2806 | loss 1.41566 | ppl   4.1192\n",
    "Learning rate: [0.0003733717023880831]\n",
    "82600/1094375 batches | batch/sec  6.04 | rem mins  2792 | loss 1.35787 | ppl   3.8879\n",
    "Learning rate: [0.00037415297273366493]\n",
    "82800/1094375 batches | batch/sec  6.04 | rem mins  2791 | loss 1.37344 | ppl   3.9489\n",
    "Learning rate: [0.0003749342430792468]\n",
    "83800/1094375 batches | batch/sec  5.98 | rem mins  2818 | loss 1.39704 | ppl   4.0432\n",
    "Learning rate: [0.00037884059480715635]\n",
    "84000/1094375 batches | batch/sec  6.00 | rem mins  2805 | loss 1.35576 | ppl   3.8797\n",
    "Learning rate: [0.0003796218651527384]\n",
    "84200/1094375 batches | batch/sec  6.05 | rem mins  2781 | loss 1.40072 | ppl   4.0581\n",
    "Learning rate: [0.00038040313549832027]\n",
    "84400/1094375 batches | batch/sec  6.00 | rem mins  2803 | loss 1.39500 | ppl   4.0350\n",
    "Learning rate: [0.0003811844058439023]\n",
    "84600/1094375 batches | batch/sec  6.06 | rem mins  2778 | loss 1.36628 | ppl   3.9207\n",
    "Learning rate: [0.00038196567618948413]\n",
    "84800/1094375 batches | batch/sec  5.99 | rem mins  2807 | loss 1.40593 | ppl   4.0793\n",
    "Learning rate: [0.000382746946535066]\n",
    "85000/1094375 batches | batch/sec  6.08 | rem mins  2768 | loss 1.38790 | ppl   4.0064\n",
    "Learning rate: [0.000383528216880648]\n",
    "85200/1094375 batches | batch/sec  6.09 | rem mins  2762 | loss 1.35554 | ppl   3.8789\n",
    "Learning rate: [0.00038430948722622984]\n",
    "85400/1094375 batches | batch/sec  6.09 | rem mins  2763 | loss 1.35951 | ppl   3.8943\n",
    "Learning rate: [0.0003850907575718119]\n",
    "85600/1094375 batches | batch/sec  6.08 | rem mins  2767 | loss 1.38883 | ppl   4.0101\n",
    "Learning rate: [0.00038587202791739376]\n",
    "85800/1094375 batches | batch/sec  6.08 | rem mins  2765 | loss 1.36526 | ppl   3.9167\n",
    "Learning rate: [0.00038665329826297556]\n",
    "86000/1094375 batches | batch/sec  6.08 | rem mins  2766 | loss 1.39680 | ppl   4.0422\n",
    "Learning rate: [0.0003874345686085574]\n",
    "86200/1094375 batches | batch/sec  6.08 | rem mins  2762 | loss 1.38213 | ppl   3.9834\n",
    "Learning rate: [0.00038821583895413947]\n",
    "86400/1094375 batches | batch/sec  6.07 | rem mins  2770 | loss 1.39880 | ppl   4.0503\n",
    "Learning rate: [0.0003889971092997213]\n",
    "86600/1094375 batches | batch/sec  6.08 | rem mins  2762 | loss 1.38526 | ppl   3.9959\n",
    "Learning rate: [0.00038977837964530333]\n",
    "86800/1094375 batches | batch/sec  6.08 | rem mins  2762 | loss 1.39358 | ppl   4.0292\n",
    "Learning rate: [0.0003905596499908852]\n",
    "87000/1094375 batches | batch/sec  6.03 | rem mins  2785 | loss 1.40081 | ppl   4.0585\n",
    "Learning rate: [0.00039134092033646703]\n",
    "87200/1094375 batches | batch/sec  6.02 | rem mins  2788 | loss 1.37736 | ppl   3.9644\n",
    "Learning rate: [0.00039212219068204905]\n",
    "87400/1094375 batches | batch/sec  6.03 | rem mins  2783 | loss 1.38242 | ppl   3.9845\n",
    "Learning rate: [0.0003929034610276309]\n",
    "87600/1094375 batches | batch/sec  6.05 | rem mins  2772 | loss 1.37758 | ppl   3.9653\n",
    "Learning rate: [0.00039368473137321296]\n",
    "87800/1094375 batches | batch/sec  6.05 | rem mins  2772 | loss 1.36342 | ppl   3.9095\n",
    "Learning rate: [0.0003944660017187948]\n",
    "88000/1094375 batches | batch/sec  6.03 | rem mins  2780 | loss 1.38818 | ppl   4.0076\n",
    "Learning rate: [0.0003952472720643766]\n",
    "88200/1094375 batches | batch/sec  6.04 | rem mins  2778 | loss 1.40260 | ppl   4.0657\n",
    "Learning rate: [0.0003960285424099587]\n",
    "88400/1094375 batches | batch/sec  6.06 | rem mins  2766 | loss 1.34772 | ppl   3.8487\n",
    "Learning rate: [0.0003968098127555405]\n",
    "88600/1094375 batches | batch/sec  6.08 | rem mins  2759 | loss 1.36411 | ppl   3.9123\n",
    "Learning rate: [0.00039759108310112254]\n",
    "88800/1094375 batches | batch/sec  6.05 | rem mins  2771 | loss 1.37999 | ppl   3.9749\n",
    "Learning rate: [0.0003983723534467044]\n",
    "89000/1094375 batches | batch/sec  6.05 | rem mins  2768 | loss 1.36394 | ppl   3.9116\n",
    "Learning rate: [0.00039915362379228624]\n",
    "89200/1094375 batches | batch/sec  6.06 | rem mins  2766 | loss 1.38998 | ppl   4.0148\n",
    "Learning rate: [0.0003999348941378681]\n",
    "89400/1094375 batches | batch/sec  6.03 | rem mins  2779 | loss 1.38034 | ppl   3.9762\n",
    "Learning rate: [0.0004007161644834501]\n",
    "89600/1094375 batches | batch/sec  6.06 | rem mins  2764 | loss 1.39587 | ppl   4.0385\n",
    "Learning rate: [0.00040149743482903195]\n",
    "89800/1094375 batches | batch/sec  6.06 | rem mins  2764 | loss 1.35417 | ppl   3.8736\n",
    "Learning rate: [0.000402278705174614]\n",
    "90000/1094375 batches | batch/sec  6.05 | rem mins  2765 | loss 1.36702 | ppl   3.9236\n",
    "Learning rate: [0.00040305997552019586]\n",
    "90200/1094375 batches | batch/sec  6.06 | rem mins  2764 | loss 1.36775 | ppl   3.9265\n",
    "Learning rate: [0.0004038412458657777]\n",
    "90400/1094375 batches | batch/sec  6.07 | rem mins  2756 | loss 1.37336 | ppl   3.9486\n",
    "Learning rate: [0.0004046225162113597]\n",
    "90600/1094375 batches | batch/sec  6.08 | rem mins  2752 | loss 1.35009 | ppl   3.8578\n",
    "Learning rate: [0.0004054037865569416]\n",
    "90800/1094375 batches | batch/sec  6.06 | rem mins  2762 | loss 1.33070 | ppl   3.7837\n",
    "Learning rate: [0.0004061850569025236]\n",
    "91000/1094375 batches | batch/sec  6.00 | rem mins  2788 | loss 1.37066 | ppl   3.9380\n",
    "Learning rate: [0.00040696632724810544]\n",
    "91200/1094375 batches | batch/sec  6.05 | rem mins  2763 | loss 1.35101 | ppl   3.8613\n",
    "Learning rate: [0.0004077475975936873]\n",
    "91800/1094375 batches | batch/sec  6.02 | rem mins  2777 | loss 1.37790 | ppl   3.9666\n",
    "Learning rate: [0.0004100914086304332]\n",
    "92000/1094375 batches | batch/sec  5.97 | rem mins  2801 | loss 1.36888 | ppl   3.9309\n",
    "Learning rate: [0.00041087267897601507]\n",
    "92200/1094375 batches | batch/sec  6.03 | rem mins  2769 | loss 1.36422 | ppl   3.9127\n",
    "Learning rate: [0.0004116539493215969]\n",
    "92400/1094375 batches | batch/sec  6.03 | rem mins  2769 | loss 1.38625 | ppl   3.9998\n",
    "Learning rate: [0.00041243521966717877]\n",
    "92600/1094375 batches | batch/sec  6.04 | rem mins  2763 | loss 1.34370 | ppl   3.8332\n",
    "Learning rate: [0.0004132164900127608]\n",
    "92800/1094375 batches | batch/sec  6.03 | rem mins  2769 | loss 1.35624 | ppl   3.8816\n",
    "Learning rate: [0.00041399776035834263]\n",
    "93000/1094375 batches | batch/sec  6.05 | rem mins  2760 | loss 1.37139 | ppl   3.9408\n",
    "Learning rate: [0.0004147790307039247]\n",
    "93200/1094375 batches | batch/sec  6.08 | rem mins  2746 | loss 1.31464 | ppl   3.7234\n",
    "Learning rate: [0.0004155603010495065]\n",
    "93400/1094375 batches | batch/sec  6.04 | rem mins  2763 | loss 1.35637 | ppl   3.8821\n",
    "Learning rate: [0.00041634157139508834]\n",
    "93600/1094375 batches | batch/sec  6.06 | rem mins  2751 | loss 1.36740 | ppl   3.9252\n",
    "Learning rate: [0.0004171228417406704]\n",
    "93800/1094375 batches | batch/sec  6.03 | rem mins  2764 | loss 1.36157 | ppl   3.9023\n",
    "Learning rate: [0.00041790411208625226]\n",
    "94000/1094375 batches | batch/sec  6.06 | rem mins  2753 | loss 1.36395 | ppl   3.9116\n",
    "Learning rate: [0.00041868538243183427]\n",
    "94200/1094375 batches | batch/sec  5.99 | rem mins  2781 | loss 1.35555 | ppl   3.8789\n",
    "Learning rate: [0.0004194666527774161]\n",
    "94400/1094375 batches | batch/sec  5.99 | rem mins  2784 | loss 1.34842 | ppl   3.8513\n",
    "Learning rate: [0.00042024792312299797]\n",
    "94600/1094375 batches | batch/sec  6.04 | rem mins  2760 | loss 1.38130 | ppl   3.9801\n",
    "Learning rate: [0.0004210291934685798]\n",
    "94800/1094375 batches | batch/sec  6.06 | rem mins  2748 | loss 1.33212 | ppl   3.7891\n",
    "Learning rate: [0.00042181046381416183]\n",
    "95000/1094375 batches | batch/sec  6.05 | rem mins  2752 | loss 1.33814 | ppl   3.8120\n",
    "Learning rate: [0.0004225917341597437]\n",
    "95200/1094375 batches | batch/sec  6.05 | rem mins  2752 | loss 1.37451 | ppl   3.9532\n",
    "Learning rate: [0.00042337300450532575]\n",
    "95400/1094375 batches | batch/sec  6.03 | rem mins  2759 | loss 1.34230 | ppl   3.8278\n",
    "Learning rate: [0.00042415427485090754]\n",
    "95600/1094375 batches | batch/sec  6.04 | rem mins  2757 | loss 1.38297 | ppl   3.9867\n",
    "Learning rate: [0.0004249355451964894]\n",
    "95800/1094375 batches | batch/sec  5.99 | rem mins  2778 | loss 1.36125 | ppl   3.9011\n",
    "Learning rate: [0.00042571681554207146]\n",
    "96000/1094375 batches | batch/sec  6.04 | rem mins  2754 | loss 1.35338 | ppl   3.8705\n",
    "Learning rate: [0.0004264980858876533]\n",
    "96200/1094375 batches | batch/sec  6.07 | rem mins  2740 | loss 1.36845 | ppl   3.9293\n",
    "Learning rate: [0.0004272793562332353]\n",
    "96400/1094375 batches | batch/sec  6.03 | rem mins  2756 | loss 1.33376 | ppl   3.7953\n",
    "Learning rate: [0.00042806062657881717]\n",
    "96600/1094375 batches | batch/sec  6.01 | rem mins  2765 | loss 1.34238 | ppl   3.8282\n",
    "Learning rate: [0.000428841896924399]\n",
    "96800/1094375 batches | batch/sec  6.05 | rem mins  2750 | loss 1.33279 | ppl   3.7916\n",
    "Learning rate: [0.00042962316726998103]\n",
    "97000/1094375 batches | batch/sec  6.06 | rem mins  2744 | loss 1.35761 | ppl   3.8869\n",
    "Learning rate: [0.0004304044376155629]\n",
    "97200/1094375 batches | batch/sec  5.97 | rem mins  2784 | loss 1.31935 | ppl   3.7410\n",
    "Learning rate: [0.00043118570796114495]\n",
    "97400/1094375 batches | batch/sec  6.02 | rem mins  2761 | loss 1.33586 | ppl   3.8033\n",
    "Learning rate: [0.0004319669783067268]\n",
    "97600/1094375 batches | batch/sec  6.06 | rem mins  2741 | loss 1.35799 | ppl   3.8884\n",
    "Learning rate: [0.00043274824865230865]\n",
    "97800/1094375 batches | batch/sec  6.03 | rem mins  2756 | loss 1.33177 | ppl   3.7878\n",
    "Learning rate: [0.00043352951899789044]\n",
    "98000/1094375 batches | batch/sec  6.05 | rem mins  2747 | loss 1.35041 | ppl   3.8590\n",
    "Learning rate: [0.0004343107893434725]\n",
    "98200/1094375 batches | batch/sec  6.02 | rem mins  2757 | loss 1.35752 | ppl   3.8865\n",
    "Learning rate: [0.00043509205968905436]\n",
    "98400/1094375 batches | batch/sec  6.03 | rem mins  2752 | loss 1.35621 | ppl   3.8814\n",
    "Learning rate: [0.00043587333003463637]\n",
    "98600/1094375 batches | batch/sec  6.05 | rem mins  2741 | loss 1.33973 | ppl   3.8180\n",
    "Learning rate: [0.0004366546003802182]\n",
    "98800/1094375 batches | batch/sec  6.03 | rem mins  2751 | loss 1.33642 | ppl   3.8054\n",
    "Learning rate: [0.00043743587072580007]\n",
    "99000/1094375 batches | batch/sec  6.04 | rem mins  2745 | loss 1.32116 | ppl   3.7478\n",
    "Learning rate: [0.00043821714107138214]\n",
    "99200/1094375 batches | batch/sec  5.99 | rem mins  2768 | loss 1.36793 | ppl   3.9272\n",
    "Learning rate: [0.00043899841141696393]\n",
    "99400/1094375 batches | batch/sec  6.10 | rem mins  2717 | loss 1.32285 | ppl   3.7541\n",
    "Learning rate: [0.000439779681762546]\n",
    "99600/1094375 batches | batch/sec  6.05 | rem mins  2741 | loss 1.32040 | ppl   3.7449\n",
    "Learning rate: [0.00044056095210812785]\n",
    "99800/1094375 batches | batch/sec  6.06 | rem mins  2737 | loss 1.36584 | ppl   3.9190\n",
    "Learning rate: [0.0004413422224537097]\n",
    "100000/1094375 batches | batch/sec  6.06 | rem mins  2734 | loss 1.36244 | ppl   3.9057\n",
    "Learning rate: [0.0004421234927992917]\n",
    "100200/1094375 batches | batch/sec  6.03 | rem mins  2747 | loss 1.34603 | ppl   3.8421\n",
    "Learning rate: [0.00044290476314487356]\n",
    "100400/1094375 batches | batch/sec  6.06 | rem mins  2732 | loss 1.37740 | ppl   3.9646\n",
    "Learning rate: [0.00044368603349045563]\n",
    "100600/1094375 batches | batch/sec  6.05 | rem mins  2740 | loss 1.36465 | ppl   3.9144\n",
    "Learning rate: [0.0004444673038360374]\n",
    "100800/1094375 batches | batch/sec  6.05 | rem mins  2735 | loss 1.32516 | ppl   3.7628\n",
    "Learning rate: [0.0004452485741816193]\n",
    "101000/1094375 batches | batch/sec  6.00 | rem mins  2757 | loss 1.33668 | ppl   3.8064\n",
    "Learning rate: [0.0004460298445272011]\n",
    "101200/1094375 batches | batch/sec  6.04 | rem mins  2740 | loss 1.34216 | ppl   3.8273\n",
    "Learning rate: [0.0004468111148727832]\n",
    "101400/1094375 batches | batch/sec  6.07 | rem mins  2728 | loss 1.35359 | ppl   3.8713\n",
    "Learning rate: [0.000447592385218365]\n",
    "101600/1094375 batches | batch/sec  6.05 | rem mins  2734 | loss 1.32700 | ppl   3.7697\n",
    "Learning rate: [0.00044837365556394705]\n",
    "101800/1094375 batches | batch/sec  6.04 | rem mins  2739 | loss 1.36436 | ppl   3.9132\n",
    "Learning rate: [0.0004491549259095289]\n",
    "102000/1094375 batches | batch/sec  6.06 | rem mins  2730 | loss 1.35243 | ppl   3.8668\n",
    "Learning rate: [0.00044993619625511075]\n",
    "102200/1094375 batches | batch/sec  6.03 | rem mins  2741 | loss 1.32364 | ppl   3.7571\n",
    "Learning rate: [0.00045071746660069276]\n",
    "102400/1094375 batches | batch/sec  6.06 | rem mins  2730 | loss 1.36044 | ppl   3.8979\n",
    "Learning rate: [0.0004514987369462746]\n",
    "103200/1094375 batches | batch/sec  6.03 | rem mins  2739 | loss 1.36450 | ppl   3.9138\n",
    "Learning rate: [0.0004546238183286024]\n",
    "103400/1094375 batches | batch/sec  6.09 | rem mins  2714 | loss 1.35624 | ppl   3.8816\n",
    "Learning rate: [0.00045540508867418424]\n",
    "103600/1094375 batches | batch/sec  6.02 | rem mins  2744 | loss 1.35440 | ppl   3.8744\n",
    "Learning rate: [0.00045618635901976625]\n",
    "103800/1094375 batches | batch/sec  6.02 | rem mins  2743 | loss 1.33585 | ppl   3.8032\n",
    "Learning rate: [0.0004569676293653481]\n",
    "104000/1094375 batches | batch/sec  6.04 | rem mins  2733 | loss 1.34013 | ppl   3.8195\n",
    "Learning rate: [0.00045774889971092995]\n",
    "104200/1094375 batches | batch/sec  6.05 | rem mins  2727 | loss 1.35605 | ppl   3.8808\n",
    "Learning rate: [0.0004585301700565118]\n",
    "104400/1094375 batches | batch/sec  6.05 | rem mins  2726 | loss 1.34855 | ppl   3.8518\n",
    "Learning rate: [0.0004593114404020938]\n",
    "104600/1094375 batches | batch/sec  6.03 | rem mins  2736 | loss 1.31420 | ppl   3.7218\n",
    "Learning rate: [0.00046009271074767567]\n",
    "104800/1094375 batches | batch/sec  6.00 | rem mins  2748 | loss 1.34959 | ppl   3.8558\n",
    "Learning rate: [0.00046087398109325773]\n",
    "105000/1094375 batches | batch/sec  6.02 | rem mins  2737 | loss 1.33710 | ppl   3.8080\n",
    "Learning rate: [0.00046165525143883953]\n",
    "105200/1094375 batches | batch/sec  6.05 | rem mins  2726 | loss 1.34734 | ppl   3.8472\n",
    "Learning rate: [0.0004624365217844214]\n",
    "105400/1094375 batches | batch/sec  6.03 | rem mins  2736 | loss 1.30322 | ppl   3.6811\n",
    "Learning rate: [0.00046321779213000344]\n",
    "105600/1094375 batches | batch/sec  6.01 | rem mins  2744 | loss 1.37004 | ppl   3.9355\n",
    "Learning rate: [0.0004639990624755853]\n",
    "105800/1094375 batches | batch/sec  6.00 | rem mins  2747 | loss 1.35747 | ppl   3.8864\n",
    "Learning rate: [0.0004647803328211673]\n",
    "106000/1094375 batches | batch/sec  6.02 | rem mins  2737 | loss 1.34423 | ppl   3.8352\n",
    "Learning rate: [0.00046556160316674916]\n",
    "106200/1094375 batches | batch/sec  6.06 | rem mins  2717 | loss 1.35608 | ppl   3.8809\n",
    "Learning rate: [0.000466342873512331]\n",
    "106400/1094375 batches | batch/sec  6.05 | rem mins  2723 | loss 1.32348 | ppl   3.7565\n",
    "Learning rate: [0.000467124143857913]\n",
    "106600/1094375 batches | batch/sec  6.08 | rem mins  2709 | loss 1.33417 | ppl   3.7968\n",
    "Learning rate: [0.00046790541420349487]\n",
    "106800/1094375 batches | batch/sec  6.04 | rem mins  2726 | loss 1.34762 | ppl   3.8483\n",
    "Learning rate: [0.00046868668454907693]\n",
    "107000/1094375 batches | batch/sec  6.04 | rem mins  2723 | loss 1.35268 | ppl   3.8678\n",
    "Learning rate: [0.0004694679548946588]\n",
    "107200/1094375 batches | batch/sec  6.05 | rem mins  2721 | loss 1.36089 | ppl   3.8996\n",
    "Learning rate: [0.00047024922524024063]\n",
    "107400/1094375 batches | batch/sec  6.07 | rem mins  2711 | loss 1.30171 | ppl   3.6756\n",
    "Learning rate: [0.00047103049558582243]\n",
    "107600/1094375 batches | batch/sec  6.03 | rem mins  2728 | loss 1.33810 | ppl   3.8118\n",
    "Learning rate: [0.0004718117659314045]\n",
    "107800/1094375 batches | batch/sec  6.05 | rem mins  2719 | loss 1.34534 | ppl   3.8395\n",
    "Learning rate: [0.00047259303627698635]\n",
    "108000/1094375 batches | batch/sec  6.07 | rem mins  2708 | loss 1.32213 | ppl   3.7514\n",
    "Learning rate: [0.00047337430662256836]\n",
    "108200/1094375 batches | batch/sec  6.04 | rem mins  2720 | loss 1.34527 | ppl   3.8392\n",
    "Learning rate: [0.0004741555769681502]\n",
    "108400/1094375 batches | batch/sec  6.03 | rem mins  2724 | loss 1.33926 | ppl   3.8162\n",
    "Learning rate: [0.00047493684731373206]\n",
    "108600/1094375 batches | batch/sec  6.06 | rem mins  2712 | loss 1.33592 | ppl   3.8035\n",
    "Learning rate: [0.0004757181176593141]\n",
    "108800/1094375 batches | batch/sec  6.05 | rem mins  2717 | loss 1.35903 | ppl   3.8924\n",
    "Learning rate: [0.0004764993880048959]\n",
    "109000/1094375 batches | batch/sec  6.01 | rem mins  2733 | loss 1.32616 | ppl   3.7665\n",
    "Learning rate: [0.000477280658350478]\n",
    "109200/1094375 batches | batch/sec  6.02 | rem mins  2728 | loss 1.33668 | ppl   3.8064\n",
    "Learning rate: [0.00047806192869605984]\n",
    "109400/1094375 batches | batch/sec  6.04 | rem mins  2717 | loss 1.31611 | ppl   3.7289\n",
    "Learning rate: [0.0004788431990416417]\n",
    "109600/1094375 batches | batch/sec  6.01 | rem mins  2729 | loss 1.34250 | ppl   3.8286\n",
    "Learning rate: [0.0004796244693872237]\n",
    "109800/1094375 batches | batch/sec  6.02 | rem mins  2726 | loss 1.32646 | ppl   3.7677\n",
    "Learning rate: [0.00048040573973280555]\n",
    "110000/1094375 batches | batch/sec  6.04 | rem mins  2716 | loss 1.29588 | ppl   3.6542\n",
    "Learning rate: [0.0004811870100783876]\n",
    "110200/1094375 batches | batch/sec  6.01 | rem mins  2728 | loss 1.33594 | ppl   3.8036\n",
    "Learning rate: [0.0004819682804239694]\n",
    "110400/1094375 batches | batch/sec  6.02 | rem mins  2723 | loss 1.32017 | ppl   3.7441\n",
    "Learning rate: [0.00048274955076955126]\n",
    "110600/1094375 batches | batch/sec  6.07 | rem mins  2703 | loss 1.31571 | ppl   3.7274\n",
    "Learning rate: [0.0004835308211151331]\n",
    "110800/1094375 batches | batch/sec  6.02 | rem mins  2723 | loss 1.31562 | ppl   3.7270\n",
    "Learning rate: [0.0004843120914607152]\n",
    "111000/1094375 batches | batch/sec  5.99 | rem mins  2734 | loss 1.31247 | ppl   3.7153\n",
    "Learning rate: [0.00048509336180629697]\n",
    "111200/1094375 batches | batch/sec  6.02 | rem mins  2721 | loss 1.28981 | ppl   3.6321\n",
    "Learning rate: [0.00048587463215187904]\n",
    "111400/1094375 batches | batch/sec  6.08 | rem mins  2696 | loss 1.33943 | ppl   3.8169\n",
    "Learning rate: [0.0004866559024974609]\n",
    "111600/1094375 batches | batch/sec  6.05 | rem mins  2707 | loss 1.31638 | ppl   3.7299\n",
    "Learning rate: [0.00048743717284304274]\n",
    "111800/1094375 batches | batch/sec  6.08 | rem mins  2694 | loss 1.34898 | ppl   3.8535\n",
    "Learning rate: [0.00048821844318862475]\n",
    "112000/1094375 batches | batch/sec  6.05 | rem mins  2708 | loss 1.28624 | ppl   3.6192\n",
    "Learning rate: [0.0004889997135342066]\n",
    "112200/1094375 batches | batch/sec  6.08 | rem mins  2692 | loss 1.33797 | ppl   3.8113\n",
    "Learning rate: [0.0004897809838797886]\n",
    "112400/1094375 batches | batch/sec  6.07 | rem mins  2697 | loss 1.32230 | ppl   3.7520\n",
    "Learning rate: [0.0004905622542253704]\n",
    "113200/1094375 batches | batch/sec  6.03 | rem mins  2711 | loss 1.34691 | ppl   3.8455\n",
    "Learning rate: [0.0004936873356076982]\n",
    "113400/1094375 batches | batch/sec  6.00 | rem mins  2723 | loss 1.29485 | ppl   3.6504\n",
    "Learning rate: [0.00049446860595328]\n",
    "113600/1094375 batches | batch/sec  6.04 | rem mins  2707 | loss 1.33439 | ppl   3.7977\n",
    "Learning rate: [0.0004952498762988619]\n",
    "113800/1094375 batches | batch/sec  6.04 | rem mins  2705 | loss 1.32565 | ppl   3.7646\n",
    "Learning rate: [0.0004960311466444437]\n",
    "114000/1094375 batches | batch/sec  5.99 | rem mins  2727 | loss 1.28556 | ppl   3.6167\n",
    "Learning rate: [0.0004968124169900257]\n",
    "114200/1094375 batches | batch/sec  6.05 | rem mins  2702 | loss 1.33661 | ppl   3.8061\n",
    "Learning rate: [0.0004975936873356077]\n",
    "114400/1094375 batches | batch/sec  6.02 | rem mins  2713 | loss 1.31814 | ppl   3.7365\n",
    "Learning rate: [0.0004983749576811897]\n",
    "114600/1094375 batches | batch/sec  6.02 | rem mins  2712 | loss 1.32433 | ppl   3.7597\n",
    "Learning rate: [0.0004991562280267716]\n",
    "114800/1094375 batches | batch/sec  6.05 | rem mins  2698 | loss 1.31899 | ppl   3.7396\n",
    "Learning rate: [0.0004999374983723534]\n",
    "115000/1094375 batches | batch/sec  6.04 | rem mins  2704 | loss 1.33055 | ppl   3.7831\n",
    "Learning rate: [0.0004992812312820648]\n",
    "115200/1094375 batches | batch/sec  6.02 | rem mins  2712 | loss 1.33256 | ppl   3.7907\n",
    "Learning rate: [0.0004984999609364827]\n",
    "115400/1094375 batches | batch/sec  5.99 | rem mins  2723 | loss 1.29328 | ppl   3.6447\n",
    "Learning rate: [0.0004977186905909007]\n",
    "115600/1094375 batches | batch/sec  6.03 | rem mins  2707 | loss 1.29910 | ppl   3.6660\n",
    "Learning rate: [0.0004969374202453188]\n",
    "115800/1094375 batches | batch/sec  6.03 | rem mins  2706 | loss 1.28948 | ppl   3.6309\n",
    "Learning rate: [0.000496156149899737]\n",
    "116000/1094375 batches | batch/sec  6.03 | rem mins  2704 | loss 1.32181 | ppl   3.7502\n",
    "Learning rate: [0.0004953748795541551]\n",
    "116200/1094375 batches | batch/sec  6.03 | rem mins  2706 | loss 1.32704 | ppl   3.7699\n",
    "Learning rate: [0.0004945936092085731]\n",
    "116400/1094375 batches | batch/sec  6.07 | rem mins  2686 | loss 1.31903 | ppl   3.7398\n",
    "Learning rate: [0.0004938123388629911]\n",
    "116600/1094375 batches | batch/sec  6.09 | rem mins  2678 | loss 1.31553 | ppl   3.7267\n",
    "Learning rate: [0.0004930310685174092]\n",
    "116800/1094375 batches | batch/sec  6.02 | rem mins  2708 | loss 1.31181 | ppl   3.7129\n",
    "Learning rate: [0.0004922497981718274]\n",
    "117000/1094375 batches | batch/sec  5.99 | rem mins  2718 | loss 1.30431 | ppl   3.6851\n",
    "Learning rate: [0.0004914685278262456]\n",
    "117200/1094375 batches | batch/sec  6.04 | rem mins  2696 | loss 1.29814 | ppl   3.6625\n",
    "Learning rate: [0.0004906872574806635]\n",
    "117400/1094375 batches | batch/sec  6.09 | rem mins  2672 | loss 1.34084 | ppl   3.8223\n",
    "Learning rate: [0.0004899059871350817]\n",
    "117600/1094375 batches | batch/sec  6.01 | rem mins  2709 | loss 1.30508 | ppl   3.6880\n",
    "Learning rate: [0.0004891247167894997]\n",
    "117800/1094375 batches | batch/sec  6.05 | rem mins  2691 | loss 1.32906 | ppl   3.7775\n",
    "Learning rate: [0.0004883434464439178]\n",
    "118000/1094375 batches | batch/sec  6.06 | rem mins  2687 | loss 1.29631 | ppl   3.6558\n",
    "Learning rate: [0.000487562176098336]\n",
    "118200/1094375 batches | batch/sec  6.10 | rem mins  2667 | loss 1.31953 | ppl   3.7416\n",
    "Learning rate: [0.00048678090575275413]\n",
    "118400/1094375 batches | batch/sec  6.05 | rem mins  2691 | loss 1.32078 | ppl   3.7464\n",
    "Learning rate: [0.0004859996354071721]\n",
    "118600/1094375 batches | batch/sec  6.05 | rem mins  2690 | loss 1.30752 | ppl   3.6970\n",
    "Learning rate: [0.00048521836506159005]\n",
    "118800/1094375 batches | batch/sec  6.09 | rem mins  2668 | loss 1.31589 | ppl   3.7281\n",
    "Learning rate: [0.0004844370947160082]\n",
    "119000/1094375 batches | batch/sec  6.05 | rem mins  2688 | loss 1.30927 | ppl   3.7035\n",
    "Learning rate: [0.00048365582437042635]\n",
    "119200/1094375 batches | batch/sec  6.06 | rem mins  2681 | loss 1.31163 | ppl   3.7122\n",
    "Learning rate: [0.0004828745540248445]\n",
    "119400/1094375 batches | batch/sec  6.07 | rem mins  2678 | loss 1.31326 | ppl   3.7183\n",
    "Learning rate: [0.0004820932836792625]\n",
    "119600/1094375 batches | batch/sec  6.07 | rem mins  2678 | loss 1.33046 | ppl   3.7828\n",
    "Learning rate: [0.0004813120133336804]\n",
    "119800/1094375 batches | batch/sec  6.05 | rem mins  2683 | loss 1.31516 | ppl   3.7254\n",
    "Learning rate: [0.0004805307429880986]\n",
    "120000/1094375 batches | batch/sec  6.08 | rem mins  2671 | loss 1.33422 | ppl   3.7970\n",
    "Learning rate: [0.0004797494726425168]\n",
    "120200/1094375 batches | batch/sec  6.08 | rem mins  2672 | loss 1.30889 | ppl   3.7021\n",
    "Learning rate: [0.0004789682022969349]\n",
    "120400/1094375 batches | batch/sec  6.11 | rem mins  2657 | loss 1.30320 | ppl   3.6811\n",
    "Learning rate: [0.00047818693195135286]\n",
    "120600/1094375 batches | batch/sec  6.08 | rem mins  2669 | loss 1.32176 | ppl   3.7500\n",
    "Learning rate: [0.000477405661605771]\n",
    "120800/1094375 batches | batch/sec  6.08 | rem mins  2670 | loss 1.33079 | ppl   3.7840\n",
    "Learning rate: [0.000476624391260189]\n",
    "121000/1094375 batches | batch/sec  6.04 | rem mins  2688 | loss 1.29075 | ppl   3.6355\n",
    "Learning rate: [0.00047584312091460715]\n",
    "121200/1094375 batches | batch/sec  6.05 | rem mins  2681 | loss 1.32834 | ppl   3.7748\n",
    "Learning rate: [0.0004750618505690253]\n",
    "121400/1094375 batches | batch/sec  6.07 | rem mins  2673 | loss 1.31058 | ppl   3.7083\n",
    "Learning rate: [0.00047428058022344345]\n",
    "121600/1094375 batches | batch/sec  6.03 | rem mins  2687 | loss 1.31190 | ppl   3.7132\n",
    "Learning rate: [0.00047349930987786144]\n",
    "121800/1094375 batches | batch/sec  6.04 | rem mins  2684 | loss 1.32137 | ppl   3.7486\n",
    "Learning rate: [0.00047271803953227937]\n",
    "122000/1094375 batches | batch/sec  6.05 | rem mins  2680 | loss 1.33312 | ppl   3.7929\n",
    "Learning rate: [0.0004719367691866975]\n",
    "122200/1094375 batches | batch/sec  6.08 | rem mins  2666 | loss 1.29651 | ppl   3.6565\n",
    "Learning rate: [0.0004711554988411157]\n",
    "122400/1094375 batches | batch/sec  6.09 | rem mins  2658 | loss 1.30531 | ppl   3.6888\n",
    "Learning rate: [0.0004703742284955339]\n",
    "122600/1094375 batches | batch/sec  6.07 | rem mins  2668 | loss 1.32608 | ppl   3.7663\n",
    "Learning rate: [0.0004695929581499518]\n",
    "122800/1094375 batches | batch/sec  6.08 | rem mins  2662 | loss 1.28172 | ppl   3.6028\n",
    "Learning rate: [0.0004688116878043698]\n",
    "123000/1094375 batches | batch/sec  6.07 | rem mins  2668 | loss 1.29696 | ppl   3.6582\n",
    "Learning rate: [0.00046803041745878795]\n",
    "123200/1094375 batches | batch/sec  6.07 | rem mins  2664 | loss 1.32871 | ppl   3.7762\n",
    "Learning rate: [0.0004672491471132061]\n",
    "123400/1094375 batches | batch/sec  6.02 | rem mins  2687 | loss 1.31404 | ppl   3.7212\n",
    "Learning rate: [0.00046646787676762425]\n",
    "123600/1094375 batches | batch/sec  6.07 | rem mins  2667 | loss 1.31218 | ppl   3.7142\n",
    "Learning rate: [0.00046568660642204223]\n",
    "123800/1094375 batches | batch/sec  6.06 | rem mins  2671 | loss 1.30381 | ppl   3.6833\n",
    "Learning rate: [0.0004649053360764604]\n",
    "124000/1094375 batches | batch/sec  6.04 | rem mins  2676 | loss 1.28476 | ppl   3.6138\n",
    "Learning rate: [0.0004641240657308783]\n",
    "124200/1094375 batches | batch/sec  6.05 | rem mins  2672 | loss 1.33236 | ppl   3.7900\n",
    "Learning rate: [0.00046334279538529647]\n",
    "124400/1094375 batches | batch/sec  6.02 | rem mins  2686 | loss 1.29357 | ppl   3.6458\n",
    "Learning rate: [0.00046256152503971467]\n",
    "124600/1094375 batches | batch/sec  6.05 | rem mins  2673 | loss 1.27788 | ppl   3.5890\n",
    "Learning rate: [0.0004617802546941328]\n",
    "124800/1094375 batches | batch/sec  6.04 | rem mins  2675 | loss 1.30145 | ppl   3.6746\n",
    "Learning rate: [0.00046099898434855076]\n",
    "125000/1094375 batches | batch/sec  6.01 | rem mins  2688 | loss 1.30764 | ppl   3.6974\n",
    "Learning rate: [0.00046021771400296874]\n",
    "125200/1094375 batches | batch/sec  6.00 | rem mins  2692 | loss 1.28050 | ppl   3.5985\n",
    "Learning rate: [0.0004594364436573869]\n",
    "125400/1094375 batches | batch/sec  5.99 | rem mins  2695 | loss 1.30861 | ppl   3.7010\n",
    "Learning rate: [0.00045865517331180504]\n",
    "125600/1094375 batches | batch/sec  6.04 | rem mins  2673 | loss 1.25285 | ppl   3.5003\n",
    "Learning rate: [0.0004578739029662232]\n",
    "125800/1094375 batches | batch/sec  6.03 | rem mins  2679 | loss 1.30937 | ppl   3.7038\n",
    "Learning rate: [0.0004570926326206412]\n",
    "126000/1094375 batches | batch/sec  6.05 | rem mins  2668 | loss 1.29017 | ppl   3.6334\n",
    "Learning rate: [0.0004563113622750591]\n",
    "126200/1094375 batches | batch/sec  6.06 | rem mins  2665 | loss 1.30067 | ppl   3.6718\n",
    "Learning rate: [0.00045553009192947727]\n",
    "126400/1094375 batches | batch/sec  6.01 | rem mins  2682 | loss 1.28942 | ppl   3.6307\n",
    "Learning rate: [0.0004547488215838954]\n",
    "126600/1094375 batches | batch/sec  6.01 | rem mins  2683 | loss 1.31036 | ppl   3.7075\n",
    "Learning rate: [0.0004539675512383136]\n",
    "126800/1094375 batches | batch/sec  6.02 | rem mins  2677 | loss 1.30475 | ppl   3.6868\n",
    "Learning rate: [0.00045318628089273155]\n",
    "127000/1094375 batches | batch/sec  6.03 | rem mins  2675 | loss 1.27974 | ppl   3.5957\n",
    "Learning rate: [0.0004524050105471497]\n",
    "127200/1094375 batches | batch/sec  6.01 | rem mins  2680 | loss 1.26970 | ppl   3.5598\n",
    "Learning rate: [0.0004516237402015677]\n",
    "127400/1094375 batches | batch/sec  6.06 | rem mins  2658 | loss 1.31493 | ppl   3.7245\n",
    "Learning rate: [0.00045084246985598584]\n",
    "127600/1094375 batches | batch/sec  6.01 | rem mins  2679 | loss 1.28442 | ppl   3.6126\n",
    "Learning rate: [0.000450061199510404]\n",
    "127800/1094375 batches | batch/sec  6.04 | rem mins  2666 | loss 1.28636 | ppl   3.6196\n",
    "Learning rate: [0.00044927992916482214]\n",
    "128000/1094375 batches | batch/sec  6.02 | rem mins  2676 | loss 1.27229 | ppl   3.5690\n",
    "Learning rate: [0.00044849865881924013]\n",
    "128200/1094375 batches | batch/sec  6.02 | rem mins  2673 | loss 1.28044 | ppl   3.5982\n",
    "Learning rate: [0.00044771738847365806]\n",
    "128400/1094375 batches | batch/sec  5.99 | rem mins  2686 | loss 1.29075 | ppl   3.6355\n",
    "Learning rate: [0.0004469361181280762]\n",
    "128600/1094375 batches | batch/sec  6.04 | rem mins  2664 | loss 1.27865 | ppl   3.5918\n",
    "Learning rate: [0.00044615484778249436]\n",
    "128800/1094375 batches | batch/sec  6.02 | rem mins  2674 | loss 1.27739 | ppl   3.5872\n",
    "Learning rate: [0.0004453735774369125]\n",
    "129000/1094375 batches | batch/sec  6.03 | rem mins  2670 | loss 1.31743 | ppl   3.7338\n",
    "Learning rate: [0.0004445923070913305]\n",
    "129200/1094375 batches | batch/sec  6.00 | rem mins  2679 | loss 1.27413 | ppl   3.5756\n",
    "Learning rate: [0.00044381103674574844]\n",
    "129400/1094375 batches | batch/sec  6.04 | rem mins  2665 | loss 1.31529 | ppl   3.7258\n",
    "Learning rate: [0.00044302976640016664]\n",
    "129600/1094375 batches | batch/sec  6.02 | rem mins  2673 | loss 1.31381 | ppl   3.7203\n",
    "Learning rate: [0.0004422484960545848]\n",
    "129800/1094375 batches | batch/sec  6.02 | rem mins  2671 | loss 1.29744 | ppl   3.6599\n",
    "Learning rate: [0.00044146722570900294]\n",
    "130000/1094375 batches | batch/sec  6.06 | rem mins  2654 | loss 1.28072 | ppl   3.5992\n",
    "Learning rate: [0.0004406859553634209]\n",
    "130200/1094375 batches | batch/sec  6.01 | rem mins  2674 | loss 1.27558 | ppl   3.5808\n",
    "Learning rate: [0.000439904685017839]\n",
    "130400/1094375 batches | batch/sec  6.01 | rem mins  2674 | loss 1.29326 | ppl   3.6447\n",
    "Learning rate: [0.000439123414672257]\n",
    "130600/1094375 batches | batch/sec  6.03 | rem mins  2662 | loss 1.29943 | ppl   3.6672\n",
    "Learning rate: [0.00043834214432667516]\n",
    "130800/1094375 batches | batch/sec  6.02 | rem mins  2669 | loss 1.28463 | ppl   3.6133\n",
    "Learning rate: [0.0004375608739810933]\n",
    "131000/1094375 batches | batch/sec  6.09 | rem mins  2638 | loss 1.30302 | ppl   3.6804\n",
    "Learning rate: [0.00043677960363551146]\n",
    "131200/1094375 batches | batch/sec  6.08 | rem mins  2642 | loss 1.30448 | ppl   3.6858\n",
    "Learning rate: [0.00043599833328992945]\n",
    "131400/1094375 batches | batch/sec  6.06 | rem mins  2647 | loss 1.29550 | ppl   3.6528\n",
    "Learning rate: [0.0004352170629443474]\n",
    "131600/1094375 batches | batch/sec  6.09 | rem mins  2636 | loss 1.29335 | ppl   3.6450\n",
    "Learning rate: [0.00043443579259876553]\n",
    "\n",
    "\n",
    "\"\"\".split('\\n')\n",
    "\n",
    "losses, learning_rates = parse_loss(training_log_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2756658-ba27-4d19-90d9-87e3f3b397d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.20951    2.20269333 2.16893333 2.16252667 2.13974    2.16424\n",
      " 2.15422333 2.15814    2.1304     2.10987333 2.09359    2.09718333\n",
      " 2.09736333 2.10379    2.09570333 2.09435667 2.08235667 2.06941\n",
      " 2.05763333 2.05068333 2.03655333 2.03201333 2.0336     2.04843333\n",
      " 2.05640333 2.04129333 2.02204333 2.00493    1.99846333 1.98547333\n",
      " 1.99078333 1.98643    1.99688667 1.97727    1.99884    1.99429667\n",
      " 1.98803    1.96652    1.97346    1.98687    1.98537333 1.97921\n",
      " 1.96928667 1.96891333 1.94002667 1.93540667 1.9139     1.92240667\n",
      " 1.91953333 1.91285333 1.92685333 1.91215    1.92429    1.91882667\n",
      " 1.92283333 1.91847333 1.91235    1.90208333 1.89562667 1.87975667\n",
      " 1.87707    1.85658    1.85345333 1.86282667 1.87816667 1.88154667\n",
      " 1.87062667 1.86553333 1.86914    1.87746    1.88490667 1.86872\n",
      " 1.85313667 1.84475667 1.85570333 1.84695333 1.8392     1.82482333\n",
      " 1.83360333 1.82009667 1.81201    1.80305333 1.81801333 1.82775333\n",
      " 1.81565    1.80905    1.79078667 1.78721667 1.78516667 1.79076667\n",
      " 1.79561333 1.78175    1.78695333 1.78449    1.78266    1.77251667\n",
      " 1.77244    1.78128    1.78486    1.78752    1.77360333 1.75185667\n",
      " 1.73389333 1.74091    1.74674    1.74383    1.71752333 1.71339667\n",
      " 1.70979333 1.72374    1.71663667 1.72401667 1.70814333 1.70449\n",
      " 1.69087667 1.70444    1.70060667 1.71424667 1.70642667 1.72196333\n",
      " 1.71421667 1.71738    1.70328667 1.69505    1.69641    1.68649\n",
      " 1.69157667 1.68991    1.69866    1.69110667 1.68893667 1.68283333\n",
      " 1.69269667 1.68043    1.66747    1.64043    1.65036333 1.66711\n",
      " 1.68136    1.66182    1.65056333 1.64109667 1.64864333 1.65932\n",
      " 1.66632    1.67210333 1.66530667 1.65482333 1.65556    1.64532333\n",
      " 1.63861    1.62222    1.63185667 1.64048    1.63787333 1.62571\n",
      " 1.61881    1.62107333 1.62769    1.6406     1.64512667 1.64548333\n",
      " 1.63609333 1.62835    1.62845667 1.61858333 1.62211667 1.62547333\n",
      " 1.62486333 1.61281667 1.61076    1.62174667 1.63246667 1.62062333\n",
      " 1.62408    1.62061333 1.61991667 1.61413667 1.60312667 1.60571333\n",
      " 1.59142667 1.59749333 1.59260667 1.59864667 1.59596333 1.5973\n",
      " 1.58621    1.57454667 1.58147    1.59610667 1.60322667 1.58251333\n",
      " 1.57434333 1.56699667 1.57558667 1.57343333 1.59172667 1.59706333\n",
      " 1.60127667 1.57106333 1.56408667 1.54473667 1.55797667 1.54988333\n",
      " 1.55288333 1.55054333 1.55784333 1.56204667 1.56045667 1.54493\n",
      " 1.52373667 1.51563333 1.52901    1.56983    1.58160333 1.58267667\n",
      " 1.54646    1.54528    1.5397     1.56482    1.57163    1.57137667\n",
      " 1.56004667 1.53771    1.5392     1.53347667 1.54310667 1.52033333\n",
      " 1.53597667 1.53615333 1.54835333 1.53088667 1.52001667 1.52087\n",
      " 1.52100667 1.52224333 1.51544    1.51139333 1.50962333 1.51464\n",
      " 1.51433    1.50742    1.50527667 1.4991     1.50991333 1.51477667\n",
      " 1.51824667 1.52318667 1.52005333 1.52815667 1.53556667 1.52235\n",
      " 1.52007667 1.50819667 1.51747667 1.52120667 1.50321667 1.49208333\n",
      " 1.48262333 1.49283333 1.50894333 1.50816333 1.51410333 1.51183333\n",
      " 1.50518667 1.50896    1.49576    1.49107    1.48502667 1.49094667\n",
      " 1.48947333 1.49066    1.48653333 1.49625333 1.48629    1.48223\n",
      " 1.46854    1.47136    1.47617    1.47845    1.46327667 1.46269667\n",
      " 1.47110333 1.48745667 1.49444333 1.49142333 1.50071333 1.48363333\n",
      " 1.48215667 1.45021333 1.44243333 1.44301333 1.46544333 1.47272667\n",
      " 1.46629    1.45659333 1.46698667 1.47602667 1.46706667 1.47554\n",
      " 1.46606    1.46230333 1.44617333 1.44258    1.46005    1.46359667\n",
      " 1.47183    1.44933667 1.44395333 1.43433667 1.45524    1.45288\n",
      " 1.45769667 1.44486    1.43704    1.44016667 1.44250333 1.44972667\n",
      " 1.45715333 1.46126    1.46471333 1.45118667 1.44134667 1.44411333\n",
      " 1.44086667 1.43449667 1.41604    1.41184    1.4253     1.43551\n",
      " 1.44394667 1.45701333 1.44805    1.45407667 1.43922    1.43786667\n",
      " 1.42731    1.41475333 1.42525667 1.42418333 1.4338     1.42123333\n",
      " 1.41777333 1.42189667 1.42727667 1.43485667 1.42104333 1.42739333\n",
      " 1.41996667 1.40916    1.39113667 1.39957333 1.40533    1.42109333\n",
      " 1.42129667 1.43264    1.43690667 1.43292    1.43847    1.42802333\n",
      " 1.42469    1.42802667 1.42374    1.41464    1.40544667 1.41337333\n",
      " 1.41689333 1.42214667 1.41688333 1.41309333 1.40088667 1.40448667\n",
      " 1.41382667 1.40280333 1.39701667 1.38925667 1.39921333 1.39311667\n",
      " 1.402      1.40509333 1.41164    1.41011    1.42453667 1.42563\n",
      " 1.42124667 1.40844667 1.40571333 1.40113333 1.38819333 1.38741667\n",
      " 1.39325    1.40468667 1.40631333 1.38545333 1.38071    1.37127667\n",
      " 1.38013333 1.38850333 1.38286    1.38232333 1.37611667 1.37541333\n",
      " 1.38450667 1.38382667 1.38733333 1.38907    1.38670333 1.38312333\n",
      " 1.36765    1.36796    1.3712     1.38363    1.38139667 1.39257667\n",
      " 1.38873    1.39254667 1.39321667 1.39058333 1.38686333 1.37912\n",
      " 1.37447333 1.37639333 1.38473333 1.3795     1.37147667 1.36394\n",
      " 1.36934667 1.37797    1.37808667 1.38873    1.37679333 1.37235333\n",
      " 1.36298    1.36937667 1.36373333 1.35138333 1.35048333 1.35079\n",
      " 1.36652333 1.36593    1.37033333 1.37311667 1.36472333 1.36206333\n",
      " 1.35711    1.34742333 1.34746667 1.34613667 1.36178    1.36430667\n",
      " 1.36035667 1.35597333 1.36175667 1.35394667 1.35052    1.34825667\n",
      " 1.35165    1.36659333 1.36217333 1.36586667 1.36102667 1.35186333\n",
      " 1.34819667 1.33631    1.34426    1.33658333 1.33760667 1.33773333\n",
      " 1.34187333 1.34672333 1.34656667 1.35471333 1.35115333 1.34412\n",
      " 1.33243667 1.34183667 1.33731333 1.33706    1.33636333 1.34956\n",
      " 1.35810333 1.36195667 1.36269333 1.35573667 1.34216333 1.33466667\n",
      " 1.34414333 1.34091667 1.34831667 1.34793    1.34681    1.34550333\n",
      " 1.34952667 1.36039333 1.35838    1.34883    1.34346    1.34401\n",
      " 1.34824333 1.3396     1.33744667 1.33363    1.34467667 1.32922\n",
      " 1.3402     1.34357667 1.35724667 1.35259333 1.34126333 1.33791\n",
      " 1.33509    1.34482333 1.35373    1.33842667 1.33356667 1.32838333\n",
      " 1.33519    1.33758    1.33555333 1.34015    1.34473667 1.34037\n",
      " 1.34062333 1.32631667 1.33176333 1.32835667 1.32161333 1.31942667\n",
      " 1.31733    1.32394    1.31716667 1.3146     1.30596667 1.31390333\n",
      " 1.31520667 1.33493    1.3172     1.32439667 1.31550333 1.33572667\n",
      " 1.32135333 1.32538333 1.31829667 1.3152     1.31594    1.31343667\n",
      " 1.32636    1.32048667 1.32462333 1.32736667 1.31879667 1.30831333\n",
      " 1.29395333 1.30346333 1.31277667 1.32262667 1.32053333 1.31545667\n",
      " 1.31055    1.30475333 1.31443    1.31468667 1.32499333 1.31015\n",
      " 1.31496667 1.31220667 1.31594333 1.31473    1.31089333 1.31226333\n",
      " 1.31138667 1.31845    1.31962667 1.32661333 1.31942333 1.31543667\n",
      " 1.31128333 1.31858333 1.31443333 1.31662667 1.30989    1.31694\n",
      " 1.31461667 1.32213    1.317      1.31164667 1.3093     1.30437\n",
      " 1.30158667 1.30246333 1.31323667 1.31831    1.31001    1.30025\n",
      " 1.30697667 1.30356333 1.30127    1.29096667 1.29565667 1.29653\n",
      " 1.29891667 1.28065333 1.29027667 1.28413    1.30007    1.29342\n",
      " 1.30015    1.30151    1.29828333 1.28473    1.28812333 1.28968333\n",
      " 1.29523667 1.28102333 1.27969667 1.28116    1.28328    1.28226333\n",
      " 1.29115667 1.28965    1.30228333 1.30107667 1.30884667 1.29732333\n",
      " 1.28458    1.28318667 1.28942333 1.29244    1.29569333 1.29737667\n",
      " 1.301      1.29777667]\n",
      "[5.30508607e-05 5.38321310e-05 5.46134014e-05 5.53946717e-05\n",
      " 5.61759421e-05 5.69572124e-05 5.77384828e-05 5.85197531e-05\n",
      " 5.93010235e-05 6.00822938e-05 6.08635642e-05 6.16448345e-05\n",
      " 6.24261048e-05 6.32073752e-05 6.39886455e-05 6.47699159e-05\n",
      " 6.55511862e-05 6.68533035e-05 6.81554207e-05 6.94575380e-05\n",
      " 7.02388083e-05 7.10200786e-05 7.18013490e-05 7.25826193e-05\n",
      " 7.33638897e-05 7.41451600e-05 7.49264304e-05 7.57077007e-05\n",
      " 7.64889711e-05 7.72702414e-05 7.80515118e-05 7.88327821e-05\n",
      " 7.96140524e-05 8.03953228e-05 8.11765931e-05 8.19578635e-05\n",
      " 8.27391338e-05 8.35204042e-05 8.43016745e-05 8.50829449e-05\n",
      " 8.58642152e-05 8.66454856e-05 8.74267559e-05 8.82080263e-05\n",
      " 8.89892966e-05 8.97705669e-05 9.05518373e-05 9.13331076e-05\n",
      " 9.21143780e-05 9.28956483e-05 9.36769187e-05 9.44581890e-05\n",
      " 9.52394594e-05 9.60207297e-05 9.68020001e-05 9.75832704e-05\n",
      " 9.83645407e-05 9.91458111e-05 9.99270814e-05 1.00708352e-04\n",
      " 1.01489622e-04 1.02270892e-04 1.03052163e-04 1.03833433e-04\n",
      " 1.04614704e-04 1.05395974e-04 1.06177244e-04 1.06958515e-04\n",
      " 1.07739785e-04 1.08521055e-04 1.09302326e-04 1.10604443e-04\n",
      " 1.11906560e-04 1.13208677e-04 1.13989948e-04 1.14771218e-04\n",
      " 1.15552488e-04 1.16333759e-04 1.17115029e-04 1.17896299e-04\n",
      " 1.18677570e-04 1.19458840e-04 1.20240110e-04 1.21021381e-04\n",
      " 1.21802651e-04 1.22583921e-04 1.23365192e-04 1.24146462e-04\n",
      " 1.24927732e-04 1.25709003e-04 1.26490273e-04 1.27271544e-04\n",
      " 1.28052814e-04 1.28834084e-04 1.29615355e-04 1.30396625e-04\n",
      " 1.31177895e-04 1.31959166e-04 1.32740436e-04 1.33521706e-04\n",
      " 1.34823824e-04 1.36125941e-04 1.37428058e-04 1.38209328e-04\n",
      " 1.38990599e-04 1.39771869e-04 1.40553139e-04 1.41334410e-04\n",
      " 1.42115680e-04 1.42896950e-04 1.43678221e-04 1.44459491e-04\n",
      " 1.45240761e-04 1.46022032e-04 1.46803302e-04 1.47584573e-04\n",
      " 1.48365843e-04 1.49147113e-04 1.49928384e-04 1.50709654e-04\n",
      " 1.51490924e-04 1.52272195e-04 1.53053465e-04 1.53834735e-04\n",
      " 1.54616006e-04 1.55397276e-04 1.56178546e-04 1.57480664e-04\n",
      " 1.58782781e-04 1.60084898e-04 1.60866168e-04 1.61647439e-04\n",
      " 1.62428709e-04 1.63209979e-04 1.63991250e-04 1.64772520e-04\n",
      " 1.65553790e-04 1.66335061e-04 1.67116331e-04 1.67897602e-04\n",
      " 1.68678872e-04 1.69460142e-04 1.70241413e-04 1.71022683e-04\n",
      " 1.71803953e-04 1.72585224e-04 1.73366494e-04 1.74147764e-04\n",
      " 1.74929035e-04 1.75710305e-04 1.76491575e-04 1.77272846e-04\n",
      " 1.78054116e-04 1.78835386e-04 1.79616657e-04 1.80397927e-04\n",
      " 1.81179197e-04 1.81960468e-04 1.82741738e-04 1.83523008e-04\n",
      " 1.84304279e-04 1.85085549e-04 1.85866819e-04 1.86648090e-04\n",
      " 1.87429360e-04 1.88210630e-04 1.88991901e-04 1.89773171e-04\n",
      " 1.90554442e-04 1.91335712e-04 1.92116982e-04 1.92898253e-04\n",
      " 1.93679523e-04 1.94460793e-04 1.95242064e-04 1.96023334e-04\n",
      " 1.96804604e-04 1.97585875e-04 1.98367145e-04 1.99148415e-04\n",
      " 1.99929686e-04 2.00710956e-04 2.01492226e-04 2.02273497e-04\n",
      " 2.03054767e-04 2.03836037e-04 2.04617308e-04 2.05398578e-04\n",
      " 2.06179848e-04 2.06961119e-04 2.07742389e-04 2.08523659e-04\n",
      " 2.09304930e-04 2.10086200e-04 2.10867471e-04 2.11648741e-04\n",
      " 2.12430011e-04 2.13211282e-04 2.13992552e-04 2.14773822e-04\n",
      " 2.15555093e-04 2.16336363e-04 2.17117633e-04 2.17898904e-04\n",
      " 2.18680174e-04 2.19461444e-04 2.20242715e-04 2.21023985e-04\n",
      " 2.21805255e-04 2.22586526e-04 2.23367796e-04 2.24149066e-04\n",
      " 2.24930337e-04 2.25711607e-04 2.26492877e-04 2.27274148e-04\n",
      " 2.28055418e-04 2.28836688e-04 2.29617959e-04 2.30399229e-04\n",
      " 2.31180499e-04 2.31961770e-04 2.32743040e-04 2.33524311e-04\n",
      " 2.34305581e-04 2.35086851e-04 2.35868122e-04 2.36649392e-04\n",
      " 2.37430662e-04 2.38211933e-04 2.38993203e-04 2.39774473e-04\n",
      " 2.40555744e-04 2.41337014e-04 2.42118284e-04 2.42899555e-04\n",
      " 2.43680825e-04 2.44462095e-04 2.45243366e-04 2.46024636e-04\n",
      " 2.46805906e-04 2.47587177e-04 2.48368447e-04 2.49149717e-04\n",
      " 2.49930988e-04 2.50712258e-04 2.51493528e-04 2.52274799e-04\n",
      " 2.53056069e-04 2.53837340e-04 2.54618610e-04 2.55399880e-04\n",
      " 2.56181151e-04 2.56962421e-04 2.57743691e-04 2.58524962e-04\n",
      " 2.59306232e-04 2.60087502e-04 2.60868773e-04 2.61650043e-04\n",
      " 2.62431313e-04 2.63212584e-04 2.63993854e-04 2.64775124e-04\n",
      " 2.65556395e-04 2.66337665e-04 2.67118935e-04 2.67900206e-04\n",
      " 2.68681476e-04 2.69462746e-04 2.70244017e-04 2.71025287e-04\n",
      " 2.71806557e-04 2.72587828e-04 2.73369098e-04 2.74150368e-04\n",
      " 2.74931639e-04 2.75712909e-04 2.76494180e-04 2.77275450e-04\n",
      " 2.78056720e-04 2.78837991e-04 2.79619261e-04 2.80400531e-04\n",
      " 2.81181802e-04 2.81963072e-04 2.82744342e-04 2.83525613e-04\n",
      " 2.85348577e-04 2.87171541e-04 2.88994505e-04 2.89775775e-04\n",
      " 2.90557046e-04 2.91338316e-04 2.92119586e-04 2.92900857e-04\n",
      " 2.93682127e-04 2.94463397e-04 2.95244668e-04 2.96025938e-04\n",
      " 2.96807209e-04 2.97588479e-04 2.98369749e-04 2.99151020e-04\n",
      " 2.99932290e-04 3.00713560e-04 3.01494831e-04 3.02276101e-04\n",
      " 3.03057371e-04 3.03838642e-04 3.04619912e-04 3.05401182e-04\n",
      " 3.06182453e-04 3.06963723e-04 3.07744993e-04 3.08526264e-04\n",
      " 3.09307534e-04 3.10088804e-04 3.10870075e-04 3.11651345e-04\n",
      " 3.12432615e-04 3.13213886e-04 3.13995156e-04 3.14776426e-04\n",
      " 3.15557697e-04 3.16338967e-04 3.17120238e-04 3.17901508e-04\n",
      " 3.18682778e-04 3.19464049e-04 3.20245319e-04 3.21026589e-04\n",
      " 3.21807860e-04 3.22589130e-04 3.23370400e-04 3.24151671e-04\n",
      " 3.24932941e-04 3.25714211e-04 3.26495482e-04 3.27276752e-04\n",
      " 3.28058022e-04 3.28839293e-04 3.29620563e-04 3.30401833e-04\n",
      " 3.31183104e-04 3.31964374e-04 3.32745644e-04 3.33526915e-04\n",
      " 3.34308185e-04 3.35089455e-04 3.35870726e-04 3.36651996e-04\n",
      " 3.37433266e-04 3.38214537e-04 3.38995807e-04 3.39777078e-04\n",
      " 3.40558348e-04 3.41339618e-04 3.42120889e-04 3.42902159e-04\n",
      " 3.43683429e-04 3.44464700e-04 3.45245970e-04 3.46027240e-04\n",
      " 3.46808511e-04 3.47589781e-04 3.48371051e-04 3.49152322e-04\n",
      " 3.49933592e-04 3.50714862e-04 3.51496133e-04 3.52277403e-04\n",
      " 3.53058673e-04 3.53839944e-04 3.54621214e-04 3.55402484e-04\n",
      " 3.56183755e-04 3.56965025e-04 3.57746295e-04 3.58527566e-04\n",
      " 3.59308836e-04 3.60090107e-04 3.60871377e-04 3.61652647e-04\n",
      " 3.62433918e-04 3.63215188e-04 3.63996458e-04 3.64777729e-04\n",
      " 3.65558999e-04 3.66340269e-04 3.67121540e-04 3.67902810e-04\n",
      " 3.68684080e-04 3.69465351e-04 3.70246621e-04 3.71027891e-04\n",
      " 3.71809162e-04 3.72590432e-04 3.73371702e-04 3.74152973e-04\n",
      " 3.75975937e-04 3.77798901e-04 3.79621865e-04 3.80403135e-04\n",
      " 3.81184406e-04 3.81965676e-04 3.82746947e-04 3.83528217e-04\n",
      " 3.84309487e-04 3.85090758e-04 3.85872028e-04 3.86653298e-04\n",
      " 3.87434569e-04 3.88215839e-04 3.88997109e-04 3.89778380e-04\n",
      " 3.90559650e-04 3.91340920e-04 3.92122191e-04 3.92903461e-04\n",
      " 3.93684731e-04 3.94466002e-04 3.95247272e-04 3.96028542e-04\n",
      " 3.96809813e-04 3.97591083e-04 3.98372353e-04 3.99153624e-04\n",
      " 3.99934894e-04 4.00716164e-04 4.01497435e-04 4.02278705e-04\n",
      " 4.03059976e-04 4.03841246e-04 4.04622516e-04 4.05403787e-04\n",
      " 4.06185057e-04 4.06966327e-04 4.08268444e-04 4.09570562e-04\n",
      " 4.10872679e-04 4.11653949e-04 4.12435220e-04 4.13216490e-04\n",
      " 4.13997760e-04 4.14779031e-04 4.15560301e-04 4.16341571e-04\n",
      " 4.17122842e-04 4.17904112e-04 4.18685382e-04 4.19466653e-04\n",
      " 4.20247923e-04 4.21029193e-04 4.21810464e-04 4.22591734e-04\n",
      " 4.23373005e-04 4.24154275e-04 4.24935545e-04 4.25716816e-04\n",
      " 4.26498086e-04 4.27279356e-04 4.28060627e-04 4.28841897e-04\n",
      " 4.29623167e-04 4.30404438e-04 4.31185708e-04 4.31966978e-04\n",
      " 4.32748249e-04 4.33529519e-04 4.34310789e-04 4.35092060e-04\n",
      " 4.35873330e-04 4.36654600e-04 4.37435871e-04 4.38217141e-04\n",
      " 4.38998411e-04 4.39779682e-04 4.40560952e-04 4.41342222e-04\n",
      " 4.42123493e-04 4.42904763e-04 4.43686033e-04 4.44467304e-04\n",
      " 4.45248574e-04 4.46029845e-04 4.46811115e-04 4.47592385e-04\n",
      " 4.48373656e-04 4.49154926e-04 4.49936196e-04 4.50717467e-04\n",
      " 4.52280007e-04 4.53842548e-04 4.55405089e-04 4.56186359e-04\n",
      " 4.56967629e-04 4.57748900e-04 4.58530170e-04 4.59311440e-04\n",
      " 4.60092711e-04 4.60873981e-04 4.61655251e-04 4.62436522e-04\n",
      " 4.63217792e-04 4.63999062e-04 4.64780333e-04 4.65561603e-04\n",
      " 4.66342874e-04 4.67124144e-04 4.67905414e-04 4.68686685e-04\n",
      " 4.69467955e-04 4.70249225e-04 4.71030496e-04 4.71811766e-04\n",
      " 4.72593036e-04 4.73374307e-04 4.74155577e-04 4.74936847e-04\n",
      " 4.75718118e-04 4.76499388e-04 4.77280658e-04 4.78061929e-04\n",
      " 4.78843199e-04 4.79624469e-04 4.80405740e-04 4.81187010e-04\n",
      " 4.81968280e-04 4.82749551e-04 4.83530821e-04 4.84312091e-04\n",
      " 4.85093362e-04 4.85874632e-04 4.86655902e-04 4.87437173e-04\n",
      " 4.88218443e-04 4.88999714e-04 4.89780984e-04 4.91343525e-04\n",
      " 4.92906065e-04 4.94468606e-04 4.95249876e-04 4.96031147e-04\n",
      " 4.96812417e-04 4.97593687e-04 4.98374958e-04 4.99156228e-04\n",
      " 4.99458319e-04 4.99239564e-04 4.98499961e-04 4.97718691e-04\n",
      " 4.96937420e-04 4.96156150e-04 4.95374880e-04 4.94593609e-04\n",
      " 4.93812339e-04 4.93031069e-04 4.92249798e-04 4.91468528e-04\n",
      " 4.90687257e-04 4.89905987e-04 4.89124717e-04 4.88343446e-04\n",
      " 4.87562176e-04 4.86780906e-04 4.85999635e-04 4.85218365e-04\n",
      " 4.84437095e-04 4.83655824e-04 4.82874554e-04 4.82093284e-04\n",
      " 4.81312013e-04 4.80530743e-04 4.79749473e-04 4.78968202e-04\n",
      " 4.78186932e-04 4.77405662e-04 4.76624391e-04 4.75843121e-04\n",
      " 4.75061851e-04 4.74280580e-04 4.73499310e-04 4.72718040e-04\n",
      " 4.71936769e-04 4.71155499e-04 4.70374228e-04 4.69592958e-04\n",
      " 4.68811688e-04 4.68030417e-04 4.67249147e-04 4.66467877e-04\n",
      " 4.65686606e-04 4.64905336e-04 4.64124066e-04 4.63342795e-04\n",
      " 4.62561525e-04 4.61780255e-04 4.60998984e-04 4.60217714e-04\n",
      " 4.59436444e-04 4.58655173e-04 4.57873903e-04 4.57092633e-04\n",
      " 4.56311362e-04 4.55530092e-04 4.54748822e-04 4.53967551e-04\n",
      " 4.53186281e-04 4.52405011e-04 4.51623740e-04 4.50842470e-04\n",
      " 4.50061200e-04 4.49279929e-04 4.48498659e-04 4.47717388e-04\n",
      " 4.46936118e-04 4.46154848e-04 4.45373577e-04 4.44592307e-04\n",
      " 4.43811037e-04 4.43029766e-04 4.42248496e-04 4.41467226e-04\n",
      " 4.40685955e-04 4.39904685e-04 4.39123415e-04 4.38342144e-04\n",
      " 4.37560874e-04 4.36779604e-04 4.35998333e-04 4.35217063e-04]\n",
      "y = -0.0007018252119537923x + 0.6324665816308229\n",
      "data start 1.882247575442827 6.568250924019484\n",
      "data end 1.2079359150813171 3.3465699142112117\n",
      "+0.5 epoch 0.8522340505454167 2.3448795841694072\n",
      "+1 epoch 0.6009005469379702 1.823760442973974\n",
      "+2 epoch 0.29892435749461443 1.348407622684301\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def smooth(data, window_width):\n",
    "    ret = np.cumsum(np.insert(data, 0, 0)) \n",
    "    return (ret[window_width:] - ret[:-window_width]) / window_width\n",
    "    \n",
    "smooth_window = 3\n",
    "\n",
    "start_idx = 0\n",
    "end_idx = len(losses)\n",
    "#end_idx -= 20\n",
    "\n",
    "total_batches = 99489#182396#\n",
    "print_rate = 100#200\n",
    "\n",
    "smooth_loss = smooth(losses[start_idx:end_idx], smooth_window)\n",
    "smooth_learning = smooth(learning_rates[start_idx:end_idx], smooth_window)\n",
    "print(smooth_loss)\n",
    "print(smooth_learning)\n",
    "x_vals = np.arange(0, len(smooth_loss))\n",
    "\n",
    "\n",
    "x_vals = np.arange(0, len(smooth_loss))\n",
    "a, y = np.polyfit(x_vals, np.log(smooth_loss), 1)\n",
    "\n",
    "def predicted_value(x, a, y):\n",
    "    return np.exp(a*x) * np.exp(y)\n",
    "\n",
    "y_vals = predicted_value(x_vals, a, y)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "print(f\"y = {a}x + {y}\")\n",
    "\n",
    "future = predicted_value(0, a, y)\n",
    "print(\"data start\", future, np.exp(future))\n",
    "\n",
    "future = predicted_value(len(smooth_loss), a, y)\n",
    "print(\"data end\", future, np.exp(future))\n",
    "\n",
    "\n",
    "one_epoch = total_batches/print_rate\n",
    "future = predicted_value(len(smooth_loss) + one_epoch//2, a, y)\n",
    "print(\"+0.5 epoch\", future, np.exp(future))\n",
    "\n",
    "future = predicted_value(len(smooth_loss) + one_epoch, a, y)\n",
    "print(\"+1 epoch\", future, np.exp(future))\n",
    "\n",
    "future = predicted_value(len(smooth_loss) + one_epoch*2, a, y)\n",
    "print(\"+2 epoch\", future, np.exp(future))\n",
    "\n",
    "\n",
    "\n",
    "ax1.plot(smooth_loss, label=\"Loss\", color=\"blue\")\n",
    "ax1.plot(x_vals, y_vals, label=\"Trend Line\")\n",
    "ax2.plot(smooth_learning, label=\"Learning Rate\", color=\"red\")\n",
    "\n",
    "fig.legend()\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a23f5980-ecdc-4277-80ec-daa9e99e013e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30720\n",
      "tensor(0.0002) tensor(0.0002) tensor(0.5003)\n"
     ]
    }
   ],
   "source": [
    "from ai.stabledisco.utils.mathutils import norm_t\n",
    "\n",
    "def make_rand_shift(cnt):\n",
    "        shift = torch.randn((cnt, 768))\n",
    "        shift /= shift.norm(dim=-1, keepdim=True)\n",
    "        scale = random_scale(cnt)\n",
    "        return scale * shift\n",
    "\n",
    "def random_scale(cnt, mean=0.025, std=0.05, min_scale=0.05):\n",
    "    return torch.randn((cnt, 1)) * std + mean + min_scale\n",
    "\n",
    "tens = make_rand_shift(int(768*40))\n",
    "\n",
    "norms = tens.norm(dim=-1)\n",
    "\n",
    "tens = norm_t(tens)\n",
    "\n",
    "svd = torch.linalg.svd(tens)\n",
    "\n",
    "print(len(tens))\n",
    "print(torch.min(svd.S/len(tens)), torch.max(svd.S/len(tens)), torch.std(svd.S))\n",
    "\n",
    "positive_vec = norm_t(torch.ones(768))\n",
    "neg_vec = -positive_vec\n",
    "\n",
    "#print(sdutils.calc_singular_vecs(tens, cutoff=0))\n",
    "\n",
    "\n",
    "#plt.hist(norms, bins=20)\n",
    "#print(\"norms\", norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a52ea9c3-7966-43b8-85c2-aec9b482e72d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'to_ratings_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torchmodules\u001b[38;5;241m.\u001b[39msave_model(\u001b[43mto_ratings_model\u001b[49m, decoderpipeline\u001b[38;5;241m.\u001b[39mFeaturesToRatingModel\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_pruned\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'to_ratings_model' is not defined"
     ]
    }
   ],
   "source": [
    "import torch_pruning as tp\n",
    "import ai.torchmodules.pruning as torchprune\n",
    "ori_size = tp.utils.count_params(to_token_model)\n",
    "\n",
    "imp = tp.importance.MagnitudeImportance(2) \n",
    "#imp = tp.importance.SensitivityImportance() \n",
    "ignored_layers = []\n",
    "\n",
    "for name, module in to_token_model.named_modules():\n",
    "    if \"_rating_out\" in name or \"embedding\" in name or isinstance():\n",
    "        ignored_layers.append(module)\n",
    "    elif 'NonDynamicallyQuantizableLinear' in type(module).__name__:\n",
    "        ignored_layers.append(module)\n",
    "\n",
    "torchutils.torch_garbage_collect()\n",
    "total_steps = 1\n",
    "pruner = tp.pruner.GlobalMagnitudePruner( \n",
    "    to_token_model.cpu(),\n",
    "    example_inputs,\n",
    "    importance=imp,\n",
    "    total_steps=total_steps, # number of iterations\n",
    "    ch_sparsity=0.5, # channel sparsity\n",
    "    ignored_layers=ignored_layers, # ignored_layers will not be pruned\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdb705a-0389-45a9-b4c9-43b03ce408a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_log_lines = \"\"\"\n",
    " Starting training\n",
    "Starting epoch 0\n",
    "  100/99489 batches | batch/sec  1.13 | rem mins  1469 | loss 3.07427 | ppl  21.6342\n",
    "Learning rate: [4.290880000000003e-05]\n",
    "  200/99489 batches | batch/sec  1.58 | rem mins  1047 | loss 3.04144 | ppl  20.9354\n",
    "Learning rate: [4.578880000000004e-05]\n",
    "  300/99489 batches | batch/sec  1.58 | rem mins  1049 | loss 3.04156 | ppl  20.9379\n",
    "Learning rate: [4.866880000000004e-05]\n",
    "  400/99489 batches | batch/sec  1.57 | rem mins  1049 | loss 3.01757 | ppl  20.4415\n",
    "Learning rate: [5.1548800000000044e-05]\n",
    "  500/99489 batches | batch/sec  1.57 | rem mins  1049 | loss 3.01923 | ppl  20.4755\n",
    "Learning rate: [5.4428800000000044e-05]\n",
    "  600/99489 batches | batch/sec  1.57 | rem mins  1048 | loss 3.04944 | ppl  21.1035\n",
    "Learning rate: [5.730880000000005e-05]\n",
    "  700/99489 batches | batch/sec  1.58 | rem mins  1045 | loss 3.02444 | ppl  20.5824\n",
    "Learning rate: [6.018880000000005e-05]\n",
    "  800/99489 batches | batch/sec  1.57 | rem mins  1045 | loss 3.02687 | ppl  20.6326\n",
    "Learning rate: [6.306880000000006e-05]\n",
    "  900/99489 batches | batch/sec  1.57 | rem mins  1044 | loss 3.04210 | ppl  20.9491\n",
    "Learning rate: [6.594880000000006e-05]\n",
    " 1000/99489 batches | batch/sec  1.57 | rem mins  1044 | loss 3.01670 | ppl  20.4237\n",
    "Learning rate: [6.882880000000005e-05]\n",
    " 1300/99489 batches | batch/sec  1.58 | rem mins  1039 | loss 3.01642 | ppl  20.4181\n",
    "Learning rate: [7.746880000000007e-05]\n",
    " 1400/99489 batches | batch/sec  1.57 | rem mins  1039 | loss 3.03772 | ppl  20.8576\n",
    "Learning rate: [8.034880000000008e-05]\n",
    " 1500/99489 batches | batch/sec  1.57 | rem mins  1037 | loss 3.02698 | ppl  20.6349\n",
    "Learning rate: [8.322880000000008e-05]\n",
    " 1600/99489 batches | batch/sec  1.57 | rem mins  1037 | loss 3.02236 | ppl  20.5397\n",
    "Learning rate: [8.610880000000008e-05]\n",
    " 1700/99489 batches | batch/sec  1.57 | rem mins  1036 | loss 3.02438 | ppl  20.5812\n",
    "Learning rate: [8.898880000000008e-05]\n",
    " 1800/99489 batches | batch/sec  1.57 | rem mins  1035 | loss 3.02482 | ppl  20.5903\n",
    "Learning rate: [9.186880000000008e-05]\n",
    " 1900/99489 batches | batch/sec  1.57 | rem mins  1034 | loss 3.02391 | ppl  20.5716\n",
    "Learning rate: [9.474879999999992e-05]\n",
    " 2000/99489 batches | batch/sec  1.57 | rem mins  1032 | loss 3.05349 | ppl  21.1892\n",
    "Learning rate: [9.762879999999993e-05]\n",
    " 2100/99489 batches | batch/sec  1.58 | rem mins  1030 | loss 3.02479 | ppl  20.5896\n",
    "Learning rate: [0.00010050879999999993]\n",
    " 2200/99489 batches | batch/sec  1.57 | rem mins  1030 | loss 3.03380 | ppl  20.7760\n",
    "Learning rate: [0.00010338879999999994]\n",
    " 2300/99489 batches | batch/sec  1.58 | rem mins  1028 | loss 3.02465 | ppl  20.5868\n",
    "Learning rate: [0.00010626879999999994]\n",
    " 2400/99489 batches | batch/sec  1.57 | rem mins  1028 | loss 3.02617 | ppl  20.6181\n",
    "Learning rate: [0.00010914879999999994]\n",
    " 2500/99489 batches | batch/sec  1.57 | rem mins  1027 | loss 3.05955 | ppl  21.3180\n",
    "Learning rate: [0.00011202879999999994]\n",
    " 2600/99489 batches | batch/sec  1.57 | rem mins  1025 | loss 3.01967 | ppl  20.4846\n",
    "Learning rate: [0.00011490879999999994]\n",
    " 2700/99489 batches | batch/sec  1.58 | rem mins  1023 | loss 3.03576 | ppl  20.8168\n",
    "Learning rate: [0.00011778879999999994]\n",
    " 2800/99489 batches | batch/sec  1.58 | rem mins  1023 | loss 3.04834 | ppl  21.0804\n",
    "Learning rate: [0.00012066879999999994]\n",
    " 2900/99489 batches | batch/sec  1.57 | rem mins  1022 | loss 3.05439 | ppl  21.2083\n",
    "Learning rate: [0.00012354879999999996]\n",
    " 3000/99489 batches | batch/sec  1.57 | rem mins  1021 | loss 3.05902 | ppl  21.3067\n",
    "Learning rate: [0.00012642879999999996]\n",
    " 3100/99489 batches | batch/sec  1.58 | rem mins  1020 | loss 3.04757 | ppl  21.0640\n",
    "Learning rate: [0.00012930879999999996]\n",
    " 3200/99489 batches | batch/sec  1.57 | rem mins  1019 | loss 3.03710 | ppl  20.8447\n",
    "Learning rate: [0.00013218879999999996]\n",
    " 3300/99489 batches | batch/sec  1.57 | rem mins  1018 | loss 3.04445 | ppl  20.9985\n",
    "Learning rate: [0.00013506879999999996]\n",
    " 3400/99489 batches | batch/sec  1.58 | rem mins  1016 | loss 3.06158 | ppl  21.3612\n",
    "Learning rate: [0.00013794879999999996]\n",
    " 3500/99489 batches | batch/sec  1.58 | rem mins  1015 | loss 3.01813 | ppl  20.4530\n",
    "Learning rate: [0.00014082879999999996]\n",
    " 3600/99489 batches | batch/sec  1.57 | rem mins  1015 | loss 3.05853 | ppl  21.2962\n",
    "Learning rate: [0.00014370879999999996]\n",
    " 3700/99489 batches | batch/sec  1.57 | rem mins  1014 | loss 3.04071 | ppl  20.9201\n",
    "Learning rate: [0.00014658879999999996]\n",
    " 3800/99489 batches | batch/sec  1.57 | rem mins  1013 | loss 3.06610 | ppl  21.4580\n",
    "Learning rate: [0.0001494688]\n",
    " 3900/99489 batches | batch/sec  1.57 | rem mins  1012 | loss 3.03917 | ppl  20.8879\n",
    "Learning rate: [0.0001523488]\n",
    " 4000/99489 batches | batch/sec  1.58 | rem mins  1010 | loss 3.06409 | ppl  21.4150\n",
    "Learning rate: [0.0001552288]\n",
    " 4100/99489 batches | batch/sec  1.58 | rem mins  1009 | loss 3.05472 | ppl  21.2152\n",
    "Learning rate: [0.00015810879999999999]\n",
    " 4200/99489 batches | batch/sec  1.58 | rem mins  1008 | loss 3.05307 | ppl  21.1802\n",
    "Learning rate: [0.00016098879999999999]\n",
    " 4300/99489 batches | batch/sec  1.57 | rem mins  1007 | loss 3.05616 | ppl  21.2458\n",
    "Learning rate: [0.00016386879999999999]\n",
    " 4400/99489 batches | batch/sec  1.57 | rem mins  1007 | loss 3.02554 | ppl  20.6052\n",
    "Learning rate: [0.00016674879999999998]\n",
    " 4500/99489 batches | batch/sec  1.58 | rem mins  1005 | loss 3.04604 | ppl  21.0318\n",
    "Learning rate: [0.00016962879999999998]\n",
    " 4600/99489 batches | batch/sec  1.57 | rem mins  1004 | loss 3.04623 | ppl  21.0358\n",
    "Learning rate: [0.00017250879999999998]\n",
    " 4700/99489 batches | batch/sec  1.57 | rem mins  1004 | loss 3.04291 | ppl  20.9661\n",
    "Learning rate: [0.00017538879999999998]\n",
    " 4800/99489 batches | batch/sec  1.57 | rem mins  1003 | loss 3.03741 | ppl  20.8511\n",
    "Learning rate: [0.0001782688]\n",
    " 4900/99489 batches | batch/sec  1.58 | rem mins  1001 | loss 3.02868 | ppl  20.6699\n",
    "Learning rate: [0.0001811488]\n",
    " 5000/99489 batches | batch/sec  1.57 | rem mins  1001 | loss 3.03773 | ppl  20.8578\n",
    "Learning rate: [0.0001840288]\n",
    " 5100/99489 batches | batch/sec  1.58 | rem mins   999 | loss 3.02667 | ppl  20.6285\n",
    "Learning rate: [0.0001869088]\n",
    " 5200/99489 batches | batch/sec  1.57 | rem mins   998 | loss 3.04937 | ppl  21.1020\n",
    "Learning rate: [0.0001897888]\n",
    " 5300/99489 batches | batch/sec  1.57 | rem mins   998 | loss 3.03507 | ppl  20.8025\n",
    "Learning rate: [0.0001926688]\n",
    " 5400/99489 batches | batch/sec  1.58 | rem mins   995 | loss 3.02489 | ppl  20.5917\n",
    "Learning rate: [0.0001955488]\n",
    " 5500/99489 batches | batch/sec  1.58 | rem mins   994 | loss 3.03319 | ppl  20.7633\n",
    "Learning rate: [0.0001984288]\n",
    " 5600/99489 batches | batch/sec  1.57 | rem mins   994 | loss 3.04220 | ppl  20.9513\n",
    "Learning rate: [0.0002013088]\n",
    " 5700/99489 batches | batch/sec  1.57 | rem mins   994 | loss 3.03960 | ppl  20.8968\n",
    "Learning rate: [0.00020418880000000003]\n",
    " 5800/99489 batches | batch/sec  1.57 | rem mins   992 | loss 3.03581 | ppl  20.8179\n",
    "Learning rate: [0.00020706880000000003]\n",
    " 5900/99489 batches | batch/sec  1.58 | rem mins   990 | loss 3.04514 | ppl  21.0129\n",
    "Learning rate: [0.00020994880000000003]\n",
    " 6000/99489 batches | batch/sec  1.57 | rem mins   990 | loss 3.02850 | ppl  20.6662\n",
    "Learning rate: [0.00021282880000000003]\n",
    " 6100/99489 batches | batch/sec  1.58 | rem mins   988 | loss 3.04919 | ppl  21.0983\n",
    "Learning rate: [0.00021570880000000003]\n",
    " 6200/99489 batches | batch/sec  1.57 | rem mins   987 | loss 3.05216 | ppl  21.1611\n",
    "Learning rate: [0.00021858880000000003]\n",
    " 6300/99489 batches | batch/sec  1.58 | rem mins   985 | loss 3.04441 | ppl  20.9977\n",
    "Learning rate: [0.00022146880000000003]\n",
    " 6400/99489 batches | batch/sec  1.57 | rem mins   986 | loss 3.01872 | ppl  20.4651\n",
    "Learning rate: [0.00022434880000000003]\n",
    " 6500/99489 batches | batch/sec  1.57 | rem mins   985 | loss 3.04918 | ppl  21.0981\n",
    "Learning rate: [0.00022722880000000006]\n",
    " 6600/99489 batches | batch/sec  1.58 | rem mins   983 | loss 3.02609 | ppl  20.6164\n",
    "Learning rate: [0.00023010880000000006]\n",
    " 6700/99489 batches | batch/sec  1.57 | rem mins   982 | loss 3.01756 | ppl  20.4414\n",
    "Learning rate: [0.00023298880000000006]\n",
    " 6800/99489 batches | batch/sec  1.57 | rem mins   981 | loss 3.02822 | ppl  20.6605\n",
    "Learning rate: [0.00023586880000000005]\n",
    " 6900/99489 batches | batch/sec  1.58 | rem mins   980 | loss 3.04450 | ppl  20.9994\n",
    "Learning rate: [0.00023874880000000005]\n",
    " 7000/99489 batches | batch/sec  1.58 | rem mins   978 | loss 3.01636 | ppl  20.4168\n",
    "Learning rate: [0.00024162880000000005]\n",
    " 7100/99489 batches | batch/sec  1.58 | rem mins   977 | loss 3.03515 | ppl  20.8041\n",
    "Learning rate: [0.00024450880000000005]\n",
    " 7200/99489 batches | batch/sec  1.58 | rem mins   976 | loss 3.04261 | ppl  20.9598\n",
    "Learning rate: [0.0002473888000000001]\n",
    " 7300/99489 batches | batch/sec  1.58 | rem mins   975 | loss 3.02960 | ppl  20.6889\n",
    "Learning rate: [0.00025026880000000005]\n",
    " 7400/99489 batches | batch/sec  1.58 | rem mins   974 | loss 3.04064 | ppl  20.9187\n",
    "Learning rate: [0.0002531488000000001]\n",
    " 7500/99489 batches | batch/sec  1.58 | rem mins   973 | loss 3.06267 | ppl  21.3846\n",
    "Learning rate: [0.0002560288000000001]\n",
    " 7600/99489 batches | batch/sec  1.57 | rem mins   973 | loss 3.04423 | ppl  20.9939\n",
    "Learning rate: [0.0002589088000000001]\n",
    " 7700/99489 batches | batch/sec  1.58 | rem mins   971 | loss 3.07206 | ppl  21.5864\n",
    "Learning rate: [0.0002617888000000001]\n",
    " 7800/99489 batches | batch/sec  1.57 | rem mins   970 | loss 3.04298 | ppl  20.9676\n",
    "Learning rate: [0.0002646688000000001]\n",
    " 7900/99489 batches | batch/sec  1.57 | rem mins   970 | loss 3.03984 | ppl  20.9019\n",
    "Learning rate: [0.0002675488000000001]\n",
    " 8000/99489 batches | batch/sec  1.58 | rem mins   968 | loss 3.03335 | ppl  20.7668\n",
    "Learning rate: [0.0002704288000000001]\n",
    " 8100/99489 batches | batch/sec  1.57 | rem mins   967 | loss 3.04035 | ppl  20.9126\n",
    "Learning rate: [0.0002733088000000001]\n",
    " 8200/99489 batches | batch/sec  1.57 | rem mins   966 | loss 3.05636 | ppl  21.2501\n",
    "Learning rate: [0.00027618880000000013]\n",
    " 8300/99489 batches | batch/sec  1.57 | rem mins   966 | loss 3.05487 | ppl  21.2185\n",
    "Learning rate: [0.0002790688000000001]\n",
    " 8400/99489 batches | batch/sec  1.58 | rem mins   964 | loss 3.02947 | ppl  20.6863\n",
    "Learning rate: [0.00028194880000000013]\n",
    " 8500/99489 batches | batch/sec  1.57 | rem mins   963 | loss 3.03854 | ppl  20.8748\n",
    "Learning rate: [0.0002848288000000001]\n",
    " 8600/99489 batches | batch/sec  1.57 | rem mins   963 | loss 3.02846 | ppl  20.6655\n",
    "Learning rate: [0.00028770880000000013]\n",
    " 8700/99489 batches | batch/sec  1.57 | rem mins   961 | loss 3.04142 | ppl  20.9349\n",
    "Learning rate: [0.0002905888000000001]\n",
    " 8800/99489 batches | batch/sec  1.58 | rem mins   959 | loss 3.03323 | ppl  20.7643\n",
    "Learning rate: [0.0002934688000000001]\n",
    " 8900/99489 batches | batch/sec  1.58 | rem mins   958 | loss 3.06547 | ppl  21.4445\n",
    "Learning rate: [0.0002963488000000001]\n",
    " 9000/99489 batches | batch/sec  1.58 | rem mins   957 | loss 3.05161 | ppl  21.1494\n",
    "Learning rate: [0.0002992288000000001]\n",
    " 9100/99489 batches | batch/sec  1.58 | rem mins   956 | loss 3.04129 | ppl  20.9322\n",
    "Learning rate: [0.00030210879999999994]\n",
    " 9200/99489 batches | batch/sec  1.57 | rem mins   956 | loss 3.04471 | ppl  21.0040\n",
    "Learning rate: [0.00030498879999999996]\n",
    " 9300/99489 batches | batch/sec  1.58 | rem mins   954 | loss 3.06007 | ppl  21.3290\n",
    "Learning rate: [0.00030786879999999993]\n",
    " 9400/99489 batches | batch/sec  1.58 | rem mins   953 | loss 3.05090 | ppl  21.1343\n",
    "Learning rate: [0.00031074879999999996]\n",
    " 9500/99489 batches | batch/sec  1.57 | rem mins   952 | loss 3.06023 | ppl  21.3325\n",
    "Learning rate: [0.0003136288]\n",
    " 9600/99489 batches | batch/sec  1.58 | rem mins   951 | loss 3.05288 | ppl  21.1762\n",
    "Learning rate: [0.00031650879999999996]\n",
    " 9700/99489 batches | batch/sec  1.58 | rem mins   950 | loss 3.02620 | ppl  20.6188\n",
    "Learning rate: [0.0003193888]\n",
    " 9800/99489 batches | batch/sec  1.58 | rem mins   948 | loss 3.05475 | ppl  21.2158\n",
    "Learning rate: [0.00032226879999999996]\n",
    " 9900/99489 batches | batch/sec  1.58 | rem mins   948 | loss 3.03472 | ppl  20.7952\n",
    "Learning rate: [0.0003251488]\n",
    "10000/99489 batches | batch/sec  1.58 | rem mins   947 | loss 3.06065 | ppl  21.3414\n",
    "Learning rate: [0.00032802879999999996]\n",
    "10100/99489 batches | batch/sec  1.58 | rem mins   945 | loss 3.04824 | ppl  21.0782\n",
    "Learning rate: [0.0003309088]\n",
    "10200/99489 batches | batch/sec  1.58 | rem mins   944 | loss 3.05494 | ppl  21.2199\n",
    "Learning rate: [0.0003337888]\n",
    "10300/99489 batches | batch/sec  1.58 | rem mins   942 | loss 3.04929 | ppl  21.1003\n",
    "Learning rate: [0.0003366688]\n",
    "10400/99489 batches | batch/sec  1.58 | rem mins   942 | loss 3.04985 | ppl  21.1122\n",
    "Learning rate: [0.0003395488]\n",
    "10500/99489 batches | batch/sec  1.58 | rem mins   941 | loss 3.02429 | ppl  20.5794\n",
    "Learning rate: [0.0003424288]\n",
    "10600/99489 batches | batch/sec  1.58 | rem mins   939 | loss 3.04732 | ppl  21.0589\n",
    "Learning rate: [0.0003453088]\n",
    "10700/99489 batches | batch/sec  1.58 | rem mins   938 | loss 3.06266 | ppl  21.3843\n",
    "Learning rate: [0.0003481888]\n",
    "10800/99489 batches | batch/sec  1.58 | rem mins   937 | loss 3.06438 | ppl  21.4211\n",
    "Learning rate: [0.0003510688]\n",
    "10900/99489 batches | batch/sec  1.58 | rem mins   935 | loss 3.04285 | ppl  20.9648\n",
    "Learning rate: [0.0003539488]\n",
    "11000/99489 batches | batch/sec  1.58 | rem mins   935 | loss 3.05010 | ppl  21.1175\n",
    "Learning rate: [0.0003568288]\n",
    "11100/99489 batches | batch/sec  1.58 | rem mins   934 | loss 3.06314 | ppl  21.3947\n",
    "Learning rate: [0.00035970880000000003]\n",
    "11200/99489 batches | batch/sec  1.58 | rem mins   932 | loss 3.03137 | ppl  20.7256\n",
    "Learning rate: [0.0003625888]\n",
    "11300/99489 batches | batch/sec  1.58 | rem mins   932 | loss 3.05974 | ppl  21.3220\n",
    "Learning rate: [0.00036546880000000003]\n",
    "11400/99489 batches | batch/sec  1.58 | rem mins   932 | loss 3.07783 | ppl  21.7112\n",
    "Learning rate: [0.0003683488]\n",
    "11500/99489 batches | batch/sec  1.58 | rem mins   930 | loss 3.04664 | ppl  21.0445\n",
    "Learning rate: [0.00037122880000000003]\n",
    "11600/99489 batches | batch/sec  1.58 | rem mins   929 | loss 3.05464 | ppl  21.2136\n",
    "Learning rate: [0.0003741088]\n",
    "11700/99489 batches | batch/sec  1.58 | rem mins   929 | loss 3.06994 | ppl  21.5406\n",
    "Learning rate: [0.00037698880000000003]\n",
    "11800/99489 batches | batch/sec  1.58 | rem mins   927 | loss 3.05759 | ppl  21.2762\n",
    "Learning rate: [0.0003798688]\n",
    "11900/99489 batches | batch/sec  1.57 | rem mins   927 | loss 3.05263 | ppl  21.1709\n",
    "Learning rate: [0.00038274880000000003]\n",
    "12000/99489 batches | batch/sec  1.57 | rem mins   927 | loss 3.06384 | ppl  21.4095\n",
    "Learning rate: [0.00038562880000000006]\n",
    "12100/99489 batches | batch/sec  1.57 | rem mins   925 | loss 3.04384 | ppl  20.9856\n",
    "Learning rate: [0.00038850880000000003]\n",
    "12200/99489 batches | batch/sec  1.57 | rem mins   924 | loss 3.07561 | ppl  21.6630\n",
    "Learning rate: [0.00039138880000000006]\n",
    "12300/99489 batches | batch/sec  1.57 | rem mins   923 | loss 3.05374 | ppl  21.1944\n",
    "Learning rate: [0.00039426880000000003]\n",
    "12400/99489 batches | batch/sec  1.57 | rem mins   924 | loss 3.05767 | ppl  21.2780\n",
    "Learning rate: [0.00039714880000000006]\n",
    "12500/99489 batches | batch/sec  1.57 | rem mins   921 | loss 3.06178 | ppl  21.3656\n",
    "Learning rate: [0.0003999712]\n",
    "12600/99489 batches | batch/sec  1.57 | rem mins   921 | loss 3.05312 | ppl  21.1813\n",
    "Learning rate: [0.0003970912]\n",
    "12700/99489 batches | batch/sec  1.57 | rem mins   920 | loss 3.07439 | ppl  21.6367\n",
    "Learning rate: [0.0003942112]\n",
    "12800/99489 batches | batch/sec  1.57 | rem mins   920 | loss 3.05917 | ppl  21.3098\n",
    "Learning rate: [0.0003913312]\n",
    "12900/99489 batches | batch/sec  1.57 | rem mins   919 | loss 3.05712 | ppl  21.2663\n",
    "Learning rate: [0.00038845119999999996]\n",
    "13000/99489 batches | batch/sec  1.57 | rem mins   917 | loss 3.04948 | ppl  21.1044\n",
    "Learning rate: [0.00038557120000000015]\n",
    "13100/99489 batches | batch/sec  1.57 | rem mins   917 | loss 3.07613 | ppl  21.6744\n",
    "Learning rate: [0.0003826912000000001]\n",
    "13200/99489 batches | batch/sec  1.57 | rem mins   916 | loss 3.05646 | ppl  21.2521\n",
    "Learning rate: [0.00037981120000000015]\n",
    "13300/99489 batches | batch/sec  1.57 | rem mins   915 | loss 3.07489 | ppl  21.6476\n",
    "Learning rate: [0.0003769312000000001]\n",
    "13400/99489 batches | batch/sec  1.57 | rem mins   914 | loss 3.03786 | ppl  20.8605\n",
    "Learning rate: [0.00037405120000000015]\n",
    "13500/99489 batches | batch/sec  1.57 | rem mins   912 | loss 3.06986 | ppl  21.5389\n",
    "Learning rate: [0.0003711712000000001]\n",
    "13600/99489 batches | batch/sec  1.57 | rem mins   911 | loss 3.05018 | ppl  21.1192\n",
    "Learning rate: [0.0003682912000000001]\n",
    "13700/99489 batches | batch/sec  1.57 | rem mins   909 | loss 3.05517 | ppl  21.2247\n",
    "Learning rate: [0.0003654112000000001]\n",
    "13800/99489 batches | batch/sec  1.57 | rem mins   908 | loss 3.03548 | ppl  20.8109\n",
    "Learning rate: [0.0003625312000000001]\n",
    "13900/99489 batches | batch/sec  1.57 | rem mins   907 | loss 3.05231 | ppl  21.1642\n",
    "Learning rate: [0.0003596512000000001]\n",
    "14000/99489 batches | batch/sec  1.57 | rem mins   906 | loss 3.04224 | ppl  20.9521\n",
    "Learning rate: [0.0003567712000000001]\n",
    "14100/99489 batches | batch/sec  1.57 | rem mins   905 | loss 3.06125 | ppl  21.3542\n",
    "Learning rate: [0.0003538912000000001]\n",
    "14200/99489 batches | batch/sec  1.57 | rem mins   904 | loss 3.04563 | ppl  21.0233\n",
    "Learning rate: [0.0003510112000000001]\n",
    "14300/99489 batches | batch/sec  1.57 | rem mins   903 | loss 3.04691 | ppl  21.0502\n",
    "Learning rate: [0.0003481312000000001]\n",
    "14400/99489 batches | batch/sec  1.58 | rem mins   900 | loss 3.04306 | ppl  20.9693\n",
    "Learning rate: [0.0003452512000000001]\n",
    "14500/99489 batches | batch/sec  1.58 | rem mins   899 | loss 3.03796 | ppl  20.8627\n",
    "Learning rate: [0.0003423712000000001]\n",
    "14600/99489 batches | batch/sec  1.58 | rem mins   898 | loss 3.03271 | ppl  20.7534\n",
    "Learning rate: [0.0003394912000000001]\n",
    "14700/99489 batches | batch/sec  1.58 | rem mins   896 | loss 3.04386 | ppl  20.9861\n",
    "Learning rate: [0.0003366112000000001]\n",
    "14800/99489 batches | batch/sec  1.57 | rem mins   897 | loss 3.05623 | ppl  21.2473\n",
    "Learning rate: [0.0003337312000000001]\n",
    "14900/99489 batches | batch/sec  1.58 | rem mins   895 | loss 3.03616 | ppl  20.8252\n",
    "Learning rate: [0.0003308512000000001]\n",
    "15000/99489 batches | batch/sec  1.57 | rem mins   895 | loss 3.04840 | ppl  21.0815\n",
    "Learning rate: [0.0003279712000000001]\n",
    "15100/99489 batches | batch/sec  1.57 | rem mins   894 | loss 3.04412 | ppl  20.9916\n",
    "Learning rate: [0.0003250912000000001]\n",
    "15200/99489 batches | batch/sec  1.57 | rem mins   893 | loss 3.03257 | ppl  20.7505\n",
    "Learning rate: [0.00032221120000000005]\n",
    "15300/99489 batches | batch/sec  1.58 | rem mins   890 | loss 3.04870 | ppl  21.0880\n",
    "Learning rate: [0.0003193312000000001]\n",
    "15400/99489 batches | batch/sec  1.58 | rem mins   889 | loss 3.04297 | ppl  20.9674\n",
    "Learning rate: [0.00031645120000000005]\n",
    "15500/99489 batches | batch/sec  1.58 | rem mins   888 | loss 3.05317 | ppl  21.1825\n",
    "Learning rate: [0.0003135712000000001]\n",
    "15600/99489 batches | batch/sec  1.57 | rem mins   888 | loss 3.03841 | ppl  20.8721\n",
    "Learning rate: [0.00031069120000000005]\n",
    "15700/99489 batches | batch/sec  1.58 | rem mins   886 | loss 3.03643 | ppl  20.8308\n",
    "Learning rate: [0.0003078112000000001]\n",
    "15800/99489 batches | batch/sec  1.58 | rem mins   884 | loss 3.04120 | ppl  20.9303\n",
    "Learning rate: [0.00030493120000000005]\n",
    "15900/99489 batches | batch/sec  1.58 | rem mins   884 | loss 3.05452 | ppl  21.2110\n",
    "Learning rate: [0.0003020512000000001]\n",
    "16000/99489 batches | batch/sec  1.58 | rem mins   883 | loss 3.04046 | ppl  20.9149\n",
    "Learning rate: [0.00029917120000000005]\n",
    "16100/99489 batches | batch/sec  1.58 | rem mins   881 | loss 3.04276 | ppl  20.9630\n",
    "Learning rate: [0.00029629120000000003]\n",
    "16200/99489 batches | batch/sec  1.58 | rem mins   881 | loss 3.02564 | ppl  20.6073\n",
    "Learning rate: [0.00029341120000000005]\n",
    "16300/99489 batches | batch/sec  1.58 | rem mins   879 | loss 3.03379 | ppl  20.7758\n",
    "Learning rate: [0.00029053120000000003]\n",
    "16400/99489 batches | batch/sec  1.58 | rem mins   879 | loss 3.03719 | ppl  20.8465\n",
    "Learning rate: [0.00028765120000000006]\n",
    "16500/99489 batches | batch/sec  1.58 | rem mins   877 | loss 3.05069 | ppl  21.1299\n",
    "Learning rate: [0.00028477120000000003]\n",
    "16600/99489 batches | batch/sec  1.58 | rem mins   876 | loss 3.01702 | ppl  20.4303\n",
    "Learning rate: [0.00028189120000000006]\n",
    "16700/99489 batches | batch/sec  1.58 | rem mins   875 | loss 3.04158 | ppl  20.9384\n",
    "Learning rate: [0.00027901120000000003]\n",
    "16800/99489 batches | batch/sec  1.58 | rem mins   874 | loss 3.03716 | ppl  20.8459\n",
    "Learning rate: [0.00027613120000000006]\n",
    "16900/99489 batches | batch/sec  1.58 | rem mins   873 | loss 3.02332 | ppl  20.5595\n",
    "Learning rate: [0.00027325120000000003]\n",
    "17000/99489 batches | batch/sec  1.58 | rem mins   872 | loss 3.02929 | ppl  20.6825\n",
    "Learning rate: [0.00027037120000000006]\n",
    "17100/99489 batches | batch/sec  1.58 | rem mins   871 | loss 3.02344 | ppl  20.5620\n",
    "Learning rate: [0.00026749120000000003]\n",
    "17200/99489 batches | batch/sec  1.58 | rem mins   869 | loss 3.05259 | ppl  21.1702\n",
    "Learning rate: [0.00026461120000000006]\n",
    "17300/99489 batches | batch/sec  1.58 | rem mins   868 | loss 3.02256 | ppl  20.5439\n",
    "Learning rate: [0.00026173120000000003]\n",
    "17400/99489 batches | batch/sec  1.58 | rem mins   867 | loss 3.03590 | ppl  20.8198\n",
    "Learning rate: [0.0002588512]\n",
    "17500/99489 batches | batch/sec  1.58 | rem mins   866 | loss 3.03604 | ppl  20.8227\n",
    "Learning rate: [0.00025597120000000003]\n",
    "17600/99489 batches | batch/sec  1.58 | rem mins   864 | loss 3.01852 | ppl  20.4611\n",
    "Learning rate: [0.0002530912]\n",
    "17700/99489 batches | batch/sec  1.58 | rem mins   864 | loss 3.00882 | ppl  20.2635\n",
    "Learning rate: [0.00025021120000000003]\n",
    "17800/99489 batches | batch/sec  1.58 | rem mins   864 | loss 3.03817 | ppl  20.8669\n",
    "Learning rate: [0.0002473312]\n",
    "17900/99489 batches | batch/sec  1.58 | rem mins   862 | loss 3.03115 | ppl  20.7211\n",
    "Learning rate: [0.00024445120000000004]\n",
    "18000/99489 batches | batch/sec  1.58 | rem mins   862 | loss 3.00677 | ppl  20.2220\n",
    "Learning rate: [0.0002415712]\n",
    "18100/99489 batches | batch/sec  1.58 | rem mins   861 | loss 3.02588 | ppl  20.6122\n",
    "Learning rate: [0.0002386912]\n",
    "18200/99489 batches | batch/sec  1.58 | rem mins   859 | loss 3.01718 | ppl  20.4335\n",
    "Learning rate: [0.00023581119999999998]\n",
    "18300/99489 batches | batch/sec  1.58 | rem mins   859 | loss 3.01244 | ppl  20.3370\n",
    "Learning rate: [0.00023293119999999998]\n",
    "18400/99489 batches | batch/sec  1.58 | rem mins   857 | loss 3.02895 | ppl  20.6755\n",
    "Learning rate: [0.00023005119999999998]\n",
    "18500/99489 batches | batch/sec  1.57 | rem mins   857 | loss 3.02411 | ppl  20.5757\n",
    "Learning rate: [0.00022717119999999998]\n",
    "18600/99489 batches | batch/sec  1.57 | rem mins   856 | loss 3.02975 | ppl  20.6921\n",
    "Learning rate: [0.00022429119999999998]\n",
    "18700/99489 batches | batch/sec  1.59 | rem mins   847 | loss 2.99326 | ppl  19.9505\n",
    "Learning rate: [0.00022141119999999999]\n",
    "18800/99489 batches | batch/sec  1.67 | rem mins   804 | loss 3.02426 | ppl  20.5788\n",
    "Learning rate: [0.00021853119999999999]\n",
    "18900/99489 batches | batch/sec  1.67 | rem mins   803 | loss 3.00274 | ppl  20.1406\n",
    "Learning rate: [0.00021565119999999999]\n",
    "19000/99489 batches | batch/sec  1.67 | rem mins   803 | loss 3.00193 | ppl  20.1244\n",
    "Learning rate: [0.00021277119999999996]\n",
    "19100/99489 batches | batch/sec  1.67 | rem mins   801 | loss 2.99459 | ppl  19.9772\n",
    "Learning rate: [0.00020989119999999996]\n",
    "19200/99489 batches | batch/sec  1.67 | rem mins   801 | loss 2.99826 | ppl  20.0507\n",
    "Learning rate: [0.00020701119999999996]\n",
    "19300/99489 batches | batch/sec  1.67 | rem mins   800 | loss 2.99384 | ppl  19.9622\n",
    "Learning rate: [0.00020413119999999996]\n",
    "19400/99489 batches | batch/sec  1.67 | rem mins   799 | loss 3.01141 | ppl  20.3159\n",
    "Learning rate: [0.00020125119999999996]\n",
    "19500/99489 batches | batch/sec  1.67 | rem mins   798 | loss 2.99968 | ppl  20.0791\n",
    "Learning rate: [0.00019837119999999996]\n",
    "19600/99489 batches | batch/sec  1.67 | rem mins   797 | loss 2.98630 | ppl  19.8122\n",
    "Learning rate: [0.00019549119999999996]\n",
    "19700/99489 batches | batch/sec  1.67 | rem mins   797 | loss 3.00657 | ppl  20.2178\n",
    "Learning rate: [0.00019261119999999996]\n",
    "19800/99489 batches | batch/sec  1.67 | rem mins   795 | loss 3.00414 | ppl  20.1689\n",
    "Learning rate: [0.00018973119999999996]\n",
    "19900/99489 batches | batch/sec  1.67 | rem mins   794 | loss 2.99778 | ppl  20.0409\n",
    "Learning rate: [0.00018685119999999994]\n",
    "20000/99489 batches | batch/sec  1.67 | rem mins   794 | loss 2.98631 | ppl  19.8124\n",
    "Learning rate: [0.00018397119999999994]\n",
    "20100/99489 batches | batch/sec  1.67 | rem mins   793 | loss 3.01315 | ppl  20.3514\n",
    "Learning rate: [0.00018109119999999994]\n",
    "20200/99489 batches | batch/sec  1.67 | rem mins   792 | loss 3.00346 | ppl  20.1552\n",
    "Learning rate: [0.00017821119999999994]\n",
    "20300/99489 batches | batch/sec  1.67 | rem mins   791 | loss 3.01431 | ppl  20.3751\n",
    "Learning rate: [0.00017533119999999994]\n",
    "20400/99489 batches | batch/sec  1.67 | rem mins   790 | loss 3.00076 | ppl  20.1008\n",
    "Learning rate: [0.00017245119999999994]\n",
    "20500/99489 batches | batch/sec  1.67 | rem mins   789 | loss 2.99753 | ppl  20.0359\n",
    "Learning rate: [0.00016957119999999994]\n",
    "20600/99489 batches | batch/sec  1.67 | rem mins   789 | loss 2.99904 | ppl  20.0663\n",
    "Learning rate: [0.00016669119999999994]\n",
    "20700/99489 batches | batch/sec  1.67 | rem mins   787 | loss 3.00112 | ppl  20.1080\n",
    "Learning rate: [0.0001638111999999999]\n",
    "20800/99489 batches | batch/sec  1.67 | rem mins   786 | loss 3.01749 | ppl  20.4399\n",
    "Learning rate: [0.00016093119999999994]\n",
    "20900/99489 batches | batch/sec  1.67 | rem mins   785 | loss 3.00238 | ppl  20.1334\n",
    "Learning rate: [0.00015805119999999991]\n",
    "21000/99489 batches | batch/sec  1.67 | rem mins   784 | loss 3.01165 | ppl  20.3209\n",
    "Learning rate: [0.00015517119999999991]\n",
    "21100/99489 batches | batch/sec  1.67 | rem mins   783 | loss 3.00560 | ppl  20.1983\n",
    "Learning rate: [0.00015229119999999992]\n",
    "21200/99489 batches | batch/sec  1.67 | rem mins   781 | loss 2.99883 | ppl  20.0621\n",
    "Learning rate: [0.00014941119999999992]\n",
    "21300/99489 batches | batch/sec  1.67 | rem mins   780 | loss 3.00480 | ppl  20.1821\n",
    "Learning rate: [0.00014653119999999992]\n",
    "21400/99489 batches | batch/sec  1.67 | rem mins   779 | loss 2.99640 | ppl  20.0134\n",
    "Learning rate: [0.00014365119999999992]\n",
    "21500/99489 batches | batch/sec  1.67 | rem mins   777 | loss 3.01341 | ppl  20.3566\n",
    "Learning rate: [0.00014077119999999992]\n",
    "21600/99489 batches | batch/sec  1.67 | rem mins   776 | loss 3.00407 | ppl  20.1675\n",
    "Learning rate: [0.00013789119999999992]\n",
    "21700/99489 batches | batch/sec  1.67 | rem mins   775 | loss 2.99338 | ppl  19.9530\n",
    "Learning rate: [0.00013501119999999992]\n",
    "21800/99489 batches | batch/sec  1.67 | rem mins   775 | loss 2.99956 | ppl  20.0766\n",
    "Learning rate: [0.0001321311999999999]\n",
    "21900/99489 batches | batch/sec  1.67 | rem mins   772 | loss 3.00962 | ppl  20.2798\n",
    "Learning rate: [0.0001292511999999999]\n",
    "22000/99489 batches | batch/sec  1.67 | rem mins   772 | loss 3.00819 | ppl  20.2507\n",
    "Learning rate: [0.0001263711999999999]\n",
    "22100/99489 batches | batch/sec  1.68 | rem mins   770 | loss 3.00286 | ppl  20.1431\n",
    "Learning rate: [0.0001234911999999999]\n",
    "22200/99489 batches | batch/sec  1.68 | rem mins   768 | loss 2.99322 | ppl  19.9499\n",
    "Learning rate: [0.00012061119999999989]\n",
    "22300/99489 batches | batch/sec  1.68 | rem mins   767 | loss 3.01102 | ppl  20.3081\n",
    "Learning rate: [0.0001177311999999999]\n",
    "22400/99489 batches | batch/sec  1.68 | rem mins   766 | loss 3.01533 | ppl  20.3958\n",
    "Learning rate: [0.00011485120000000006]\n",
    "22500/99489 batches | batch/sec  1.68 | rem mins   765 | loss 2.99970 | ppl  20.0794\n",
    "Learning rate: [0.00011197120000000003]\n",
    "22600/99489 batches | batch/sec  1.68 | rem mins   764 | loss 3.00407 | ppl  20.1674\n",
    "Learning rate: [0.00010909120000000003]\n",
    "22700/99489 batches | batch/sec  1.68 | rem mins   763 | loss 2.99802 | ppl  20.0457\n",
    "Learning rate: [0.00010621120000000003]\n",
    "22800/99489 batches | batch/sec  1.68 | rem mins   762 | loss 2.98946 | ppl  19.8749\n",
    "Learning rate: [0.00010333120000000003]\n",
    "22900/99489 batches | batch/sec  1.68 | rem mins   761 | loss 2.98839 | ppl  19.8537\n",
    "Learning rate: [0.00010045120000000003]\n",
    "23000/99489 batches | batch/sec  1.68 | rem mins   760 | loss 3.00709 | ppl  20.2284\n",
    "Learning rate: [9.757120000000003e-05]\n",
    "23100/99489 batches | batch/sec  1.68 | rem mins   759 | loss 3.01880 | ppl  20.4667\n",
    "Learning rate: [9.469120000000003e-05]\n",
    "23200/99489 batches | batch/sec  1.68 | rem mins   758 | loss 2.99033 | ppl  19.8922\n",
    "Learning rate: [9.181120000000003e-05]\n",
    "23300/99489 batches | batch/sec  1.68 | rem mins   757 | loss 2.99670 | ppl  20.0195\n",
    "Learning rate: [8.893120000000002e-05]\n",
    "23400/99489 batches | batch/sec  1.68 | rem mins   756 | loss 2.99313 | ppl  19.9481\n",
    "Learning rate: [8.605120000000002e-05]\n",
    "23500/99489 batches | batch/sec  1.68 | rem mins   755 | loss 2.97948 | ppl  19.6776\n",
    "Learning rate: [8.317120000000001e-05]\n",
    "23600/99489 batches | batch/sec  1.68 | rem mins   754 | loss 2.99944 | ppl  20.0743\n",
    "Learning rate: [8.029120000000001e-05]\n",
    "23700/99489 batches | batch/sec  1.68 | rem mins   754 | loss 2.99656 | ppl  20.0165\n",
    "Learning rate: [7.741120000000001e-05]\n",
    "23800/99489 batches | batch/sec  1.68 | rem mins   752 | loss 3.00522 | ppl  20.1908\n",
    "Learning rate: [7.453120000000001e-05]\n",
    "23900/99489 batches | batch/sec  1.68 | rem mins   750 | loss 3.00363 | ppl  20.1587\n",
    "Learning rate: [7.165120000000001e-05]\n",
    "24000/99489 batches | batch/sec  1.68 | rem mins   750 | loss 3.01209 | ppl  20.3299\n",
    "Learning rate: [6.877120000000001e-05]\n",
    "24100/99489 batches | batch/sec  1.68 | rem mins   749 | loss 2.99595 | ppl  20.0044\n",
    "Learning rate: [6.58912e-05]\n",
    "24200/99489 batches | batch/sec  1.68 | rem mins   748 | loss 2.99344 | ppl  19.9542\n",
    "Learning rate: [6.30112e-05]\n",
    "24300/99489 batches | batch/sec  1.68 | rem mins   747 | loss 3.00987 | ppl  20.2847\n",
    "Learning rate: [6.01312e-05]\n",
    "24400/99489 batches | batch/sec  1.68 | rem mins   746 | loss 3.01977 | ppl  20.4866\n",
    "Learning rate: [5.725119999999999e-05]\n",
    "24500/99489 batches | batch/sec  1.68 | rem mins   745 | loss 2.99504 | ppl  19.9862\n",
    "Learning rate: [5.4371199999999985e-05]\n",
    "24600/99489 batches | batch/sec  1.68 | rem mins   743 | loss 2.99626 | ppl  20.0105\n",
    "Learning rate: [5.1491199999999986e-05]\n",
    "24700/99489 batches | batch/sec  1.68 | rem mins   744 | loss 2.99823 | ppl  20.0501\n",
    "Learning rate: [4.8611199999999986e-05]\n",
    "24800/99489 batches | batch/sec  1.68 | rem mins   742 | loss 3.01117 | ppl  20.3112\n",
    "Learning rate: [4.573119999999998e-05]\n",
    "24900/99489 batches | batch/sec  1.68 | rem mins   741 | loss 3.02134 | ppl  20.5187\n",
    "Learning rate: [4.285119999999998e-05]\n",
    "25000/99489 batches | batch/sec  1.68 | rem mins   741 | loss 2.99734 | ppl  20.0322\n",
    "Learning rate: [4.0028800000000195e-05]\n",
    "25100/99489 batches | batch/sec  1.68 | rem mins   740 | loss 2.99182 | ppl  19.9219\n",
    "Learning rate: [4.2908799999999876e-05]\n",
    "25200/99489 batches | batch/sec  1.68 | rem mins   739 | loss 3.00483 | ppl  20.1827\n",
    "Learning rate: [4.5788800000000194e-05]\n",
    "25300/99489 batches | batch/sec  1.67 | rem mins   738 | loss 2.99914 | ppl  20.0683\n",
    "Learning rate: [4.866879999999988e-05]\n",
    "25400/99489 batches | batch/sec  1.68 | rem mins   737 | loss 2.99849 | ppl  20.0552\n",
    "Learning rate: [5.154880000000021e-05]\n",
    "25500/99489 batches | batch/sec  1.67 | rem mins   737 | loss 3.00279 | ppl  20.1416\n",
    "Learning rate: [5.442879999999989e-05]\n",
    "25600/99489 batches | batch/sec  1.67 | rem mins   736 | loss 3.00862 | ppl  20.2594\n",
    "Learning rate: [5.7308800000000206e-05]\n",
    "25700/99489 batches | batch/sec  1.67 | rem mins   735 | loss 3.00326 | ppl  20.1512\n",
    "Learning rate: [6.0188799999999894e-05]\n",
    "25800/99489 batches | batch/sec  1.67 | rem mins   734 | loss 2.99489 | ppl  19.9831\n",
    "Learning rate: [6.306880000000022e-05]\n",
    "25900/99489 batches | batch/sec  1.67 | rem mins   733 | loss 2.99968 | ppl  20.0792\n",
    "Learning rate: [6.594879999999989e-05]\n",
    "26000/99489 batches | batch/sec  1.67 | rem mins   732 | loss 2.99798 | ppl  20.0451\n",
    "Learning rate: [6.882880000000022e-05]\n",
    "26100/99489 batches | batch/sec  1.67 | rem mins   732 | loss 3.01063 | ppl  20.3002\n",
    "Learning rate: [7.17087999999999e-05]\n",
    "26200/99489 batches | batch/sec  1.67 | rem mins   730 | loss 2.99548 | ppl  19.9950\n",
    "Learning rate: [7.458880000000022e-05]\n",
    "26300/99489 batches | batch/sec  1.67 | rem mins   730 | loss 3.01166 | ppl  20.3211\n",
    "Learning rate: [7.74687999999999e-05]\n",
    "26400/99489 batches | batch/sec  1.67 | rem mins   729 | loss 3.01127 | ppl  20.3131\n",
    "Learning rate: [8.034880000000023e-05]\n",
    "26500/99489 batches | batch/sec  1.67 | rem mins   728 | loss 3.00708 | ppl  20.2283\n",
    "Learning rate: [8.322879999999992e-05]\n",
    "26600/99489 batches | batch/sec  1.67 | rem mins   728 | loss 2.98933 | ppl  19.8723\n",
    "Learning rate: [8.610880000000024e-05]\n",
    "26700/99489 batches | batch/sec  1.67 | rem mins   727 | loss 3.02440 | ppl  20.5817\n",
    "Learning rate: [8.898879999999992e-05]\n",
    "26800/99489 batches | batch/sec  1.67 | rem mins   725 | loss 2.99793 | ppl  20.0441\n",
    "Learning rate: [9.186880000000024e-05]\n",
    "26900/99489 batches | batch/sec  1.67 | rem mins   725 | loss 3.01121 | ppl  20.3120\n",
    "Learning rate: [9.474879999999992e-05]\n",
    "27000/99489 batches | batch/sec  1.67 | rem mins   725 | loss 3.00122 | ppl  20.1100\n",
    "Learning rate: [9.762879999999993e-05]\n",
    "27100/99489 batches | batch/sec  1.67 | rem mins   723 | loss 2.99634 | ppl  20.0121\n",
    "Learning rate: [0.00010050879999999993]\n",
    "27200/99489 batches | batch/sec  1.67 | rem mins   723 | loss 3.01558 | ppl  20.4010\n",
    "Learning rate: [0.00010338879999999994]\n",
    "27300/99489 batches | batch/sec  1.67 | rem mins   722 | loss 2.99766 | ppl  20.0387\n",
    "Learning rate: [0.00010626879999999994]\n",
    "27400/99489 batches | batch/sec  1.67 | rem mins   720 | loss 3.02564 | ppl  20.6071\n",
    "Learning rate: [0.00010914879999999994]\n",
    "27500/99489 batches | batch/sec  1.67 | rem mins   720 | loss 3.02039 | ppl  20.4992\n",
    "Learning rate: [0.00011202879999999994]\n",
    "27600/99489 batches | batch/sec  1.67 | rem mins   719 | loss 3.00218 | ppl  20.1294\n",
    "Learning rate: [0.00011490879999999994]\n",
    "27700/99489 batches | batch/sec  1.67 | rem mins   717 | loss 3.01510 | ppl  20.3911\n",
    "Learning rate: [0.00011778879999999994]\n",
    "27800/99489 batches | batch/sec  1.67 | rem mins   716 | loss 2.99808 | ppl  20.0471\n",
    "Learning rate: [0.00012066879999999994]\n",
    "27900/99489 batches | batch/sec  1.67 | rem mins   716 | loss 3.02994 | ppl  20.6959\n",
    "Learning rate: [0.00012354879999999996]\n",
    "28000/99489 batches | batch/sec  1.67 | rem mins   715 | loss 2.99974 | ppl  20.0803\n",
    "Learning rate: [0.00012642879999999996]\n",
    "28100/99489 batches | batch/sec  1.67 | rem mins   713 | loss 2.99911 | ppl  20.0676\n",
    "Learning rate: [0.00012930879999999996]\n",
    "28200/99489 batches | batch/sec  1.67 | rem mins   712 | loss 3.00817 | ppl  20.2503\n",
    "Learning rate: [0.00013218879999999996]\n",
    "28300/99489 batches | batch/sec  1.67 | rem mins   710 | loss 2.97923 | ppl  19.6727\n",
    "Learning rate: [0.00013506879999999996]\n",
    "28400/99489 batches | batch/sec  1.67 | rem mins   709 | loss 2.99272 | ppl  19.9398\n",
    "Learning rate: [0.00013794879999999996]\n",
    "28500/99489 batches | batch/sec  1.67 | rem mins   709 | loss 2.98510 | ppl  19.7885\n",
    "Learning rate: [0.00014082879999999996]\n",
    "28600/99489 batches | batch/sec  1.67 | rem mins   707 | loss 3.00639 | ppl  20.2143\n",
    "Learning rate: [0.00014370879999999996]\n",
    "28700/99489 batches | batch/sec  1.67 | rem mins   706 | loss 2.98676 | ppl  19.8213\n",
    "Learning rate: [0.00014658879999999996]\n",
    "28800/99489 batches | batch/sec  1.67 | rem mins   704 | loss 2.98328 | ppl  19.7524\n",
    "Learning rate: [0.0001494688]\n",
    "28900/99489 batches | batch/sec  1.67 | rem mins   703 | loss 2.98694 | ppl  19.8249\n",
    "Learning rate: [0.0001523488]\n",
    "29000/99489 batches | batch/sec  1.67 | rem mins   702 | loss 3.01412 | ppl  20.3712\n",
    "Learning rate: [0.0001552288]\n",
    "29100/99489 batches | batch/sec  1.67 | rem mins   701 | loss 2.98592 | ppl  19.8048\n",
    "Learning rate: [0.00015810879999999999]\n",
    "29200/99489 batches | batch/sec  1.67 | rem mins   700 | loss 3.00339 | ppl  20.1537\n",
    "Learning rate: [0.00016098879999999999]\n",
    "29300/99489 batches | batch/sec  1.67 | rem mins   699 | loss 3.00225 | ppl  20.1308\n",
    "Learning rate: [0.00016386879999999999]\n",
    "29400/99489 batches | batch/sec  1.67 | rem mins   698 | loss 3.00843 | ppl  20.2556\n",
    "Learning rate: [0.00016674879999999998]\n",
    "29500/99489 batches | batch/sec  1.67 | rem mins   696 | loss 3.00535 | ppl  20.1932\n",
    "Learning rate: [0.00016962879999999998]\n",
    "29600/99489 batches | batch/sec  1.68 | rem mins   695 | loss 3.00907 | ppl  20.2685\n",
    "Learning rate: [0.00017250879999999998]\n",
    "29700/99489 batches | batch/sec  1.67 | rem mins   694 | loss 3.01846 | ppl  20.4597\n",
    "Learning rate: [0.00017538879999999998]\n",
    "29800/99489 batches | batch/sec  1.67 | rem mins   694 | loss 3.02782 | ppl  20.6522\n",
    "Learning rate: [0.0001782688]\n",
    "29900/99489 batches | batch/sec  1.67 | rem mins   693 | loss 2.99067 | ppl  19.8989\n",
    "Learning rate: [0.0001811488]\n",
    "30000/99489 batches | batch/sec  1.67 | rem mins   692 | loss 3.02044 | ppl  20.5003\n",
    "Learning rate: [0.0001840288]\n",
    "30100/99489 batches | batch/sec  1.67 | rem mins   692 | loss 3.01446 | ppl  20.3781\n",
    "Learning rate: [0.0001869088]\n",
    "30200/99489 batches | batch/sec  1.67 | rem mins   690 | loss 2.99230 | ppl  19.9315\n",
    "Learning rate: [0.0001897888]\n",
    "30300/99489 batches | batch/sec  1.67 | rem mins   689 | loss 2.99336 | ppl  19.9527\n",
    "Learning rate: [0.0001926688]\n",
    "30400/99489 batches | batch/sec  1.67 | rem mins   689 | loss 3.00173 | ppl  20.1204\n",
    "Learning rate: [0.0001955488]\n",
    "30500/99489 batches | batch/sec  1.67 | rem mins   687 | loss 3.00403 | ppl  20.1666\n",
    "Learning rate: [0.0001984288]\n",
    "30600/99489 batches | batch/sec  1.67 | rem mins   686 | loss 3.01305 | ppl  20.3494\n",
    "Learning rate: [0.0002013088]\n",
    "30700/99489 batches | batch/sec  1.68 | rem mins   684 | loss 3.00005 | ppl  20.0866\n",
    "Learning rate: [0.00020418880000000003]\n",
    "30800/99489 batches | batch/sec  1.68 | rem mins   683 | loss 2.98225 | ppl  19.7321\n",
    "Learning rate: [0.00020706880000000003]\n",
    "30900/99489 batches | batch/sec  1.68 | rem mins   682 | loss 2.99840 | ppl  20.0535\n",
    "Learning rate: [0.00020994880000000003]\n",
    "31000/99489 batches | batch/sec  1.68 | rem mins   681 | loss 2.99225 | ppl  19.9304\n",
    "Learning rate: [0.00021282880000000003]\n",
    "31100/99489 batches | batch/sec  1.68 | rem mins   680 | loss 3.00525 | ppl  20.1912\n",
    "Learning rate: [0.00021570880000000003]\n",
    "31200/99489 batches | batch/sec  1.68 | rem mins   679 | loss 3.01668 | ppl  20.4233\n",
    "Learning rate: [0.00021858880000000003]\n",
    "31300/99489 batches | batch/sec  1.68 | rem mins   678 | loss 2.99582 | ppl  20.0019\n",
    "Learning rate: [0.00022146880000000003]\n",
    "31400/99489 batches | batch/sec  1.68 | rem mins   677 | loss 2.99068 | ppl  19.8993\n",
    "Learning rate: [0.00022434880000000003]\n",
    "31500/99489 batches | batch/sec  1.68 | rem mins   676 | loss 2.99647 | ppl  20.0148\n",
    "Learning rate: [0.00022722880000000006]\n",
    "31600/99489 batches | batch/sec  1.67 | rem mins   676 | loss 3.00720 | ppl  20.2307\n",
    "Learning rate: [0.00023010880000000006]\n",
    "31700/99489 batches | batch/sec  1.68 | rem mins   674 | loss 2.99479 | ppl  19.9812\n",
    "Learning rate: [0.00023298880000000006]\n",
    "31800/99489 batches | batch/sec  1.68 | rem mins   673 | loss 3.00829 | ppl  20.2527\n",
    "Learning rate: [0.00023586880000000005]\n",
    "31900/99489 batches | batch/sec  1.68 | rem mins   672 | loss 2.99187 | ppl  19.9230\n",
    "Learning rate: [0.00023874880000000005]\n",
    "32000/99489 batches | batch/sec  1.68 | rem mins   671 | loss 2.99863 | ppl  20.0580\n",
    "Learning rate: [0.00024162880000000005]\n",
    "32100/99489 batches | batch/sec  1.68 | rem mins   670 | loss 3.00124 | ppl  20.1105\n",
    "Learning rate: [0.00024450880000000005]\n",
    "32200/99489 batches | batch/sec  1.68 | rem mins   669 | loss 3.01374 | ppl  20.3635\n",
    "Learning rate: [0.0002473888000000001]\n",
    "32300/99489 batches | batch/sec  1.67 | rem mins   669 | loss 3.01195 | ppl  20.3269\n",
    "Learning rate: [0.00025026880000000005]\n",
    "32400/99489 batches | batch/sec  1.68 | rem mins   667 | loss 3.01647 | ppl  20.4191\n",
    "Learning rate: [0.0002531488000000001]\n",
    "32500/99489 batches | batch/sec  1.68 | rem mins   666 | loss 3.00425 | ppl  20.1710\n",
    "Learning rate: [0.0002560288000000001]\n",
    "32600/99489 batches | batch/sec  1.68 | rem mins   665 | loss 3.00382 | ppl  20.1624\n",
    "Learning rate: [0.0002589088000000001]\n",
    "32700/99489 batches | batch/sec  1.68 | rem mins   664 | loss 3.00692 | ppl  20.2251\n",
    "Learning rate: [0.0002617888000000001]\n",
    "32800/99489 batches | batch/sec  1.68 | rem mins   663 | loss 3.00790 | ppl  20.2449\n",
    "Learning rate: [0.0002646688000000001]\n",
    "32900/99489 batches | batch/sec  1.67 | rem mins   663 | loss 3.01220 | ppl  20.3320\n",
    "Learning rate: [0.0002675488000000001]\n",
    "33000/99489 batches | batch/sec  1.68 | rem mins   661 | loss 3.01281 | ppl  20.3446\n",
    "Learning rate: [0.0002704288000000001]\n",
    "33100/99489 batches | batch/sec  1.68 | rem mins   660 | loss 3.00432 | ppl  20.1726\n",
    "Learning rate: [0.0002733088000000001]\n",
    "33200/99489 batches | batch/sec  1.67 | rem mins   660 | loss 2.99111 | ppl  19.9077\n",
    "Learning rate: [0.00027618880000000013]\n",
    "33300/99489 batches | batch/sec  1.68 | rem mins   658 | loss 3.01064 | ppl  20.3004\n",
    "Learning rate: [0.0002790688000000001]\n",
    "33400/99489 batches | batch/sec  1.68 | rem mins   657 | loss 3.01399 | ppl  20.3685\n",
    "Learning rate: [0.0002819487999999998]\n",
    "33500/99489 batches | batch/sec  1.68 | rem mins   656 | loss 3.00042 | ppl  20.0939\n",
    "Learning rate: [0.0002848288000000001]\n",
    "33600/99489 batches | batch/sec  1.68 | rem mins   655 | loss 3.02769 | ppl  20.6495\n",
    "Learning rate: [0.0002877087999999998]\n",
    "33700/99489 batches | batch/sec  1.68 | rem mins   654 | loss 2.97167 | ppl  19.5245\n",
    "Learning rate: [0.0002905888000000001]\n",
    "33800/99489 batches | batch/sec  1.68 | rem mins   653 | loss 2.99575 | ppl  20.0004\n",
    "Learning rate: [0.0002934687999999998]\n",
    "33900/99489 batches | batch/sec  1.68 | rem mins   652 | loss 2.98987 | ppl  19.8831\n",
    "Learning rate: [0.0002963488000000001]\n",
    "34000/99489 batches | batch/sec  1.68 | rem mins   651 | loss 2.99739 | ppl  20.0333\n",
    "Learning rate: [0.0002992287999999998]\n",
    "34100/99489 batches | batch/sec  1.68 | rem mins   650 | loss 3.00851 | ppl  20.2572\n",
    "Learning rate: [0.0003021088000000001]\n",
    "34200/99489 batches | batch/sec  1.67 | rem mins   650 | loss 3.00851 | ppl  20.2573\n",
    "Learning rate: [0.0003049887999999998]\n",
    "34300/99489 batches | batch/sec  1.67 | rem mins   649 | loss 3.00349 | ppl  20.1558\n",
    "Learning rate: [0.0003078688000000001]\n",
    "34400/99489 batches | batch/sec  1.68 | rem mins   648 | loss 3.00334 | ppl  20.1528\n",
    "Learning rate: [0.0003107487999999998]\n",
    "34500/99489 batches | batch/sec  1.67 | rem mins   647 | loss 3.02160 | ppl  20.5241\n",
    "Learning rate: [0.00031362880000000015]\n",
    "34600/99489 batches | batch/sec  1.68 | rem mins   646 | loss 2.99677 | ppl  20.0207\n",
    "Learning rate: [0.0003165087999999998]\n",
    "34700/99489 batches | batch/sec  1.67 | rem mins   645 | loss 2.99685 | ppl  20.0224\n",
    "Learning rate: [0.00031938880000000015]\n",
    "34800/99489 batches | batch/sec  1.67 | rem mins   644 | loss 2.99833 | ppl  20.0520\n",
    "Learning rate: [0.0003222687999999998]\n",
    "34900/99489 batches | batch/sec  1.67 | rem mins   643 | loss 2.98146 | ppl  19.7167\n",
    "Learning rate: [0.00032514880000000015]\n",
    "35000/99489 batches | batch/sec  1.67 | rem mins   642 | loss 3.00147 | ppl  20.1151\n",
    "Learning rate: [0.0003280287999999998]\n",
    "35100/99489 batches | batch/sec  1.67 | rem mins   641 | loss 3.01671 | ppl  20.4241\n",
    "Learning rate: [0.00033090880000000015]\n",
    "35200/99489 batches | batch/sec  1.67 | rem mins   640 | loss 3.02141 | ppl  20.5201\n",
    "Learning rate: [0.00033378879999999985]\n",
    "35300/99489 batches | batch/sec  1.67 | rem mins   639 | loss 3.01815 | ppl  20.4534\n",
    "Learning rate: [0.00033666880000000015]\n",
    "35400/99489 batches | batch/sec  1.67 | rem mins   638 | loss 3.01121 | ppl  20.3120\n",
    "Learning rate: [0.00033954879999999985]\n",
    "35500/99489 batches | batch/sec  1.67 | rem mins   637 | loss 3.00146 | ppl  20.1148\n",
    "Learning rate: [0.00034242880000000015]\n",
    "35600/99489 batches | batch/sec  1.67 | rem mins   636 | loss 3.01323 | ppl  20.3530\n",
    "Learning rate: [0.00034530879999999985]\n",
    "35700/99489 batches | batch/sec  1.67 | rem mins   635 | loss 2.99524 | ppl  19.9902\n",
    "Learning rate: [0.00034818880000000014]\n",
    "35800/99489 batches | batch/sec  1.67 | rem mins   634 | loss 3.00303 | ppl  20.1464\n",
    "Learning rate: [0.00035106879999999985]\n",
    "35900/99489 batches | batch/sec  1.67 | rem mins   633 | loss 3.01000 | ppl  20.2875\n",
    "Learning rate: [0.00035394880000000014]\n",
    "36000/99489 batches | batch/sec  1.67 | rem mins   632 | loss 3.00417 | ppl  20.1694\n",
    "Learning rate: [0.00035682879999999985]\n",
    "36100/99489 batches | batch/sec  1.67 | rem mins   631 | loss 2.98463 | ppl  19.7791\n",
    "Learning rate: [0.00035970880000000014]\n",
    "36200/99489 batches | batch/sec  1.67 | rem mins   630 | loss 3.01208 | ppl  20.3297\n",
    "Learning rate: [0.00036258879999999984]\n",
    "36300/99489 batches | batch/sec  1.67 | rem mins   629 | loss 2.99278 | ppl  19.9410\n",
    "Learning rate: [0.0003654688000000002]\n",
    "36400/99489 batches | batch/sec  1.67 | rem mins   629 | loss 3.00426 | ppl  20.1712\n",
    "Learning rate: [0.00036834879999999984]\n",
    "36500/99489 batches | batch/sec  1.67 | rem mins   627 | loss 3.00324 | ppl  20.1508\n",
    "Learning rate: [0.0003712288000000002]\n",
    "36600/99489 batches | batch/sec  1.67 | rem mins   626 | loss 2.98820 | ppl  19.8499\n",
    "Learning rate: [0.00037410879999999984]\n",
    "36700/99489 batches | batch/sec  1.67 | rem mins   625 | loss 3.00771 | ppl  20.2411\n",
    "Learning rate: [0.0003769888000000002]\n",
    "36800/99489 batches | batch/sec  1.67 | rem mins   624 | loss 3.00171 | ppl  20.1198\n",
    "Learning rate: [0.0003798687999999999]\n",
    "36900/99489 batches | batch/sec  1.67 | rem mins   623 | loss 3.02352 | ppl  20.5636\n",
    "Learning rate: [0.0003827488000000002]\n",
    "37000/99489 batches | batch/sec  1.67 | rem mins   623 | loss 3.00425 | ppl  20.1710\n",
    "Learning rate: [0.0003856287999999999]\n",
    "37100/99489 batches | batch/sec  1.67 | rem mins   621 | loss 2.99964 | ppl  20.0783\n",
    "Learning rate: [0.0003885088000000002]\n",
    "37200/99489 batches | batch/sec  1.67 | rem mins   620 | loss 2.99455 | ppl  19.9763\n",
    "Learning rate: [0.0003913887999999999]\n",
    "37300/99489 batches | batch/sec  1.67 | rem mins   619 | loss 2.99723 | ppl  20.0300\n",
    "Learning rate: [0.0003942688000000002]\n",
    "37400/99489 batches | batch/sec  1.67 | rem mins   618 | loss 2.99016 | ppl  19.8889\n",
    "Learning rate: [0.0003971487999999999]\n",
    "37500/99489 batches | batch/sec  1.67 | rem mins   617 | loss 3.01110 | ppl  20.3096\n",
    "Learning rate: [0.00039997119999999985]\n",
    "37600/99489 batches | batch/sec  1.68 | rem mins   616 | loss 3.00177 | ppl  20.1211\n",
    "Learning rate: [0.00039709120000000015]\n",
    "37700/99489 batches | batch/sec  1.67 | rem mins   615 | loss 2.99427 | ppl  19.9707\n",
    "Learning rate: [0.00039421119999999985]\n",
    "37800/99489 batches | batch/sec  1.67 | rem mins   614 | loss 2.99758 | ppl  20.0370\n",
    "Learning rate: [0.00039133120000000015]\n",
    "37900/99489 batches | batch/sec  1.67 | rem mins   613 | loss 3.00634 | ppl  20.2133\n",
    "Learning rate: [0.0003884511999999998]\n",
    "38000/99489 batches | batch/sec  1.67 | rem mins   613 | loss 3.00813 | ppl  20.2495\n",
    "Learning rate: [0.00038557120000000015]\n",
    "38100/99489 batches | batch/sec  1.67 | rem mins   611 | loss 3.00297 | ppl  20.1453\n",
    "Learning rate: [0.0003826911999999998]\n",
    "38200/99489 batches | batch/sec  1.67 | rem mins   611 | loss 3.00473 | ppl  20.1807\n",
    "Learning rate: [0.00037981120000000015]\n",
    "38300/99489 batches | batch/sec  1.67 | rem mins   609 | loss 3.00474 | ppl  20.1811\n",
    "Learning rate: [0.0003769311999999998]\n",
    "38400/99489 batches | batch/sec  1.67 | rem mins   608 | loss 2.99676 | ppl  20.0206\n",
    "Learning rate: [0.00037405120000000015]\n",
    "38500/99489 batches | batch/sec  1.67 | rem mins   607 | loss 3.00408 | ppl  20.1677\n",
    "Learning rate: [0.0003711711999999998]\n",
    "38600/99489 batches | batch/sec  1.67 | rem mins   606 | loss 3.02143 | ppl  20.5206\n",
    "Learning rate: [0.0003682912000000001]\n",
    "38700/99489 batches | batch/sec  1.67 | rem mins   606 | loss 2.99425 | ppl  19.9704\n",
    "Learning rate: [0.0003654111999999998]\n",
    "38800/99489 batches | batch/sec  1.67 | rem mins   604 | loss 3.00683 | ppl  20.2232\n",
    "Learning rate: [0.0003625312000000001]\n",
    "38900/99489 batches | batch/sec  1.67 | rem mins   604 | loss 3.00694 | ppl  20.2254\n",
    "Learning rate: [0.0003596511999999998]\n",
    "39000/99489 batches | batch/sec  1.67 | rem mins   602 | loss 3.02083 | ppl  20.5084\n",
    "Learning rate: [0.0003567712000000001]\n",
    "39100/99489 batches | batch/sec  1.67 | rem mins   601 | loss 3.01219 | ppl  20.3319\n",
    "Learning rate: [0.0003538911999999998]\n",
    "39200/99489 batches | batch/sec  1.67 | rem mins   600 | loss 3.00208 | ppl  20.1273\n",
    "Learning rate: [0.0003510112000000001]\n",
    "39300/99489 batches | batch/sec  1.67 | rem mins   599 | loss 3.01087 | ppl  20.3050\n",
    "Learning rate: [0.0003481311999999998]\n",
    "39400/99489 batches | batch/sec  1.67 | rem mins   598 | loss 2.99192 | ppl  19.9238\n",
    "Learning rate: [0.0003452512000000001]\n",
    "39500/99489 batches | batch/sec  1.67 | rem mins   597 | loss 3.01226 | ppl  20.3333\n",
    "Learning rate: [0.0003423712000000001]\n",
    "39600/99489 batches | batch/sec  1.67 | rem mins   596 | loss 2.99622 | ppl  20.0098\n",
    "Learning rate: [0.0003394912000000001]\n",
    "39700/99489 batches | batch/sec  1.67 | rem mins   596 | loss 3.01225 | ppl  20.3332\n",
    "Learning rate: [0.0003366112000000001]\n",
    "39800/99489 batches | batch/sec  1.67 | rem mins   594 | loss 2.99780 | ppl  20.0413\n",
    "Learning rate: [0.0003337312000000001]\n",
    "39900/99489 batches | batch/sec  1.67 | rem mins   594 | loss 3.00226 | ppl  20.1310\n",
    "Learning rate: [0.0003308512000000001]\n",
    "40000/99489 batches | batch/sec  1.67 | rem mins   592 | loss 2.99222 | ppl  19.9298\n",
    "Learning rate: [0.0003279712000000001]\n",
    "40100/99489 batches | batch/sec  1.67 | rem mins   591 | loss 3.00486 | ppl  20.1834\n",
    "Learning rate: [0.0003250912000000001]\n",
    "40200/99489 batches | batch/sec  1.67 | rem mins   590 | loss 3.00035 | ppl  20.0926\n",
    "Learning rate: [0.00032221120000000005]\n",
    "40300/99489 batches | batch/sec  1.67 | rem mins   589 | loss 3.00988 | ppl  20.2849\n",
    "Learning rate: [0.0003193312000000001]\n",
    "40400/99489 batches | batch/sec  1.67 | rem mins   588 | loss 2.99946 | ppl  20.0748\n",
    "Learning rate: [0.00031645120000000005]\n",
    "40500/99489 batches | batch/sec  1.67 | rem mins   587 | loss 3.00245 | ppl  20.1348\n",
    "Learning rate: [0.0003135712000000001]\n",
    "40600/99489 batches | batch/sec  1.68 | rem mins   586 | loss 3.01027 | ppl  20.2929\n",
    "Learning rate: [0.00031069120000000005]\n",
    "40700/99489 batches | batch/sec  1.67 | rem mins   585 | loss 3.00250 | ppl  20.1358\n",
    "Learning rate: [0.0003078112000000001]\n",
    "40800/99489 batches | batch/sec  1.67 | rem mins   585 | loss 3.00175 | ppl  20.1207\n",
    "Learning rate: [0.00030493120000000005]\n",
    "40900/99489 batches | batch/sec  1.67 | rem mins   583 | loss 3.01936 | ppl  20.4781\n",
    "Learning rate: [0.0003020512000000001]\n",
    "41000/99489 batches | batch/sec  1.67 | rem mins   582 | loss 3.00461 | ppl  20.1783\n",
    "Learning rate: [0.00029917120000000005]\n",
    "41100/99489 batches | batch/sec  1.67 | rem mins   581 | loss 3.00943 | ppl  20.2757\n",
    "Learning rate: [0.00029629120000000003]\n",
    "41200/99489 batches | batch/sec  1.67 | rem mins   580 | loss 3.02570 | ppl  20.6084\n",
    "Learning rate: [0.00029341120000000005]\n",
    "41300/99489 batches | batch/sec  1.67 | rem mins   579 | loss 3.00547 | ppl  20.1957\n",
    "Learning rate: [0.00029053120000000003]\n",
    "41400/99489 batches | batch/sec  1.67 | rem mins   579 | loss 2.98896 | ppl  19.8650\n",
    "Learning rate: [0.00028765120000000006]\n",
    "41500/99489 batches | batch/sec  1.67 | rem mins   577 | loss 3.00012 | ppl  20.0879\n",
    "Learning rate: [0.00028477120000000003]\n",
    "41600/99489 batches | batch/sec  1.67 | rem mins   577 | loss 3.00662 | ppl  20.2190\n",
    "Learning rate: [0.00028189120000000006]\n",
    "41700/99489 batches | batch/sec  1.67 | rem mins   576 | loss 2.99154 | ppl  19.9164\n",
    "Learning rate: [0.00027901120000000003]\n",
    "41800/99489 batches | batch/sec  1.67 | rem mins   575 | loss 3.00563 | ppl  20.1990\n",
    "Learning rate: [0.00027613120000000006]\n",
    "41900/99489 batches | batch/sec  1.67 | rem mins   574 | loss 3.00711 | ppl  20.2288\n",
    "Learning rate: [0.00027325120000000003]\n",
    "42000/99489 batches | batch/sec  1.67 | rem mins   573 | loss 3.00717 | ppl  20.2301\n",
    "Learning rate: [0.00027037120000000006]\n",
    "42100/99489 batches | batch/sec  1.67 | rem mins   572 | loss 3.00371 | ppl  20.1603\n",
    "Learning rate: [0.00026749120000000003]\n",
    "42200/99489 batches | batch/sec  1.67 | rem mins   571 | loss 2.99716 | ppl  20.0286\n",
    "Learning rate: [0.00026461120000000006]\n",
    "42300/99489 batches | batch/sec  1.67 | rem mins   570 | loss 3.00364 | ppl  20.1587\n",
    "Learning rate: [0.00026173120000000003]\n",
    "42400/99489 batches | batch/sec  1.67 | rem mins   569 | loss 3.01454 | ppl  20.3797\n",
    "Learning rate: [0.0002588512]\n",
    "42500/99489 batches | batch/sec  1.67 | rem mins   568 | loss 3.00740 | ppl  20.2348\n",
    "Learning rate: [0.00025597120000000003]\n",
    "42600/99489 batches | batch/sec  1.67 | rem mins   567 | loss 2.99997 | ppl  20.0849\n",
    "Learning rate: [0.0002530912]\n",
    "42700/99489 batches | batch/sec  1.67 | rem mins   567 | loss 2.98507 | ppl  19.7879\n",
    "Learning rate: [0.00025021120000000003]\n",
    "42800/99489 batches | batch/sec  1.67 | rem mins   565 | loss 3.01259 | ppl  20.3400\n",
    "Learning rate: [0.0002473312]\n",
    "42900/99489 batches | batch/sec  1.67 | rem mins   564 | loss 3.00287 | ppl  20.1432\n",
    "Learning rate: [0.00024445120000000004]\n",
    "43000/99489 batches | batch/sec  1.67 | rem mins   563 | loss 3.00872 | ppl  20.2614\n",
    "Learning rate: [0.0002415712]\n",
    "43100/99489 batches | batch/sec  1.67 | rem mins   563 | loss 3.01705 | ppl  20.4310\n",
    "Learning rate: [0.0002386912]\n",
    "43200/99489 batches | batch/sec  1.67 | rem mins   561 | loss 2.99901 | ppl  20.0657\n",
    "Learning rate: [0.00023581119999999998]\n",
    "43300/99489 batches | batch/sec  1.67 | rem mins   560 | loss 3.02478 | ppl  20.5894\n",
    "Learning rate: [0.00023293119999999998]\n",
    "43400/99489 batches | batch/sec  1.67 | rem mins   559 | loss 3.00521 | ppl  20.1905\n",
    "Learning rate: [0.00023005119999999998]\n",
    "43500/99489 batches | batch/sec  1.67 | rem mins   558 | loss 3.02299 | ppl  20.5526\n",
    "Learning rate: [0.00022717119999999998]\n",
    "43600/99489 batches | batch/sec  1.67 | rem mins   558 | loss 2.99202 | ppl  19.9259\n",
    "Learning rate: [0.00022429119999999998]\n",
    "43700/99489 batches | batch/sec  1.67 | rem mins   557 | loss 2.99846 | ppl  20.0546\n",
    "Learning rate: [0.00022141119999999999]\n",
    "43800/99489 batches | batch/sec  1.67 | rem mins   555 | loss 3.00221 | ppl  20.1300\n",
    "Learning rate: [0.00021853119999999999]\n",
    "43900/99489 batches | batch/sec  1.67 | rem mins   554 | loss 3.00271 | ppl  20.1400\n",
    "Learning rate: [0.00021565119999999999]\n",
    "44000/99489 batches | batch/sec  1.67 | rem mins   554 | loss 3.00424 | ppl  20.1709\n",
    "Learning rate: [0.00021277119999999996]\n",
    "44100/99489 batches | batch/sec  1.67 | rem mins   552 | loss 3.01786 | ppl  20.4474\n",
    "Learning rate: [0.00020989119999999996]\n",
    "44200/99489 batches | batch/sec  1.67 | rem mins   551 | loss 2.99714 | ppl  20.0282\n",
    "Learning rate: [0.00020701119999999996]\n",
    "44300/99489 batches | batch/sec  1.67 | rem mins   550 | loss 3.01904 | ppl  20.4715\n",
    "Learning rate: [0.00020413119999999996]\n",
    "44400/99489 batches | batch/sec  1.67 | rem mins   549 | loss 2.99413 | ppl  19.9679\n",
    "Learning rate: [0.00020125119999999996]\n",
    "44500/99489 batches | batch/sec  1.67 | rem mins   549 | loss 3.00500 | ppl  20.1862\n",
    "Learning rate: [0.00019837119999999996]\n",
    "44600/99489 batches | batch/sec  1.67 | rem mins   548 | loss 3.00521 | ppl  20.1904\n",
    "Learning rate: [0.00019549119999999996]\n",
    "44700/99489 batches | batch/sec  1.67 | rem mins   546 | loss 2.99797 | ppl  20.0448\n",
    "Learning rate: [0.00019261119999999996]\n",
    "44800/99489 batches | batch/sec  1.67 | rem mins   545 | loss 3.01523 | ppl  20.3938\n",
    "Learning rate: [0.00018973119999999996]\n",
    "44900/99489 batches | batch/sec  1.67 | rem mins   544 | loss 3.01560 | ppl  20.4013\n",
    "Learning rate: [0.00018685119999999994]\n",
    "45000/99489 batches | batch/sec  1.67 | rem mins   543 | loss 3.01410 | ppl  20.3707\n",
    "Learning rate: [0.00018397119999999994]\n",
    "45100/99489 batches | batch/sec  1.67 | rem mins   542 | loss 2.99734 | ppl  20.0322\n",
    "Learning rate: [0.00018109119999999994]\n",
    "45200/99489 batches | batch/sec  1.67 | rem mins   542 | loss 2.99227 | ppl  19.9309\n",
    "Learning rate: [0.00017821119999999994]\n",
    "45300/99489 batches | batch/sec  1.67 | rem mins   540 | loss 3.00946 | ppl  20.2764\n",
    "Learning rate: [0.00017533119999999994]\n",
    "45400/99489 batches | batch/sec  1.67 | rem mins   540 | loss 2.99757 | ppl  20.0369\n",
    "Learning rate: [0.00017245119999999994]\n",
    "45500/99489 batches | batch/sec  1.67 | rem mins   539 | loss 3.00827 | ppl  20.2523\n",
    "Learning rate: [0.00016957119999999994]\n",
    "45600/99489 batches | batch/sec  1.67 | rem mins   538 | loss 3.01992 | ppl  20.4896\n",
    "Learning rate: [0.00016669119999999994]\n",
    "45700/99489 batches | batch/sec  1.67 | rem mins   536 | loss 3.00105 | ppl  20.1067\n",
    "Learning rate: [0.0001638111999999999]\n",
    "45800/99489 batches | batch/sec  1.67 | rem mins   535 | loss 3.03499 | ppl  20.8008\n",
    "Learning rate: [0.00016093119999999994]\n",
    "45900/99489 batches | batch/sec  1.67 | rem mins   535 | loss 3.01315 | ppl  20.3515\n",
    "Learning rate: [0.00015805120000000024]\n",
    "46000/99489 batches | batch/sec  1.67 | rem mins   533 | loss 3.01341 | ppl  20.3566\n",
    "Learning rate: [0.00015517119999999991]\n",
    "46100/99489 batches | batch/sec  1.67 | rem mins   533 | loss 3.00432 | ppl  20.1726\n",
    "Learning rate: [0.00015229120000000024]\n",
    "46200/99489 batches | batch/sec  1.67 | rem mins   531 | loss 2.99762 | ppl  20.0377\n",
    "Learning rate: [0.00014941119999999992]\n",
    "46300/99489 batches | batch/sec  1.67 | rem mins   531 | loss 3.01105 | ppl  20.3087\n",
    "Learning rate: [0.00014653120000000024]\n",
    "46400/99489 batches | batch/sec  1.67 | rem mins   529 | loss 3.00122 | ppl  20.1101\n",
    "Learning rate: [0.00014365119999999992]\n",
    "46500/99489 batches | batch/sec  1.67 | rem mins   529 | loss 3.00132 | ppl  20.1121\n",
    "Learning rate: [0.00014077120000000024]\n",
    "46600/99489 batches | batch/sec  1.67 | rem mins   527 | loss 2.99682 | ppl  20.0218\n",
    "Learning rate: [0.00013789119999999992]\n",
    "46700/99489 batches | batch/sec  1.67 | rem mins   526 | loss 3.00485 | ppl  20.1832\n",
    "Learning rate: [0.00013501120000000022]\n",
    "46800/99489 batches | batch/sec  1.67 | rem mins   525 | loss 3.00151 | ppl  20.1158\n",
    "Learning rate: [0.0001321311999999999]\n",
    "46900/99489 batches | batch/sec  1.67 | rem mins   524 | loss 2.99778 | ppl  20.0411\n",
    "Learning rate: [0.00012925120000000022]\n",
    "47000/99489 batches | batch/sec  1.67 | rem mins   524 | loss 3.00742 | ppl  20.2352\n",
    "Learning rate: [0.0001263711999999999]\n",
    "47100/99489 batches | batch/sec  1.67 | rem mins   522 | loss 3.00531 | ppl  20.1924\n",
    "Learning rate: [0.00012349120000000022]\n",
    "47200/99489 batches | batch/sec  1.67 | rem mins   521 | loss 3.00855 | ppl  20.2580\n",
    "Learning rate: [0.00012061119999999989]\n",
    "47300/99489 batches | batch/sec  1.67 | rem mins   520 | loss 2.99250 | ppl  19.9355\n",
    "Learning rate: [0.00011773120000000022]\n",
    "47400/99489 batches | batch/sec  1.67 | rem mins   519 | loss 3.01933 | ppl  20.4777\n",
    "Learning rate: [0.0001148511999999999]\n",
    "47500/99489 batches | batch/sec  1.67 | rem mins   519 | loss 3.01195 | ppl  20.3271\n",
    "Learning rate: [0.00011197120000000019]\n",
    "47600/99489 batches | batch/sec  1.67 | rem mins   518 | loss 2.98684 | ppl  19.8229\n",
    "Learning rate: [0.00010909119999999987]\n",
    "47700/99489 batches | batch/sec  1.67 | rem mins   516 | loss 3.01025 | ppl  20.2925\n",
    "Learning rate: [0.0001062112000000002]\n",
    "47800/99489 batches | batch/sec  1.67 | rem mins   516 | loss 3.00136 | ppl  20.1128\n",
    "Learning rate: [0.00010333119999999987]\n",
    "47900/99489 batches | batch/sec  1.67 | rem mins   514 | loss 3.00461 | ppl  20.1783\n",
    "Learning rate: [0.0001004512000000002]\n",
    "48000/99489 batches | batch/sec  1.67 | rem mins   514 | loss 3.01098 | ppl  20.3073\n",
    "Learning rate: [9.757119999999987e-05]\n",
    "48100/99489 batches | batch/sec  1.67 | rem mins   512 | loss 3.00262 | ppl  20.1382\n",
    "Learning rate: [9.46912000000002e-05]\n",
    "48200/99489 batches | batch/sec  1.67 | rem mins   511 | loss 3.03976 | ppl  20.9001\n",
    "Learning rate: [9.181119999999987e-05]\n",
    "48300/99489 batches | batch/sec  1.67 | rem mins   510 | loss 3.01353 | ppl  20.3591\n",
    "Learning rate: [8.893120000000018e-05]\n",
    "48400/99489 batches | batch/sec  1.67 | rem mins   510 | loss 2.99551 | ppl  19.9955\n",
    "Learning rate: [8.605119999999986e-05]\n",
    "48500/99489 batches | batch/sec  1.67 | rem mins   508 | loss 3.00342 | ppl  20.1544\n",
    "Learning rate: [8.317120000000017e-05]\n",
    "48600/99489 batches | batch/sec  1.67 | rem mins   507 | loss 2.99305 | ppl  19.9463\n",
    "Learning rate: [8.029119999999985e-05]\n",
    "48700/99489 batches | batch/sec  1.67 | rem mins   507 | loss 2.98034 | ppl  19.6944\n",
    "Learning rate: [7.741120000000017e-05]\n",
    "48800/99489 batches | batch/sec  1.67 | rem mins   506 | loss 2.99592 | ppl  20.0038\n",
    "Learning rate: [7.453119999999985e-05]\n",
    "48900/99489 batches | batch/sec  1.67 | rem mins   505 | loss 3.00385 | ppl  20.1630\n",
    "Learning rate: [7.165120000000017e-05]\n",
    "49000/99489 batches | batch/sec  1.67 | rem mins   503 | loss 2.99430 | ppl  19.9714\n",
    "Learning rate: [6.877119999999985e-05]\n",
    "49100/99489 batches | batch/sec  1.67 | rem mins   503 | loss 3.01374 | ppl  20.3633\n",
    "Learning rate: [6.589120000000016e-05]\n",
    "49200/99489 batches | batch/sec  1.67 | rem mins   502 | loss 2.99201 | ppl  19.9257\n",
    "Learning rate: [6.301119999999983e-05]\n",
    "49300/99489 batches | batch/sec  1.67 | rem mins   501 | loss 3.00361 | ppl  20.1582\n",
    "Learning rate: [6.0131200000000154e-05]\n",
    "49400/99489 batches | batch/sec  1.67 | rem mins   500 | loss 2.98420 | ppl  19.7706\n",
    "Learning rate: [5.7251199999999836e-05]\n",
    "49500/99489 batches | batch/sec  1.67 | rem mins   498 | loss 2.98923 | ppl  19.8705\n",
    "Learning rate: [5.437120000000015e-05]\n",
    "49600/99489 batches | batch/sec  1.67 | rem mins   498 | loss 3.00641 | ppl  20.2147\n",
    "Learning rate: [5.149119999999982e-05]\n",
    "49700/99489 batches | batch/sec  1.67 | rem mins   496 | loss 3.01005 | ppl  20.2884\n",
    "Learning rate: [4.861120000000014e-05]\n",
    "50000/99489 batches | batch/sec  1.67 | rem mins   493 | loss 3.00357 | ppl  20.1574\n",
    "Learning rate: [4.002879999999987e-05]\n",
    "50100/99489 batches | batch/sec  1.67 | rem mins   492 | loss 3.01549 | ppl  20.3990\n",
    "Learning rate: [4.2908799999999876e-05]\n",
    "50200/99489 batches | batch/sec  1.67 | rem mins   491 | loss 2.99915 | ppl  20.0684\n",
    "Learning rate: [4.5788799999999876e-05]\n",
    "50300/99489 batches | batch/sec  1.67 | rem mins   491 | loss 3.03219 | ppl  20.7426\n",
    "Learning rate: [4.866879999999988e-05]\n",
    "50400/99489 batches | batch/sec  1.67 | rem mins   490 | loss 3.01144 | ppl  20.3166\n",
    "Learning rate: [5.154879999999988e-05]\n",
    "50500/99489 batches | batch/sec  1.67 | rem mins   489 | loss 3.00632 | ppl  20.2129\n",
    "Learning rate: [5.442879999999989e-05]\n",
    "50600/99489 batches | batch/sec  1.67 | rem mins   487 | loss 3.01502 | ppl  20.3894\n",
    "Learning rate: [5.730879999999989e-05]\n",
    "50700/99489 batches | batch/sec  1.67 | rem mins   486 | loss 3.01122 | ppl  20.3121\n",
    "Learning rate: [6.0188799999999894e-05]\n",
    "50800/99489 batches | batch/sec  1.67 | rem mins   486 | loss 3.01616 | ppl  20.4127\n",
    "Learning rate: [6.30687999999999e-05]\n",
    "50900/99489 batches | batch/sec  1.67 | rem mins   484 | loss 3.00491 | ppl  20.1845\n",
    "Learning rate: [6.594879999999989e-05]\n",
    "51000/99489 batches | batch/sec  1.67 | rem mins   483 | loss 2.98963 | ppl  19.8783\n",
    "Learning rate: [6.882879999999989e-05]\n",
    "51100/99489 batches | batch/sec  1.67 | rem mins   483 | loss 3.00897 | ppl  20.2665\n",
    "Learning rate: [7.17087999999999e-05]\n",
    "51200/99489 batches | batch/sec  1.67 | rem mins   482 | loss 3.00639 | ppl  20.2144\n",
    "Learning rate: [7.45887999999999e-05]\n",
    "51300/99489 batches | batch/sec  1.67 | rem mins   481 | loss 2.99435 | ppl  19.9724\n",
    "Learning rate: [7.74687999999999e-05]\n",
    "51400/99489 batches | batch/sec  1.67 | rem mins   479 | loss 3.00621 | ppl  20.2107\n",
    "Learning rate: [8.034879999999992e-05]\n",
    "51500/99489 batches | batch/sec  1.67 | rem mins   479 | loss 2.99953 | ppl  20.0762\n",
    "Learning rate: [8.322879999999992e-05]\n",
    "51600/99489 batches | batch/sec  1.67 | rem mins   478 | loss 2.99639 | ppl  20.0131\n",
    "Learning rate: [8.610879999999992e-05]\n",
    "51700/99489 batches | batch/sec  1.67 | rem mins   477 | loss 3.00662 | ppl  20.2190\n",
    "Learning rate: [8.898879999999992e-05]\n",
    "51800/99489 batches | batch/sec  1.67 | rem mins   475 | loss 3.00979 | ppl  20.2830\n",
    "Learning rate: [9.186879999999992e-05]\n",
    "51900/99489 batches | batch/sec  1.67 | rem mins   475 | loss 3.01357 | ppl  20.3600\n",
    "Learning rate: [9.474879999999992e-05]\n",
    "52000/99489 batches | batch/sec  1.67 | rem mins   473 | loss 3.01693 | ppl  20.4285\n",
    "Learning rate: [9.762879999999993e-05]\n",
    "52100/99489 batches | batch/sec  1.67 | rem mins   473 | loss 2.98086 | ppl  19.7047\n",
    "Learning rate: [0.00010050879999999993]\n",
    "52200/99489 batches | batch/sec  1.67 | rem mins   472 | loss 3.01030 | ppl  20.2935\n",
    "Learning rate: [0.00010338879999999994]\n",
    "52300/99489 batches | batch/sec  1.67 | rem mins   471 | loss 2.99370 | ppl  19.9593\n",
    "Learning rate: [0.00010626879999999994]\n",
    "52400/99489 batches | batch/sec  1.67 | rem mins   469 | loss 2.98565 | ppl  19.7994\n",
    "Learning rate: [0.00010914879999999994]\n",
    "52500/99489 batches | batch/sec  1.67 | rem mins   468 | loss 2.99246 | ppl  19.9346\n",
    "Learning rate: [0.00011202879999999994]\n",
    "52600/99489 batches | batch/sec  1.67 | rem mins   467 | loss 2.98440 | ppl  19.7746\n",
    "Learning rate: [0.00011490879999999994]\n",
    "52700/99489 batches | batch/sec  1.67 | rem mins   467 | loss 2.99824 | ppl  20.0503\n",
    "Learning rate: [0.00011778879999999994]\n",
    "52800/99489 batches | batch/sec  1.67 | rem mins   466 | loss 3.03378 | ppl  20.7756\n",
    "Learning rate: [0.00012066879999999994]\n",
    "53000/99489 batches | batch/sec  1.67 | rem mins   464 | loss 3.00709 | ppl  20.2285\n",
    "Learning rate: [0.00012642879999999996]\n",
    "53100/99489 batches | batch/sec  1.67 | rem mins   463 | loss 2.99580 | ppl  20.0014\n",
    "Learning rate: [0.00012930879999999996]\n",
    "53200/99489 batches | batch/sec  1.67 | rem mins   462 | loss 2.99692 | ppl  20.0237\n",
    "Learning rate: [0.00013218879999999996]\n",
    "53300/99489 batches | batch/sec  1.67 | rem mins   461 | loss 3.01226 | ppl  20.3332\n",
    "Learning rate: [0.00013506879999999996]\n",
    "53400/99489 batches | batch/sec  1.67 | rem mins   460 | loss 2.99438 | ppl  19.9731\n",
    "Learning rate: [0.00013794879999999996]\n",
    "53500/99489 batches | batch/sec  1.67 | rem mins   458 | loss 3.00358 | ppl  20.1576\n",
    "Learning rate: [0.00014082879999999996]\n",
    "53600/99489 batches | batch/sec  1.67 | rem mins   458 | loss 3.01528 | ppl  20.3948\n",
    "Learning rate: [0.00014370879999999996]\n",
    "53700/99489 batches | batch/sec  1.67 | rem mins   457 | loss 3.00669 | ppl  20.2203\n",
    "Learning rate: [0.00014658879999999996]\n",
    "53800/99489 batches | batch/sec  1.67 | rem mins   456 | loss 2.97889 | ppl  19.6660\n",
    "Learning rate: [0.0001494688]\n",
    "53900/99489 batches | batch/sec  1.67 | rem mins   455 | loss 2.98899 | ppl  19.8656\n",
    "Learning rate: [0.0001523488]\n",
    "54000/99489 batches | batch/sec  1.67 | rem mins   454 | loss 3.00450 | ppl  20.1761\n",
    "Learning rate: [0.0001552288]\n",
    "54100/99489 batches | batch/sec  1.67 | rem mins   453 | loss 3.01449 | ppl  20.3787\n",
    "Learning rate: [0.00015810879999999999]\n",
    "54200/99489 batches | batch/sec  1.67 | rem mins   452 | loss 2.99346 | ppl  19.9545\n",
    "Learning rate: [0.00016098879999999999]\n",
    "54300/99489 batches | batch/sec  1.67 | rem mins   451 | loss 2.98811 | ppl  19.8481\n",
    "Learning rate: [0.00016386879999999999]\n",
    "54400/99489 batches | batch/sec  1.67 | rem mins   450 | loss 3.00499 | ppl  20.1861\n",
    "Learning rate: [0.00016674879999999998]\n",
    "54500/99489 batches | batch/sec  1.67 | rem mins   449 | loss 3.00710 | ppl  20.2286\n",
    "Learning rate: [0.00016962879999999998]\n",
    "54800/99489 batches | batch/sec  1.67 | rem mins   446 | loss 2.99305 | ppl  19.9463\n",
    "Learning rate: [0.0001782688]\n",
    "54900/99489 batches | batch/sec  1.67 | rem mins   444 | loss 2.99696 | ppl  20.0246\n",
    "Learning rate: [0.0001811488]\n",
    "55000/99489 batches | batch/sec  1.67 | rem mins   444 | loss 3.01798 | ppl  20.4499\n",
    "Learning rate: [0.0001840288]\n",
    "55100/99489 batches | batch/sec  1.67 | rem mins   443 | loss 2.99254 | ppl  19.9363\n",
    "Learning rate: [0.0001869088]\n",
    "55200/99489 batches | batch/sec  1.67 | rem mins   442 | loss 3.00583 | ppl  20.2030\n",
    "Learning rate: [0.0001897888]\n",
    "55300/99489 batches | batch/sec  1.67 | rem mins   441 | loss 3.02683 | ppl  20.6317\n",
    "Learning rate: [0.0001926688]\n",
    "55400/99489 batches | batch/sec  1.67 | rem mins   440 | loss 2.99401 | ppl  19.9657\n",
    "Learning rate: [0.0001955488]\n",
    "55500/99489 batches | batch/sec  1.67 | rem mins   439 | loss 3.01723 | ppl  20.4345\n",
    "Learning rate: [0.0001984288]\n",
    "55600/99489 batches | batch/sec  1.67 | rem mins   438 | loss 3.02214 | ppl  20.5353\n",
    "Learning rate: [0.0002013088]\n",
    "55700/99489 batches | batch/sec  1.67 | rem mins   437 | loss 3.01990 | ppl  20.4893\n",
    "Learning rate: [0.00020418880000000003]\n",
    "55800/99489 batches | batch/sec  1.67 | rem mins   436 | loss 2.99990 | ppl  20.0835\n",
    "Learning rate: [0.00020706880000000003]\n",
    "55900/99489 batches | batch/sec  1.67 | rem mins   435 | loss 2.99570 | ppl  19.9994\n",
    "Learning rate: [0.00020994880000000003]\n",
    "56000/99489 batches | batch/sec  1.67 | rem mins   434 | loss 3.03290 | ppl  20.7573\n",
    "Learning rate: [0.00021282880000000003]\n",
    "56100/99489 batches | batch/sec  1.67 | rem mins   432 | loss 3.00581 | ppl  20.2026\n",
    "Learning rate: [0.00021570880000000003]\n",
    "56200/99489 batches | batch/sec  1.67 | rem mins   431 | loss 3.01144 | ppl  20.3166\n",
    "Learning rate: [0.00021858880000000003]\n",
    "56300/99489 batches | batch/sec  1.67 | rem mins   431 | loss 3.00867 | ppl  20.2605\n",
    "Learning rate: [0.00022146880000000003]\n",
    "56600/99489 batches | batch/sec  1.67 | rem mins   428 | loss 2.99318 | ppl  19.9490\n",
    "Learning rate: [0.00023010880000000006]\n",
    "56700/99489 batches | batch/sec  1.67 | rem mins   427 | loss 3.00391 | ppl  20.1642\n",
    "Learning rate: [0.00023298880000000006]\n",
    "56800/99489 batches | batch/sec  1.67 | rem mins   426 | loss 3.02512 | ppl  20.5965\n",
    "Learning rate: [0.00023586880000000005]\n",
    "56900/99489 batches | batch/sec  1.67 | rem mins   425 | loss 3.00823 | ppl  20.2516\n",
    "Learning rate: [0.00023874880000000005]\n",
    "57000/99489 batches | batch/sec  1.67 | rem mins   424 | loss 2.99372 | ppl  19.9597\n",
    "Learning rate: [0.00024162880000000005]\n",
    "57100/99489 batches | batch/sec  1.67 | rem mins   423 | loss 3.01390 | ppl  20.3667\n",
    "Learning rate: [0.00024450880000000005]\n",
    "57200/99489 batches | batch/sec  1.67 | rem mins   422 | loss 3.00005 | ppl  20.0866\n",
    "Learning rate: [0.0002473888000000001]\n",
    "57300/99489 batches | batch/sec  1.67 | rem mins   421 | loss 3.01766 | ppl  20.4433\n",
    "Learning rate: [0.00025026880000000005]\n",
    "57400/99489 batches | batch/sec  1.67 | rem mins   420 | loss 2.99660 | ppl  20.0174\n",
    "Learning rate: [0.0002531488000000001]\n",
    "57500/99489 batches | batch/sec  1.67 | rem mins   419 | loss 2.99501 | ppl  19.9856\n",
    "Learning rate: [0.0002560288000000001]\n",
    "57600/99489 batches | batch/sec  1.67 | rem mins   418 | loss 3.01851 | ppl  20.4609\n",
    "Learning rate: [0.0002589088000000001]\n",
    "57700/99489 batches | batch/sec  1.67 | rem mins   417 | loss 3.01179 | ppl  20.3238\n",
    "Learning rate: [0.0002617888000000001]\n",
    "57800/99489 batches | batch/sec  1.67 | rem mins   416 | loss 2.98976 | ppl  19.8808\n",
    "Learning rate: [0.0002646688000000001]\n",
    "57900/99489 batches | batch/sec  1.67 | rem mins   415 | loss 3.00998 | ppl  20.2870\n",
    "Learning rate: [0.0002675488000000001]\n",
    "58000/99489 batches | batch/sec  1.67 | rem mins   414 | loss 3.03420 | ppl  20.7843\n",
    "Learning rate: [0.0002704288000000001]\n",
    "\"\"\".split('\\n')\n",
    "\n",
    "losses, learning_rates = parse_loss(training_log_lines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stable-disco",
   "language": "python",
   "name": "stable-disco"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
