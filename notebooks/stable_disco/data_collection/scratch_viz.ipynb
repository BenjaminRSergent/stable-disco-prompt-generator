{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74a04ba8-2de2-4eb6-8282-81f95e404705",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext tensorboard\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import clip\n",
    "\n",
    "import importlib\n",
    "\n",
    "import contextlib\n",
    "\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('../..'))\n",
    "sys.path.insert(0, os.path.abspath('../../..'))\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "from utils import get_default_path\n",
    "from utils import Stopwatch\n",
    "import time\n",
    "\n",
    "import datetime\n",
    "\n",
    "\n",
    "import ai.stabledisco as sd\n",
    "import ai.torchmodules as torchmodules\n",
    "import ai.torchmodules.data as torchdata\n",
    "import ai.torchmodules.utils as torchutils\n",
    "import ai.stabledisco.utils as sdutils\n",
    "import ai.stabledisco.data as sddata\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "from clip.clip import _tokenizer as clip_tokenizer\n",
    "import ai.stabledisco.decoderpipeline as decoderpipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72e9ddd9-3c9b-4836-8b78-472c24ee32fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def parse_loss(training_log_lines):\n",
    "    losses = []\n",
    "    learning_rates = []\n",
    "\n",
    "    for line in training_log_lines:\n",
    "        matches = re.findall(fr\"(?<=loss )\\d+\\.\\d+\", line)\n",
    "        for match in matches:\n",
    "            losses.append(float(match))\n",
    "            \n",
    "        matches = re.finditer(fr\"(?<=Learning rate: \\[)\\d+\\.\\d+(e-?\\d+)?(?=])\", line)\n",
    "        for match in matches:\n",
    "            learning_rates.append(float(match.group(0)))\n",
    "        \n",
    "    return losses, learning_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c944b4d3-f98c-4d31-b05c-64b587bde6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_log_lines = \"\"\"\n",
    "Starting training\n",
    "Starting epoch 0\n",
    "  200/47582 batches | batch/sec  1.85 | rem mins   427 | loss 2.23640 | ppl   9.3596\n",
    "Learning rate: [0.00016100638977635805]\n",
    "  400/47582 batches | batch/sec  1.91 | rem mins   411 | loss 2.18606 | ppl   8.9001\n",
    "Learning rate: [0.00022170926517571862]\n",
    "  600/47582 batches | batch/sec  1.91 | rem mins   409 | loss 2.13129 | ppl   8.4257\n",
    "Learning rate: [0.00028241214057508]\n",
    "  800/47582 batches | batch/sec  1.91 | rem mins   407 | loss 2.07387 | ppl   7.9556\n",
    "Learning rate: [0.00034311501597444053]\n",
    " 1000/47582 batches | batch/sec  1.91 | rem mins   406 | loss 2.02631 | ppl   7.5860\n",
    "Learning rate: [0.0004038178913738019]\n",
    " 1200/47582 batches | batch/sec  1.91 | rem mins   404 | loss 1.96631 | ppl   7.1443\n",
    "Learning rate: [0.0004645207667731633]\n",
    " 1400/47582 batches | batch/sec  1.91 | rem mins   403 | loss 1.90981 | ppl   6.7518\n",
    "Learning rate: [0.0005252236421725239]\n",
    " 1600/47582 batches | batch/sec  1.91 | rem mins   401 | loss 1.86687 | ppl   6.4680\n",
    "Learning rate: [0.0005859265175718853]\n",
    " 1800/47582 batches | batch/sec  1.91 | rem mins   400 | loss 1.81861 | ppl   6.1633\n",
    "Learning rate: [0.0006466293929712458]\n",
    " 2000/47582 batches | batch/sec  1.91 | rem mins   398 | loss 1.77468 | ppl   5.8984\n",
    "Learning rate: [0.0007073322683706073]\n",
    " 2200/47582 batches | batch/sec  1.91 | rem mins   396 | loss 1.72826 | ppl   5.6309\n",
    "Learning rate: [0.0007680351437699677]\n",
    " 2400/47582 batches | batch/sec  1.91 | rem mins   395 | loss 1.71080 | ppl   5.5334\n",
    "Learning rate: [0.0008287380191693292]\n",
    " 2600/47582 batches | batch/sec  1.91 | rem mins   393 | loss 1.68304 | ppl   5.3819\n",
    "Learning rate: [0.0008894408945686905]\n",
    " 2800/47582 batches | batch/sec  1.91 | rem mins   392 | loss 1.66762 | ppl   5.2996\n",
    "Learning rate: [0.0009501437699680511]\n",
    " 3000/47582 batches | batch/sec  1.90 | rem mins   390 | loss 1.63592 | ppl   5.1342\n",
    "Learning rate: [0.0010108466453674124]\n",
    " 3200/47582 batches | batch/sec  1.90 | rem mins   389 | loss 1.62762 | ppl   5.0917\n",
    "Learning rate: [0.001071549520766773]\n",
    " 3400/47582 batches | batch/sec  1.90 | rem mins   387 | loss 1.61128 | ppl   5.0092\n",
    "Learning rate: [0.0011322523961661344]\n",
    " 3600/47582 batches | batch/sec  1.90 | rem mins   386 | loss 1.58956 | ppl   4.9016\n",
    "Learning rate: [0.001192955271565495]\n",
    " 3800/47582 batches | batch/sec  1.90 | rem mins   384 | loss 1.57634 | ppl   4.8372\n",
    "Learning rate: [0.0012536581469648565]\n",
    " 4000/47582 batches | batch/sec  1.91 | rem mins   381 | loss 1.55557 | ppl   4.7378\n",
    "Learning rate: [0.0013143610223642168]\n",
    " 4200/47582 batches | batch/sec  1.91 | rem mins   379 | loss 1.54114 | ppl   4.6699\n",
    "Learning rate: [0.0013750638977635783]\n",
    " 4400/47582 batches | batch/sec  1.91 | rem mins   377 | loss 1.53387 | ppl   4.6361\n",
    "Learning rate: [0.0014357667731629397]\n",
    " 4600/47582 batches | batch/sec  1.91 | rem mins   375 | loss 1.50332 | ppl   4.4966\n",
    "Learning rate: [0.0014964696485623003]\n",
    " 4800/47582 batches | batch/sec  1.91 | rem mins   373 | loss 1.49831 | ppl   4.4741\n",
    "Learning rate: [0.0015571725239616617]\n",
    " 5000/47582 batches | batch/sec  1.91 | rem mins   371 | loss 1.48198 | ppl   4.4017\n",
    "Learning rate: [0.001617875399361022]\n",
    " 5200/47582 batches | batch/sec  1.91 | rem mins   369 | loss 1.47140 | ppl   4.3553\n",
    "Learning rate: [0.0016785782747603835]\n",
    " 5400/47582 batches | batch/sec  1.92 | rem mins   367 | loss 1.45201 | ppl   4.2717\n",
    "Learning rate: [0.001739281150159745]\n",
    " 5600/47582 batches | batch/sec  1.92 | rem mins   365 | loss 1.44231 | ppl   4.2305\n",
    "Learning rate: [0.0017999840255591055]\n",
    " 5800/47582 batches | batch/sec  1.92 | rem mins   363 | loss 1.42292 | ppl   4.1492\n",
    "Learning rate: [0.001860686900958466]\n",
    " 6000/47582 batches | batch/sec  1.92 | rem mins   362 | loss 1.41765 | ppl   4.1274\n",
    "Learning rate: [0.0019213897763578273]\n",
    " 6200/47582 batches | batch/sec  1.92 | rem mins   360 | loss 1.40855 | ppl   4.0900\n",
    "Learning rate: [0.0019820926517571886]\n",
    " 6400/47582 batches | batch/sec  1.92 | rem mins   358 | loss 1.40057 | ppl   4.0575\n",
    "Learning rate: [0.00195720447284345]\n",
    " 6600/47582 batches | batch/sec  1.92 | rem mins   356 | loss 1.37897 | ppl   3.9708\n",
    "Learning rate: [0.0018965015974440893]\n",
    " 6800/47582 batches | batch/sec  1.92 | rem mins   354 | loss 1.37088 | ppl   3.9388\n",
    "Learning rate: [0.0018357987220447287]\n",
    " 7000/47582 batches | batch/sec  1.92 | rem mins   353 | loss 1.36398 | ppl   3.9117\n",
    "Learning rate: [0.0017750958466453675]\n",
    " 7200/47582 batches | batch/sec  1.92 | rem mins   351 | loss 1.35815 | ppl   3.8890\n",
    "Learning rate: [0.001714392971246006]\n",
    " 7400/47582 batches | batch/sec  1.92 | rem mins   349 | loss 1.34241 | ppl   3.8283\n",
    "Learning rate: [0.0016536900958466455]\n",
    " 7600/47582 batches | batch/sec  1.92 | rem mins   348 | loss 1.33853 | ppl   3.8134\n",
    "Learning rate: [0.001592987220447285]\n",
    " 7800/47582 batches | batch/sec  1.92 | rem mins   346 | loss 1.32860 | ppl   3.7757\n",
    "Learning rate: [0.0015322843450479235]\n",
    " 8000/47582 batches | batch/sec  1.92 | rem mins   344 | loss 1.31760 | ppl   3.7344\n",
    "Learning rate: [0.0014715814696485622]\n",
    " 8200/47582 batches | batch/sec  1.92 | rem mins   342 | loss 1.31488 | ppl   3.7243\n",
    "Learning rate: [0.0014108785942492008]\n",
    " 8400/47582 batches | batch/sec  1.92 | rem mins   341 | loss 1.30613 | ppl   3.6919\n",
    "Learning rate: [0.0013501757188498402]\n",
    " 8600/47582 batches | batch/sec  1.92 | rem mins   339 | loss 1.29425 | ppl   3.6483\n",
    "Learning rate: [0.0012894728434504797]\n",
    " 8800/47582 batches | batch/sec  1.92 | rem mins   337 | loss 1.28988 | ppl   3.6324\n",
    "Learning rate: [0.0012287699680511182]\n",
    " 9000/47582 batches | batch/sec  1.92 | rem mins   335 | loss 1.28138 | ppl   3.6016\n",
    "Learning rate: [0.001168067092651757]\n",
    " 9200/47582 batches | batch/sec  1.92 | rem mins   334 | loss 1.28768 | ppl   3.6244\n",
    "Learning rate: [0.0011073642172523964]\n",
    " 9400/47582 batches | batch/sec  1.92 | rem mins   332 | loss 1.27767 | ppl   3.5883\n",
    "Learning rate: [0.0010466613418530358]\n",
    " 9600/47582 batches | batch/sec  1.92 | rem mins   330 | loss 1.26974 | ppl   3.5599\n",
    "Learning rate: [0.0009859584664536744]\n",
    " 9800/47582 batches | batch/sec  1.92 | rem mins   329 | loss 1.27170 | ppl   3.5669\n",
    "Learning rate: [0.0009252555910543131]\n",
    "10000/47582 batches | batch/sec  1.92 | rem mins   326 | loss 1.25944 | ppl   3.5234\n",
    "Learning rate: [0.0008645527156549516]\n",
    "10200/47582 batches | batch/sec  1.92 | rem mins   325 | loss 1.25595 | ppl   3.5112\n",
    "Learning rate: [0.000803849840255591]\n",
    "10400/47582 batches | batch/sec  1.92 | rem mins   323 | loss 1.25637 | ppl   3.5126\n",
    "Learning rate: [0.0007431469648562306]\n",
    "10600/47582 batches | batch/sec  1.92 | rem mins   321 | loss 1.24840 | ppl   3.4848\n",
    "Learning rate: [0.0006824440894568691]\n",
    "10800/47582 batches | batch/sec  1.92 | rem mins   320 | loss 1.24813 | ppl   3.4838\n",
    "Learning rate: [0.0006217412140575078]\n",
    "11000/47582 batches | batch/sec  1.92 | rem mins   318 | loss 1.24895 | ppl   3.4867\n",
    "Learning rate: [0.0005610383386581464]\n",
    "11200/47582 batches | batch/sec  1.92 | rem mins   316 | loss 1.24503 | ppl   3.4730\n",
    "Learning rate: [0.0005003354632587858]\n",
    "11400/47582 batches | batch/sec  1.92 | rem mins   315 | loss 1.23519 | ppl   3.4390\n",
    "Learning rate: [0.0004396325878594252]\n",
    "11600/47582 batches | batch/sec  1.92 | rem mins   313 | loss 1.23443 | ppl   3.4364\n",
    "Learning rate: [0.00037892971246006384]\n",
    "11800/47582 batches | batch/sec  1.92 | rem mins   311 | loss 1.23073 | ppl   3.4237\n",
    "Learning rate: [0.0003182268370607025]\n",
    "12000/47582 batches | batch/sec  1.92 | rem mins   309 | loss 1.22804 | ppl   3.4145\n",
    "Learning rate: [0.00025752396166134193]\n",
    "12200/47582 batches | batch/sec  1.92 | rem mins   307 | loss 1.22867 | ppl   3.4167\n",
    "Learning rate: [0.00019682108626198138]\n",
    "12400/47582 batches | batch/sec  1.92 | rem mins   306 | loss 1.22490 | ppl   3.4038\n",
    "Learning rate: [0.00013611821086262]\n",
    "12600/47582 batches | batch/sec  1.92 | rem mins   304 | loss 1.22759 | ppl   3.4130\n",
    "Learning rate: [0.0001245846645367414]\n",
    "12800/47582 batches | batch/sec  1.92 | rem mins   302 | loss 1.22697 | ppl   3.4109\n",
    "Learning rate: [0.0001852875399361011]\n",
    "13000/47582 batches | batch/sec  1.92 | rem mins   301 | loss 1.22621 | ppl   3.4083\n",
    "Learning rate: [0.0002459904153354625]\n",
    "13200/47582 batches | batch/sec  1.92 | rem mins   299 | loss 1.22792 | ppl   3.4141\n",
    "Learning rate: [0.0003066932907348239]\n",
    "13400/47582 batches | batch/sec  1.92 | rem mins   297 | loss 1.22562 | ppl   3.4063\n",
    "Learning rate: [0.00036739616613418527]\n",
    "13600/47582 batches | batch/sec  1.92 | rem mins   295 | loss 1.22910 | ppl   3.4182\n",
    "Learning rate: [0.00042809904153354666]\n",
    "13800/47582 batches | batch/sec  1.92 | rem mins   293 | loss 1.22867 | ppl   3.4167\n",
    "Learning rate: [0.000488801916932908]\n",
    "14000/47582 batches | batch/sec  1.92 | rem mins   292 | loss 1.22701 | ppl   3.4110\n",
    "Learning rate: [0.0005495047923322695]\n",
    "14200/47582 batches | batch/sec  1.92 | rem mins   290 | loss 1.22006 | ppl   3.3874\n",
    "Learning rate: [0.0006102076677316292]\n",
    "14400/47582 batches | batch/sec  1.92 | rem mins   289 | loss 1.22087 | ppl   3.3901\n",
    "Learning rate: [0.0006709105431309905]\n",
    "14600/47582 batches | batch/sec  1.92 | rem mins   287 | loss 1.22585 | ppl   3.4071\n",
    "Learning rate: [0.0007316134185303502]\n",
    "14800/47582 batches | batch/sec  1.92 | rem mins   285 | loss 1.22308 | ppl   3.3976\n",
    "Learning rate: [0.0007923162939297117]\n",
    "15000/47582 batches | batch/sec  1.92 | rem mins   283 | loss 1.22168 | ppl   3.3929\n",
    "Learning rate: [0.000853019169329073]\n",
    "15200/47582 batches | batch/sec  1.92 | rem mins   281 | loss 1.22156 | ppl   3.3925\n",
    "Learning rate: [0.0009137220447284344]\n",
    "15400/47582 batches | batch/sec  1.92 | rem mins   279 | loss 1.22266 | ppl   3.3962\n",
    "Learning rate: [0.0009744249201277958]\n",
    "15600/47582 batches | batch/sec  1.92 | rem mins   278 | loss 1.22007 | ppl   3.3874\n",
    "Learning rate: [0.0010351277955271572]\n",
    "15800/47582 batches | batch/sec  1.92 | rem mins   276 | loss 1.21865 | ppl   3.3826\n",
    "Learning rate: [0.0010958306709265187]\n",
    "16000/47582 batches | batch/sec  1.92 | rem mins   274 | loss 1.21213 | ppl   3.3606\n",
    "Learning rate: [0.0011565335463258784]\n",
    "16200/47582 batches | batch/sec  1.92 | rem mins   272 | loss 1.21694 | ppl   3.3768\n",
    "Learning rate: [0.0012172364217252396]\n",
    "16400/47582 batches | batch/sec  1.92 | rem mins   271 | loss 1.21615 | ppl   3.3742\n",
    "Learning rate: [0.001277939297124601]\n",
    "16600/47582 batches | batch/sec  1.92 | rem mins   269 | loss 1.21170 | ppl   3.3592\n",
    "Learning rate: [0.0013386421725239607]\n",
    "16800/47582 batches | batch/sec  1.92 | rem mins   268 | loss 1.21057 | ppl   3.3554\n",
    "Learning rate: [0.0013993450479233222]\n",
    "17000/47582 batches | batch/sec  1.92 | rem mins   266 | loss 1.20692 | ppl   3.3432\n",
    "Learning rate: [0.0014600479233226836]\n",
    "17200/47582 batches | batch/sec  1.92 | rem mins   264 | loss 1.22973 | ppl   3.4203\n",
    "Learning rate: [0.0015207507987220449]\n",
    "17400/47582 batches | batch/sec  1.92 | rem mins   262 | loss 1.22639 | ppl   3.4089\n",
    "Learning rate: [0.0015814536741214063]\n",
    "17600/47582 batches | batch/sec  1.92 | rem mins   260 | loss 1.22110 | ppl   3.3909\n",
    "Learning rate: [0.0016421565495207677]\n",
    "17800/47582 batches | batch/sec  1.92 | rem mins   259 | loss 1.21707 | ppl   3.3773\n",
    "Learning rate: [0.0017028594249201274]\n",
    "18000/47582 batches | batch/sec  1.92 | rem mins   257 | loss 1.21921 | ppl   3.3845\n",
    "Learning rate: [0.0017635623003194889]\n",
    "18200/47582 batches | batch/sec  1.92 | rem mins   255 | loss 1.22034 | ppl   3.3884\n",
    "Learning rate: [0.00182426517571885]\n",
    "18400/47582 batches | batch/sec  1.92 | rem mins   253 | loss 1.21152 | ppl   3.3586\n",
    "Learning rate: [0.0018849680511182098]\n",
    "18600/47582 batches | batch/sec  1.92 | rem mins   251 | loss 1.21395 | ppl   3.3667\n",
    "Learning rate: [0.0019456709265175713]\n",
    "18800/47582 batches | batch/sec  1.92 | rem mins   250 | loss 1.21390 | ppl   3.3666\n",
    "Learning rate: [0.0019936261980830674]\n",
    "19000/47582 batches | batch/sec  1.92 | rem mins   248 | loss 1.20579 | ppl   3.3394\n",
    "Learning rate: [0.001932923322683706]\n",
    "19200/47582 batches | batch/sec  1.92 | rem mins   246 | loss 1.19013 | ppl   3.2875\n",
    "Learning rate: [0.0018722204472843447]\n",
    "19400/47582 batches | batch/sec  1.92 | rem mins   245 | loss 1.17597 | ppl   3.2413\n",
    "Learning rate: [0.0018115175718849833]\n",
    "19600/47582 batches | batch/sec  1.92 | rem mins   243 | loss 1.16695 | ppl   3.2122\n",
    "Learning rate: [0.0017508146964856218]\n",
    "19800/47582 batches | batch/sec  1.92 | rem mins   241 | loss 1.17693 | ppl   3.2444\n",
    "Learning rate: [0.0016901118210862621]\n",
    "20000/47582 batches | batch/sec  1.92 | rem mins   239 | loss 1.18569 | ppl   3.2729\n",
    "Learning rate: [0.0016294089456869007]\n",
    "20200/47582 batches | batch/sec  1.92 | rem mins   238 | loss 1.17996 | ppl   3.2542\n",
    "Learning rate: [0.001568706070287541]\n",
    "20400/47582 batches | batch/sec  1.92 | rem mins   236 | loss 1.17378 | ppl   3.2342\n",
    "Learning rate: [0.0015080031948881798]\n",
    "20600/47582 batches | batch/sec  1.92 | rem mins   234 | loss 1.16563 | ppl   3.2079\n",
    "Learning rate: [0.0014473003194888183]\n",
    "20800/47582 batches | batch/sec  1.92 | rem mins   232 | loss 1.16208 | ppl   3.1966\n",
    "Learning rate: [0.0013865974440894569]\n",
    "21000/47582 batches | batch/sec  1.92 | rem mins   231 | loss 1.16298 | ppl   3.1994\n",
    "Learning rate: [0.0013258945686900954]\n",
    "21200/47582 batches | batch/sec  1.92 | rem mins   229 | loss 1.15373 | ppl   3.1700\n",
    "Learning rate: [0.0012651916932907342]\n",
    "21400/47582 batches | batch/sec  1.92 | rem mins   227 | loss 1.14818 | ppl   3.1525\n",
    "Learning rate: [0.0012044888178913728]\n",
    "21600/47582 batches | batch/sec  1.92 | rem mins   225 | loss 1.15068 | ppl   3.1603\n",
    "Learning rate: [0.001143785942492013]\n",
    "21800/47582 batches | batch/sec  1.92 | rem mins   224 | loss 1.14018 | ppl   3.1273\n",
    "Learning rate: [0.0010830830670926516]\n",
    "22000/47582 batches | batch/sec  1.92 | rem mins   222 | loss 1.13295 | ppl   3.1048\n",
    "Learning rate: [0.001022380191693292]\n",
    "22200/47582 batches | batch/sec  1.92 | rem mins   221 | loss 1.12952 | ppl   3.0942\n",
    "Learning rate: [0.0009616773162939306]\n",
    "22400/47582 batches | batch/sec  1.92 | rem mins   219 | loss 1.12396 | ppl   3.0770\n",
    "Learning rate: [0.0009009744408945691]\n",
    "22600/47582 batches | batch/sec  1.92 | rem mins   217 | loss 1.12297 | ppl   3.0740\n",
    "Learning rate: [0.0008402715654952078]\n",
    "22800/47582 batches | batch/sec  1.92 | rem mins   215 | loss 1.12059 | ppl   3.0667\n",
    "Learning rate: [0.0007795686900958464]\n",
    "23000/47582 batches | batch/sec  1.92 | rem mins   213 | loss 1.11992 | ppl   3.0646\n",
    "Learning rate: [0.000718865814696485]\n",
    "23200/47582 batches | batch/sec  1.92 | rem mins   212 | loss 1.11202 | ppl   3.0405\n",
    "Learning rate: [0.0006581629392971236]\n",
    "23400/47582 batches | batch/sec  1.92 | rem mins   210 | loss 1.11177 | ppl   3.0397\n",
    "Learning rate: [0.0005974600638977639]\n",
    "23600/47582 batches | batch/sec  1.92 | rem mins   209 | loss 1.11506 | ppl   3.0497\n",
    "Learning rate: [0.0005367571884984024]\n",
    "23800/47582 batches | batch/sec  1.92 | rem mins   206 | loss 1.11308 | ppl   3.0437\n",
    "Learning rate: [0.00047605431309904274]\n",
    "24000/47582 batches | batch/sec  1.92 | rem mins   205 | loss 1.10709 | ppl   3.0255\n",
    "Learning rate: [0.00041535143769968135]\n",
    "24200/47582 batches | batch/sec  1.92 | rem mins   203 | loss 1.10117 | ppl   3.0077\n",
    "Learning rate: [0.00035464856230031996]\n",
    "24400/47582 batches | batch/sec  1.92 | rem mins   201 | loss 1.10358 | ppl   3.0150\n",
    "Learning rate: [0.0002939456869009586]\n",
    "24600/47582 batches | batch/sec  1.92 | rem mins   200 | loss 1.10693 | ppl   3.0251\n",
    "Learning rate: [0.0002332428115015972]\n",
    "24800/47582 batches | batch/sec  1.92 | rem mins   198 | loss 1.09983 | ppl   3.0036\n",
    "Learning rate: [0.0001725399361022358]\n",
    "25000/47582 batches | batch/sec  1.92 | rem mins   196 | loss 1.09865 | ppl   3.0001\n",
    "Learning rate: [0.00011183706070287443]\n",
    "25200/47582 batches | batch/sec  1.92 | rem mins   194 | loss 1.09738 | ppl   2.9963\n",
    "Learning rate: [0.00014886581469648527]\n",
    "25400/47582 batches | batch/sec  1.92 | rem mins   193 | loss 1.10145 | ppl   3.0085\n",
    "Learning rate: [0.00020956869009584666]\n",
    "25600/47582 batches | batch/sec  1.92 | rem mins   191 | loss 1.09524 | ppl   2.9899\n",
    "Learning rate: [0.00027027156549520805]\n",
    "25800/47582 batches | batch/sec  1.92 | rem mins   189 | loss 1.09606 | ppl   2.9924\n",
    "Learning rate: [0.00033097444089456944]\n",
    "26000/47582 batches | batch/sec  1.92 | rem mins   187 | loss 1.09737 | ppl   2.9963\n",
    "Learning rate: [0.00039167731629392914]\n",
    "26200/47582 batches | batch/sec  1.92 | rem mins   186 | loss 1.09650 | ppl   2.9937\n",
    "Learning rate: [0.00045238019169329053]\n",
    "26400/47582 batches | batch/sec  1.92 | rem mins   184 | loss 1.09887 | ppl   3.0008\n",
    "Learning rate: [0.000513083067092652]\n",
    "26600/47582 batches | batch/sec  1.92 | rem mins   182 | loss 1.09679 | ppl   2.9945\n",
    "Learning rate: [0.0005737859424920133]\n",
    "26800/47582 batches | batch/sec  1.92 | rem mins   180 | loss 1.09674 | ppl   2.9944\n",
    "Learning rate: [0.000634488817891373]\n",
    "27000/47582 batches | batch/sec  1.92 | rem mins   179 | loss 1.09787 | ppl   2.9978\n",
    "Learning rate: [0.0006951916932907345]\n",
    "27200/47582 batches | batch/sec  1.92 | rem mins   177 | loss 1.09752 | ppl   2.9967\n",
    "Learning rate: [0.0007558945686900958]\n",
    "27400/47582 batches | batch/sec  1.92 | rem mins   175 | loss 1.09663 | ppl   2.9941\n",
    "Learning rate: [0.0008165974440894572]\n",
    "27600/47582 batches | batch/sec  1.92 | rem mins   174 | loss 1.10658 | ppl   3.0240\n",
    "Learning rate: [0.0008773003194888187]\n",
    "27800/47582 batches | batch/sec  1.92 | rem mins   172 | loss 1.10524 | ppl   3.0200\n",
    "Learning rate: [0.0009380031948881783]\n",
    "28000/47582 batches | batch/sec  1.92 | rem mins   170 | loss 1.10290 | ppl   3.0129\n",
    "Learning rate: [0.0009987060702875397]\n",
    "28200/47582 batches | batch/sec  1.92 | rem mins   168 | loss 1.10116 | ppl   3.0076\n",
    "Learning rate: [0.001059408945686901]\n",
    "28400/47582 batches | batch/sec  1.92 | rem mins   167 | loss 1.09859 | ppl   2.9999\n",
    "Learning rate: [0.0011201118210862626]\n",
    "28600/47582 batches | batch/sec  1.92 | rem mins   165 | loss 1.10442 | ppl   3.0175\n",
    "Learning rate: [0.0011808146964856238]\n",
    "28800/47582 batches | batch/sec  1.92 | rem mins   163 | loss 1.10155 | ppl   3.0088\n",
    "Learning rate: [0.0012415175718849835]\n",
    "29000/47582 batches | batch/sec  1.92 | rem mins   161 | loss 1.09863 | ppl   3.0000\n",
    "Learning rate: [0.001302220447284345]\n",
    "29200/47582 batches | batch/sec  1.92 | rem mins   160 | loss 1.10570 | ppl   3.0213\n",
    "Learning rate: [0.0013629233226837064]\n",
    "29400/47582 batches | batch/sec  1.92 | rem mins   158 | loss 1.10323 | ppl   3.0139\n",
    "Learning rate: [0.0014236261980830678]\n",
    "29600/47582 batches | batch/sec  1.92 | rem mins   156 | loss 1.10766 | ppl   3.0273\n",
    "Learning rate: [0.0014843290734824273]\n",
    "29800/47582 batches | batch/sec  1.92 | rem mins   154 | loss 1.09917 | ppl   3.0017\n",
    "Learning rate: [0.0015450319488817888]\n",
    "30000/47582 batches | batch/sec  1.92 | rem mins   153 | loss 1.10400 | ppl   3.0162\n",
    "Learning rate: [0.0016057348242811502]\n",
    "30200/47582 batches | batch/sec  1.92 | rem mins   151 | loss 1.11864 | ppl   3.0607\n",
    "Learning rate: [0.0016664376996805117]\n",
    "30400/47582 batches | batch/sec  1.92 | rem mins   149 | loss 1.12801 | ppl   3.0895\n",
    "Learning rate: [0.001727140575079873]\n",
    "30600/47582 batches | batch/sec  1.92 | rem mins   147 | loss 1.12388 | ppl   3.0768\n",
    "Learning rate: [0.0017878434504792326]\n",
    "30800/47582 batches | batch/sec  1.92 | rem mins   146 | loss 1.13188 | ppl   3.1015\n",
    "Learning rate: [0.001848546325878594]\n",
    "31000/47582 batches | batch/sec  1.92 | rem mins   144 | loss 1.11982 | ppl   3.0643\n",
    "Learning rate: [0.0019092492012779555]\n",
    "31200/47582 batches | batch/sec  1.92 | rem mins   142 | loss 1.12669 | ppl   3.0854\n",
    "Learning rate: [0.001969952076677317]\n",
    "31400/47582 batches | batch/sec  1.92 | rem mins   141 | loss 1.12895 | ppl   3.0924\n",
    "Learning rate: [0.0019693450479233232]\n",
    "31600/47582 batches | batch/sec  1.92 | rem mins   139 | loss 1.12969 | ppl   3.0947\n",
    "Learning rate: [0.0019086421725239622]\n",
    "31800/47582 batches | batch/sec  1.92 | rem mins   137 | loss 1.12744 | ppl   3.0877\n",
    "Learning rate: [0.0018479392971246008]\n",
    "32000/47582 batches | batch/sec  1.92 | rem mins   135 | loss 1.12173 | ppl   3.0702\n",
    "Learning rate: [0.0017872364217252394]\n",
    "32200/47582 batches | batch/sec  1.92 | rem mins   134 | loss 1.10271 | ppl   3.0123\n",
    "Learning rate: [0.001726533546325878]\n",
    "32400/47582 batches | batch/sec  1.92 | rem mins   132 | loss 1.09251 | ppl   2.9818\n",
    "Learning rate: [0.0016658306709265182]\n",
    "32600/47582 batches | batch/sec  1.92 | rem mins   130 | loss 1.09277 | ppl   2.9825\n",
    "Learning rate: [0.0016051277955271568]\n",
    "32800/47582 batches | batch/sec  1.92 | rem mins   128 | loss 1.08617 | ppl   2.9629\n",
    "Learning rate: [0.0015444249201277955]\n",
    "33000/47582 batches | batch/sec  1.92 | rem mins   127 | loss 1.08764 | ppl   2.9673\n",
    "Learning rate: [0.001483722044728434]\n",
    "33200/47582 batches | batch/sec  1.92 | rem mins   125 | loss 1.09159 | ppl   2.9790\n",
    "Learning rate: [0.0014230191693290727]\n",
    "33400/47582 batches | batch/sec  1.92 | rem mins   123 | loss 1.09140 | ppl   2.9785\n",
    "Learning rate: [0.001362316293929713]\n",
    "33600/47582 batches | batch/sec  1.92 | rem mins   121 | loss 1.09230 | ppl   2.9811\n",
    "Learning rate: [0.0013016134185303515]\n",
    "33800/47582 batches | batch/sec  1.92 | rem mins   120 | loss 1.09416 | ppl   2.9867\n",
    "Learning rate: [0.0012409105431309903]\n",
    "34000/47582 batches | batch/sec  1.92 | rem mins   118 | loss 1.08758 | ppl   2.9671\n",
    "Learning rate: [0.0011802076677316288]\n",
    "34200/47582 batches | batch/sec  1.92 | rem mins   116 | loss 1.08771 | ppl   2.9675\n",
    "Learning rate: [0.0011195047923322691]\n",
    "34400/47582 batches | batch/sec  1.92 | rem mins   114 | loss 1.08205 | ppl   2.9507\n",
    "Learning rate: [0.0010588019169329077]\n",
    "34600/47582 batches | batch/sec  1.92 | rem mins   113 | loss 1.07995 | ppl   2.9445\n",
    "Learning rate: [0.0009980990415335463]\n",
    "34800/47582 batches | batch/sec  1.92 | rem mins   111 | loss 1.08004 | ppl   2.9448\n",
    "Learning rate: [0.0009373961661341849]\n",
    "35000/47582 batches | batch/sec  1.92 | rem mins   109 | loss 1.07325 | ppl   2.9249\n",
    "Learning rate: [0.0008766932907348236]\n",
    "35200/47582 batches | batch/sec  1.92 | rem mins   107 | loss 1.06377 | ppl   2.8973\n",
    "Learning rate: [0.0008159904153354639]\n",
    "35400/47582 batches | batch/sec  1.92 | rem mins   106 | loss 1.06134 | ppl   2.8903\n",
    "Learning rate: [0.0007552875399361024]\n",
    "35600/47582 batches | batch/sec  1.92 | rem mins   104 | loss 1.06053 | ppl   2.8879\n",
    "Learning rate: [0.0006945846645367411]\n",
    "35800/47582 batches | batch/sec  1.92 | rem mins   102 | loss 1.05149 | ppl   2.8619\n",
    "Learning rate: [0.0006338817891373797]\n",
    "36000/47582 batches | batch/sec  1.92 | rem mins   101 | loss 1.05102 | ppl   2.8606\n",
    "Learning rate: [0.00057317891373802]\n",
    "36200/47582 batches | batch/sec  1.92 | rem mins    99 | loss 1.04816 | ppl   2.8524\n",
    "Learning rate: [0.0005124760383386586]\n",
    "36400/47582 batches | batch/sec  1.92 | rem mins    97 | loss 1.04510 | ppl   2.8437\n",
    "Learning rate: [0.0004517731629392972]\n",
    "36600/47582 batches | batch/sec  1.92 | rem mins    95 | loss 1.05170 | ppl   2.8625\n",
    "Learning rate: [0.0003910702875399358]\n",
    "36800/47582 batches | batch/sec  1.92 | rem mins    94 | loss 1.05025 | ppl   2.8584\n",
    "Learning rate: [0.0003303674121405744]\n",
    "37000/47582 batches | batch/sec  1.92 | rem mins    92 | loss 1.04802 | ppl   2.8520\n",
    "Learning rate: [0.0002696645367412147]\n",
    "37200/47582 batches | batch/sec  1.92 | rem mins    90 | loss 1.03917 | ppl   2.8269\n",
    "Learning rate: [0.00020896166134185332]\n",
    "37400/47582 batches | batch/sec  1.92 | rem mins    88 | loss 1.04072 | ppl   2.8312\n",
    "Learning rate: [0.00014825878594249193]\n",
    "37600/47582 batches | batch/sec  1.92 | rem mins    87 | loss 1.04302 | ppl   2.8378\n",
    "Learning rate: [0.00011244408945686947]\n",
    "37800/47582 batches | batch/sec  1.92 | rem mins    85 | loss 1.04309 | ppl   2.8380\n",
    "Learning rate: [0.00017314696485623085]\n",
    "38000/47582 batches | batch/sec  1.92 | rem mins    83 | loss 1.04003 | ppl   2.8293\n",
    "Learning rate: [0.00023384984025558885]\n",
    "38200/47582 batches | batch/sec  1.92 | rem mins    81 | loss 1.03465 | ppl   2.8141\n",
    "Learning rate: [0.00029455271565495024]\n",
    "38400/47582 batches | batch/sec  1.92 | rem mins    80 | loss 1.03977 | ppl   2.8286\n",
    "Learning rate: [0.0003552555910543116]\n",
    "38600/47582 batches | batch/sec  1.92 | rem mins    78 | loss 1.04283 | ppl   2.8372\n",
    "Learning rate: [0.000415958466453673]\n",
    "38800/47582 batches | batch/sec  1.92 | rem mins    76 | loss 1.04675 | ppl   2.8484\n",
    "Learning rate: [0.0004766613418530344]\n",
    "39000/47582 batches | batch/sec  1.92 | rem mins    74 | loss 1.03835 | ppl   2.8246\n",
    "Learning rate: [0.0005373642172523958]\n",
    "39200/47582 batches | batch/sec  1.92 | rem mins    73 | loss 1.04579 | ppl   2.8457\n",
    "Learning rate: [0.0005980670926517572]\n",
    "39400/47582 batches | batch/sec  1.92 | rem mins    71 | loss 1.04019 | ppl   2.8297\n",
    "Learning rate: [0.0006587699680511187]\n",
    "39600/47582 batches | batch/sec  1.92 | rem mins    69 | loss 1.04419 | ppl   2.8411\n",
    "Learning rate: [0.00071947284345048]\n",
    "39800/47582 batches | batch/sec  1.92 | rem mins    68 | loss 1.04255 | ppl   2.8364\n",
    "Learning rate: [0.0007801757188498414]\n",
    "40000/47582 batches | batch/sec  1.92 | rem mins    66 | loss 1.04348 | ppl   2.8391\n",
    "Learning rate: [0.0008408785942492028]\n",
    "40200/47582 batches | batch/sec  1.92 | rem mins    64 | loss 1.04682 | ppl   2.8486\n",
    "Learning rate: [0.0009015814696485642]\n",
    "40400/47582 batches | batch/sec  1.92 | rem mins    62 | loss 1.04053 | ppl   2.8307\n",
    "Learning rate: [0.0009622843450479256]\n",
    "40600/47582 batches | batch/sec  1.92 | rem mins    61 | loss 1.04811 | ppl   2.8522\n",
    "Learning rate: [0.0010229872204472836]\n",
    "40800/47582 batches | batch/sec  1.92 | rem mins    59 | loss 1.04707 | ppl   2.8493\n",
    "Learning rate: [0.001083690095846645]\n",
    "41000/47582 batches | batch/sec  1.92 | rem mins    57 | loss 1.04547 | ppl   2.8447\n",
    "Learning rate: [0.0011443929712460063]\n",
    "41200/47582 batches | batch/sec  1.92 | rem mins    55 | loss 1.05125 | ppl   2.8612\n",
    "Learning rate: [0.0012050958466453677]\n",
    "41400/47582 batches | batch/sec  1.92 | rem mins    54 | loss 1.05136 | ppl   2.8616\n",
    "Learning rate: [0.0012657987220447292]\n",
    "41600/47582 batches | batch/sec  1.92 | rem mins    52 | loss 1.06691 | ppl   2.9064\n",
    "Learning rate: [0.0013265015974440872]\n",
    "41800/47582 batches | batch/sec  1.92 | rem mins    50 | loss 1.07016 | ppl   2.9158\n",
    "Learning rate: [0.0013872044728434486]\n",
    "42000/47582 batches | batch/sec  1.92 | rem mins    48 | loss 1.07512 | ppl   2.9303\n",
    "Learning rate: [0.00144790734824281]\n",
    "42200/47582 batches | batch/sec  1.92 | rem mins    47 | loss 1.06918 | ppl   2.9130\n",
    "Learning rate: [0.0015086102236421713]\n",
    "42400/47582 batches | batch/sec  1.92 | rem mins    45 | loss 1.06823 | ppl   2.9102\n",
    "Learning rate: [0.0015693130990415327]\n",
    "42600/47582 batches | batch/sec  1.92 | rem mins    43 | loss 1.07672 | ppl   2.9350\n",
    "Learning rate: [0.0016300159744408941]\n",
    "42800/47582 batches | batch/sec  1.92 | rem mins    42 | loss 1.08035 | ppl   2.9457\n",
    "Learning rate: [0.0016907188498402556]\n",
    "43000/47582 batches | batch/sec  1.92 | rem mins    40 | loss 1.07897 | ppl   2.9416\n",
    "Learning rate: [0.0017514217252396168]\n",
    "43200/47582 batches | batch/sec  1.92 | rem mins    38 | loss 1.07769 | ppl   2.9379\n",
    "Learning rate: [0.0018121246006389783]\n",
    "43400/47582 batches | batch/sec  1.92 | rem mins    36 | loss 1.07806 | ppl   2.9390\n",
    "Learning rate: [0.0018728274760383397]\n",
    "43600/47582 batches | batch/sec  1.92 | rem mins    35 | loss 1.06282 | ppl   2.8945\n",
    "Learning rate: [0.0019335303514377011]\n",
    "43800/47582 batches | batch/sec  1.92 | rem mins    33 | loss 1.05591 | ppl   2.8746\n",
    "Learning rate: [0.0019942332268370624]\n",
    "44000/47582 batches | batch/sec  1.92 | rem mins    31 | loss 1.05097 | ppl   2.8604\n",
    "Learning rate: [0.0019450638977635763]\n",
    "44200/47582 batches | batch/sec  1.92 | rem mins    29 | loss 1.05144 | ppl   2.8618\n",
    "Learning rate: [0.0018843610223642148]\n",
    "44400/47582 batches | batch/sec  1.92 | rem mins    28 | loss 1.05002 | ppl   2.8577\n",
    "Learning rate: [0.0018236581469648569]\n",
    "44600/47582 batches | batch/sec  1.92 | rem mins    26 | loss 1.05202 | ppl   2.8634\n",
    "Learning rate: [0.0017629552715654954]\n",
    "44800/47582 batches | batch/sec  1.92 | rem mins    24 | loss 1.04303 | ppl   2.8378\n",
    "Learning rate: [0.001702252396166134]\n",
    "45000/47582 batches | batch/sec  1.92 | rem mins    22 | loss 1.04321 | ppl   2.8383\n",
    "Learning rate: [0.0016415495207667728]\n",
    "45200/47582 batches | batch/sec  1.92 | rem mins    21 | loss 1.04365 | ppl   2.8396\n",
    "Learning rate: [0.0015808466453674146]\n",
    "45400/47582 batches | batch/sec  1.92 | rem mins    19 | loss 1.04169 | ppl   2.8340\n",
    "Learning rate: [0.0015201437699680533]\n",
    "45600/47582 batches | batch/sec  1.92 | rem mins    17 | loss 1.04291 | ppl   2.8375\n",
    "Learning rate: [0.001459440894568692]\n",
    "45800/47582 batches | batch/sec  1.92 | rem mins    15 | loss 1.03469 | ppl   2.8142\n",
    "Learning rate: [0.0013987380191693305]\n",
    "46000/47582 batches | batch/sec  1.92 | rem mins    14 | loss 1.03489 | ppl   2.8148\n",
    "Learning rate: [0.001338035143769969]\n",
    "46200/47582 batches | batch/sec  1.92 | rem mins    12 | loss 1.03134 | ppl   2.8048\n",
    "Learning rate: [0.0012773322683706078]\n",
    "46400/47582 batches | batch/sec  1.92 | rem mins    10 | loss 1.02868 | ppl   2.7974\n",
    "Learning rate: [0.0012166293929712464]\n",
    "46600/47582 batches | batch/sec  1.92 | rem mins     9 | loss 1.02709 | ppl   2.7929\n",
    "Learning rate: [0.001155926517571885]\n",
    "46800/47582 batches | batch/sec  1.92 | rem mins     7 | loss 1.02689 | ppl   2.7924\n",
    "Learning rate: [0.0010952236421725235]\n",
    "47000/47582 batches | batch/sec  1.92 | rem mins     5 | loss 1.02737 | ppl   2.7937\n",
    "Learning rate: [0.001034520766773162]\n",
    "47200/47582 batches | batch/sec  1.92 | rem mins     3 | loss 1.02419 | ppl   2.7848\n",
    "Learning rate: [0.0009738178913738008]\n",
    "47400/47582 batches | batch/sec  1.92 | rem mins     2 | loss 1.02537 | ppl   2.7881\n",
    "Learning rate: [0.0009131150159744394]\n",
    "\n",
    "\"\"\".split('\\n')\n",
    "\n",
    "losses, learning_rates = parse_loss(training_log_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2756658-ba27-4d19-90d9-87e3f3b397d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.18458333 2.13040667 2.07715667 2.02216333 1.96747667 1.91433\n",
      " 1.86509667 1.82005333 1.77385    1.73791333 1.70736667 1.68715333\n",
      " 1.66219333 1.64372    1.62494    1.60948667 1.59239333 1.57382333\n",
      " 1.55768333 1.54352667 1.52611    1.51183333 1.49453667 1.48389667\n",
      " 1.46846333 1.45524    1.43908    1.42762667 1.41637333 1.40892333\n",
      " 1.39603    1.38347333 1.37127667 1.36433667 1.35484667 1.34636333\n",
      " 1.33651333 1.32824333 1.32036    1.31287    1.30508667 1.29675333\n",
      " 1.28850333 1.28631333 1.28224333 1.27836333 1.27303667 1.26696\n",
      " 1.26236333 1.25725333 1.25357333 1.25096667 1.24849333 1.24737\n",
      " 1.24305667 1.23821667 1.23345    1.23106667 1.22914667 1.22720333\n",
      " 1.22705333 1.22648667 1.22692333 1.22703333 1.22658333 1.22754667\n",
      " 1.22779667 1.22826    1.22524667 1.22264667 1.22226    1.22326667\n",
      " 1.22353667 1.22210667 1.22196667 1.22143    1.22046    1.21695\n",
      " 1.21590667 1.21507333 1.21493    1.21280667 1.20973    1.21574\n",
      " 1.22101333 1.22574    1.22152    1.21912667 1.21887333 1.21702333\n",
      " 1.21527    1.21312333 1.21121333 1.20327333 1.19063    1.17768333\n",
      " 1.17328333 1.17652333 1.18086    1.17981    1.17312333 1.16716333\n",
      " 1.16356333 1.15959667 1.15496333 1.15086333 1.14634667 1.14127\n",
      " 1.13421667 1.12881    1.12548333 1.12250667 1.12116    1.11751\n",
      " 1.11457    1.11295    1.11330333 1.11174333 1.10711333 1.10394667\n",
      " 1.10389333 1.10344667 1.10180333 1.09862    1.09916    1.09802333\n",
      " 1.09758333 1.09622333 1.09664333 1.09758    1.09738667 1.09746667\n",
      " 1.09713333 1.09737667 1.09734    1.10024333 1.10281667 1.10490667\n",
      " 1.1031     1.10088333 1.10139    1.10152    1.10153333 1.10196\n",
      " 1.10252    1.10553    1.10335333 1.10361    1.10727    1.11688333\n",
      " 1.12351    1.12792333 1.12519333 1.12613    1.12515333 1.12844333\n",
      " 1.12869333 1.12628667 1.11729333 1.10565    1.09599667 1.09048333\n",
      " 1.08886    1.08846667 1.09021    1.09176333 1.09262    1.09134667\n",
      " 1.08981667 1.08578    1.08323667 1.08068    1.07774667 1.07235333\n",
      " 1.06612    1.06188    1.05778667 1.05434667 1.05022333 1.04809333\n",
      " 1.04832    1.04901667 1.04999    1.04581333 1.04263667 1.04097\n",
      " 1.04227667 1.04204667 1.03925667 1.03815    1.03908333 1.04311667\n",
      " 1.04264333 1.04363    1.04144333 1.04339    1.04231    1.04340667\n",
      " 1.04428333 1.04361    1.04515333 1.04523667 1.04688333 1.04793\n",
      " 1.04936    1.05650667 1.06281    1.07073    1.07148667 1.07084333\n",
      " 1.07137667 1.0751     1.07868    1.07900333 1.07824    1.07285667\n",
      " 1.06559667 1.05656667 1.05277333 1.05081    1.05116    1.04835667\n",
      " 1.04608667 1.04329667 1.04285    1.04275    1.03976333 1.03749667\n",
      " 1.03364    1.03163667 1.02903667 1.02755333 1.02711667 1.02615\n",
      " 1.02564333]\n",
      "[0.00022171 0.00028241 0.00034312 0.00040382 0.00046452 0.00052522\n",
      " 0.00058593 0.00064663 0.00070733 0.00076804 0.00082874 0.00088944\n",
      " 0.00095014 0.00101085 0.00107155 0.00113225 0.00119296 0.00125366\n",
      " 0.00131436 0.00137506 0.00143577 0.00149647 0.00155717 0.00161788\n",
      " 0.00167858 0.00173928 0.00179998 0.00186069 0.00192139 0.00195356\n",
      " 0.00194527 0.0018965  0.0018358  0.0017751  0.00171439 0.00165369\n",
      " 0.00159299 0.00153228 0.00147158 0.00141088 0.00135018 0.00128947\n",
      " 0.00122877 0.00116807 0.00110736 0.00104666 0.00098596 0.00092526\n",
      " 0.00086455 0.00080385 0.00074315 0.00068244 0.00062174 0.00056104\n",
      " 0.00050034 0.00043963 0.00037893 0.00031823 0.00025752 0.00019682\n",
      " 0.00015251 0.00014866 0.00018529 0.00024599 0.00030669 0.0003674\n",
      " 0.0004281  0.0004888  0.0005495  0.00061021 0.00067091 0.00073161\n",
      " 0.00079232 0.00085302 0.00091372 0.00097442 0.00103513 0.00109583\n",
      " 0.00115653 0.00121724 0.00127794 0.00133864 0.00139935 0.00146005\n",
      " 0.00152075 0.00158145 0.00164216 0.00170286 0.00176356 0.00182427\n",
      " 0.00188497 0.00194142 0.00195741 0.00193292 0.00187222 0.00181152\n",
      " 0.00175081 0.00169011 0.00162941 0.00156871 0.001508   0.0014473\n",
      " 0.0013866  0.00132589 0.00126519 0.00120449 0.00114379 0.00108308\n",
      " 0.00102238 0.00096168 0.00090097 0.00084027 0.00077957 0.00071887\n",
      " 0.00065816 0.00059746 0.00053676 0.00047605 0.00041535 0.00035465\n",
      " 0.00029395 0.00023324 0.00017254 0.00014441 0.00015676 0.00020957\n",
      " 0.00027027 0.00033097 0.00039168 0.00045238 0.00051308 0.00057379\n",
      " 0.00063449 0.00069519 0.00075589 0.0008166  0.0008773  0.000938\n",
      " 0.00099871 0.00105941 0.00112011 0.00118081 0.00124152 0.00130222\n",
      " 0.00136292 0.00142363 0.00148433 0.00154503 0.00160573 0.00166644\n",
      " 0.00172714 0.00178784 0.00184855 0.00190925 0.00194952 0.00194931\n",
      " 0.00190864 0.00184794 0.00178724 0.00172653 0.00166583 0.00160513\n",
      " 0.00154442 0.00148372 0.00142302 0.00136232 0.00130161 0.00124091\n",
      " 0.00118021 0.0011195  0.0010588  0.0009981  0.0009374  0.00087669\n",
      " 0.00081599 0.00075529 0.00069458 0.00063388 0.00057318 0.00051248\n",
      " 0.00045177 0.00039107 0.00033037 0.00026966 0.00020896 0.00015655\n",
      " 0.00014462 0.00017315 0.00023385 0.00029455 0.00035526 0.00041596\n",
      " 0.00047666 0.00053736 0.00059807 0.00065877 0.00071947 0.00078018\n",
      " 0.00084088 0.00090158 0.00096228 0.00102299 0.00108369 0.00114439\n",
      " 0.0012051  0.0012658  0.0013265  0.0013872  0.00144791 0.00150861\n",
      " 0.00156931 0.00163002 0.00169072 0.00175142 0.00181212 0.00187283\n",
      " 0.00193353 0.00195761 0.00194122 0.00188436 0.00182366 0.00176296\n",
      " 0.00170225 0.00164155 0.00158085 0.00152014 0.00145944 0.00139874\n",
      " 0.00133804 0.00127733 0.00121663 0.00115593 0.00109522 0.00103452\n",
      " 0.00097382]\n",
      "y = -0.0019160172874660175x + 0.3999764456209828\n",
      "data start 1.4917895590507504 4.4450430726359915\n",
      "data end 0.9509558741512965 2.588182453993919\n",
      "+0.5 epoch 0.9509558741512965 2.588182453993919\n",
      "+1 epoch 0.9491501706407325 2.5835131807809844\n",
      "+2 epoch 0.9473478958541048 2.5788611734713016\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def smooth(data, window_width):\n",
    "    ret = np.cumsum(np.insert(data, 0, 0)) \n",
    "    return (ret[window_width:] - ret[:-window_width]) / window_width\n",
    "    \n",
    "smooth_window = 3\n",
    "\n",
    "start_idx = 0\n",
    "end_idx = len(losses)\n",
    "#end_idx -= 20\n",
    "\n",
    "total_batches = 47200#182396#\n",
    "print_rate = 47582#200\n",
    "\n",
    "smooth_loss = smooth(losses[start_idx:end_idx], smooth_window)\n",
    "smooth_learning = smooth(learning_rates[start_idx:end_idx], smooth_window)\n",
    "print(smooth_loss)\n",
    "print(smooth_learning)\n",
    "x_vals = np.arange(0, len(smooth_loss))\n",
    "\n",
    "\n",
    "x_vals = np.arange(0, len(smooth_loss))\n",
    "a, y = np.polyfit(x_vals, np.log(smooth_loss), 1)\n",
    "\n",
    "def predicted_value(x, a, y):\n",
    "    return np.exp(a*x) * np.exp(y)\n",
    "\n",
    "y_vals = predicted_value(x_vals, a, y)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "print(f\"y = {a}x + {y}\")\n",
    "\n",
    "future = predicted_value(0, a, y)\n",
    "print(\"data start\", future, np.exp(future))\n",
    "\n",
    "future = predicted_value(len(smooth_loss), a, y)\n",
    "print(\"data end\", future, np.exp(future))\n",
    "\n",
    "\n",
    "one_epoch = total_batches/print_rate\n",
    "future = predicted_value(len(smooth_loss) + one_epoch//2, a, y)\n",
    "print(\"+0.5 epoch\", future, np.exp(future))\n",
    "\n",
    "future = predicted_value(len(smooth_loss) + one_epoch, a, y)\n",
    "print(\"+1 epoch\", future, np.exp(future))\n",
    "\n",
    "future = predicted_value(len(smooth_loss) + one_epoch*2, a, y)\n",
    "print(\"+2 epoch\", future, np.exp(future))\n",
    "\n",
    "\n",
    "\n",
    "ax1.plot(smooth_loss, label=\"Loss\", color=\"blue\")\n",
    "ax1.plot(x_vals, y_vals, label=\"Trend Line\")\n",
    "ax2.plot(smooth_learning, label=\"Learning Rate\", color=\"red\")\n",
    "\n",
    "fig.legend()\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a23f5980-ecdc-4277-80ec-daa9e99e013e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30720\n",
      "tensor(0.0002) tensor(0.0002) tensor(0.5003)\n"
     ]
    }
   ],
   "source": [
    "from ai.stabledisco.utils.mathutils import norm_t\n",
    "\n",
    "def make_rand_shift(cnt):\n",
    "        shift = torch.randn((cnt, 768))\n",
    "        shift /= shift.norm(dim=-1, keepdim=True)\n",
    "        scale = random_scale(cnt)\n",
    "        return scale * shift\n",
    "\n",
    "def random_scale(cnt, mean=0.025, std=0.05, min_scale=0.05):\n",
    "    return torch.randn((cnt, 1)) * std + mean + min_scale\n",
    "\n",
    "tens = make_rand_shift(int(768*40))\n",
    "\n",
    "norms = tens.norm(dim=-1)\n",
    "\n",
    "tens = norm_t(tens)\n",
    "\n",
    "svd = torch.linalg.svd(tens)\n",
    "\n",
    "print(len(tens))\n",
    "print(torch.min(svd.S/len(tens)), torch.max(svd.S/len(tens)), torch.std(svd.S))\n",
    "\n",
    "positive_vec = norm_t(torch.ones(768))\n",
    "neg_vec = -positive_vec\n",
    "\n",
    "#print(sdutils.calc_singular_vecs(tens, cutoff=0))\n",
    "\n",
    "\n",
    "#plt.hist(norms, bins=20)\n",
    "#print(\"norms\", norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a52ea9c3-7966-43b8-85c2-aec9b482e72d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'to_ratings_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torchmodules\u001b[38;5;241m.\u001b[39msave_model(\u001b[43mto_ratings_model\u001b[49m, decoderpipeline\u001b[38;5;241m.\u001b[39mFeaturesToRatingModel\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_pruned\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'to_ratings_model' is not defined"
     ]
    }
   ],
   "source": [
    "import torch_pruning as tp\n",
    "import ai.torchmodules.pruning as torchprune\n",
    "ori_size = tp.utils.count_params(to_token_model)\n",
    "\n",
    "imp = tp.importance.MagnitudeImportance(2) \n",
    "#imp = tp.importance.SensitivityImportance() \n",
    "ignored_layers = []\n",
    "\n",
    "for name, module in to_token_model.named_modules():\n",
    "    if \"_rating_out\" in name or \"embedding\" in name or isinstance():\n",
    "        ignored_layers.append(module)\n",
    "    elif 'NonDynamicallyQuantizableLinear' in type(module).__name__:\n",
    "        ignored_layers.append(module)\n",
    "\n",
    "torchutils.torch_garbage_collect()\n",
    "total_steps = 1\n",
    "pruner = tp.pruner.GlobalMagnitudePruner( \n",
    "    to_token_model.cpu(),\n",
    "    example_inputs,\n",
    "    importance=imp,\n",
    "    total_steps=total_steps, # number of iterations\n",
    "    ch_sparsity=0.5, # channel sparsity\n",
    "    ignored_layers=ignored_layers, # ignored_layers will not be pruned\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdb705a-0389-45a9-b4c9-43b03ce408a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_log_lines = \"\"\"\n",
    " Starting training\n",
    "Starting epoch 0\n",
    "  100/99489 batches | batch/sec  1.13 | rem mins  1469 | loss 3.07427 | ppl  21.6342\n",
    "Learning rate: [4.290880000000003e-05]\n",
    "  200/99489 batches | batch/sec  1.58 | rem mins  1047 | loss 3.04144 | ppl  20.9354\n",
    "Learning rate: [4.578880000000004e-05]\n",
    "  300/99489 batches | batch/sec  1.58 | rem mins  1049 | loss 3.04156 | ppl  20.9379\n",
    "Learning rate: [4.866880000000004e-05]\n",
    "  400/99489 batches | batch/sec  1.57 | rem mins  1049 | loss 3.01757 | ppl  20.4415\n",
    "Learning rate: [5.1548800000000044e-05]\n",
    "  500/99489 batches | batch/sec  1.57 | rem mins  1049 | loss 3.01923 | ppl  20.4755\n",
    "Learning rate: [5.4428800000000044e-05]\n",
    "  600/99489 batches | batch/sec  1.57 | rem mins  1048 | loss 3.04944 | ppl  21.1035\n",
    "Learning rate: [5.730880000000005e-05]\n",
    "  700/99489 batches | batch/sec  1.58 | rem mins  1045 | loss 3.02444 | ppl  20.5824\n",
    "Learning rate: [6.018880000000005e-05]\n",
    "  800/99489 batches | batch/sec  1.57 | rem mins  1045 | loss 3.02687 | ppl  20.6326\n",
    "Learning rate: [6.306880000000006e-05]\n",
    "  900/99489 batches | batch/sec  1.57 | rem mins  1044 | loss 3.04210 | ppl  20.9491\n",
    "Learning rate: [6.594880000000006e-05]\n",
    " 1000/99489 batches | batch/sec  1.57 | rem mins  1044 | loss 3.01670 | ppl  20.4237\n",
    "Learning rate: [6.882880000000005e-05]\n",
    " 1300/99489 batches | batch/sec  1.58 | rem mins  1039 | loss 3.01642 | ppl  20.4181\n",
    "Learning rate: [7.746880000000007e-05]\n",
    " 1400/99489 batches | batch/sec  1.57 | rem mins  1039 | loss 3.03772 | ppl  20.8576\n",
    "Learning rate: [8.034880000000008e-05]\n",
    " 1500/99489 batches | batch/sec  1.57 | rem mins  1037 | loss 3.02698 | ppl  20.6349\n",
    "Learning rate: [8.322880000000008e-05]\n",
    " 1600/99489 batches | batch/sec  1.57 | rem mins  1037 | loss 3.02236 | ppl  20.5397\n",
    "Learning rate: [8.610880000000008e-05]\n",
    " 1700/99489 batches | batch/sec  1.57 | rem mins  1036 | loss 3.02438 | ppl  20.5812\n",
    "Learning rate: [8.898880000000008e-05]\n",
    " 1800/99489 batches | batch/sec  1.57 | rem mins  1035 | loss 3.02482 | ppl  20.5903\n",
    "Learning rate: [9.186880000000008e-05]\n",
    " 1900/99489 batches | batch/sec  1.57 | rem mins  1034 | loss 3.02391 | ppl  20.5716\n",
    "Learning rate: [9.474879999999992e-05]\n",
    " 2000/99489 batches | batch/sec  1.57 | rem mins  1032 | loss 3.05349 | ppl  21.1892\n",
    "Learning rate: [9.762879999999993e-05]\n",
    " 2100/99489 batches | batch/sec  1.58 | rem mins  1030 | loss 3.02479 | ppl  20.5896\n",
    "Learning rate: [0.00010050879999999993]\n",
    " 2200/99489 batches | batch/sec  1.57 | rem mins  1030 | loss 3.03380 | ppl  20.7760\n",
    "Learning rate: [0.00010338879999999994]\n",
    " 2300/99489 batches | batch/sec  1.58 | rem mins  1028 | loss 3.02465 | ppl  20.5868\n",
    "Learning rate: [0.00010626879999999994]\n",
    " 2400/99489 batches | batch/sec  1.57 | rem mins  1028 | loss 3.02617 | ppl  20.6181\n",
    "Learning rate: [0.00010914879999999994]\n",
    " 2500/99489 batches | batch/sec  1.57 | rem mins  1027 | loss 3.05955 | ppl  21.3180\n",
    "Learning rate: [0.00011202879999999994]\n",
    " 2600/99489 batches | batch/sec  1.57 | rem mins  1025 | loss 3.01967 | ppl  20.4846\n",
    "Learning rate: [0.00011490879999999994]\n",
    " 2700/99489 batches | batch/sec  1.58 | rem mins  1023 | loss 3.03576 | ppl  20.8168\n",
    "Learning rate: [0.00011778879999999994]\n",
    " 2800/99489 batches | batch/sec  1.58 | rem mins  1023 | loss 3.04834 | ppl  21.0804\n",
    "Learning rate: [0.00012066879999999994]\n",
    " 2900/99489 batches | batch/sec  1.57 | rem mins  1022 | loss 3.05439 | ppl  21.2083\n",
    "Learning rate: [0.00012354879999999996]\n",
    " 3000/99489 batches | batch/sec  1.57 | rem mins  1021 | loss 3.05902 | ppl  21.3067\n",
    "Learning rate: [0.00012642879999999996]\n",
    " 3100/99489 batches | batch/sec  1.58 | rem mins  1020 | loss 3.04757 | ppl  21.0640\n",
    "Learning rate: [0.00012930879999999996]\n",
    " 3200/99489 batches | batch/sec  1.57 | rem mins  1019 | loss 3.03710 | ppl  20.8447\n",
    "Learning rate: [0.00013218879999999996]\n",
    " 3300/99489 batches | batch/sec  1.57 | rem mins  1018 | loss 3.04445 | ppl  20.9985\n",
    "Learning rate: [0.00013506879999999996]\n",
    " 3400/99489 batches | batch/sec  1.58 | rem mins  1016 | loss 3.06158 | ppl  21.3612\n",
    "Learning rate: [0.00013794879999999996]\n",
    " 3500/99489 batches | batch/sec  1.58 | rem mins  1015 | loss 3.01813 | ppl  20.4530\n",
    "Learning rate: [0.00014082879999999996]\n",
    " 3600/99489 batches | batch/sec  1.57 | rem mins  1015 | loss 3.05853 | ppl  21.2962\n",
    "Learning rate: [0.00014370879999999996]\n",
    " 3700/99489 batches | batch/sec  1.57 | rem mins  1014 | loss 3.04071 | ppl  20.9201\n",
    "Learning rate: [0.00014658879999999996]\n",
    " 3800/99489 batches | batch/sec  1.57 | rem mins  1013 | loss 3.06610 | ppl  21.4580\n",
    "Learning rate: [0.0001494688]\n",
    " 3900/99489 batches | batch/sec  1.57 | rem mins  1012 | loss 3.03917 | ppl  20.8879\n",
    "Learning rate: [0.0001523488]\n",
    " 4000/99489 batches | batch/sec  1.58 | rem mins  1010 | loss 3.06409 | ppl  21.4150\n",
    "Learning rate: [0.0001552288]\n",
    " 4100/99489 batches | batch/sec  1.58 | rem mins  1009 | loss 3.05472 | ppl  21.2152\n",
    "Learning rate: [0.00015810879999999999]\n",
    " 4200/99489 batches | batch/sec  1.58 | rem mins  1008 | loss 3.05307 | ppl  21.1802\n",
    "Learning rate: [0.00016098879999999999]\n",
    " 4300/99489 batches | batch/sec  1.57 | rem mins  1007 | loss 3.05616 | ppl  21.2458\n",
    "Learning rate: [0.00016386879999999999]\n",
    " 4400/99489 batches | batch/sec  1.57 | rem mins  1007 | loss 3.02554 | ppl  20.6052\n",
    "Learning rate: [0.00016674879999999998]\n",
    " 4500/99489 batches | batch/sec  1.58 | rem mins  1005 | loss 3.04604 | ppl  21.0318\n",
    "Learning rate: [0.00016962879999999998]\n",
    " 4600/99489 batches | batch/sec  1.57 | rem mins  1004 | loss 3.04623 | ppl  21.0358\n",
    "Learning rate: [0.00017250879999999998]\n",
    " 4700/99489 batches | batch/sec  1.57 | rem mins  1004 | loss 3.04291 | ppl  20.9661\n",
    "Learning rate: [0.00017538879999999998]\n",
    " 4800/99489 batches | batch/sec  1.57 | rem mins  1003 | loss 3.03741 | ppl  20.8511\n",
    "Learning rate: [0.0001782688]\n",
    " 4900/99489 batches | batch/sec  1.58 | rem mins  1001 | loss 3.02868 | ppl  20.6699\n",
    "Learning rate: [0.0001811488]\n",
    " 5000/99489 batches | batch/sec  1.57 | rem mins  1001 | loss 3.03773 | ppl  20.8578\n",
    "Learning rate: [0.0001840288]\n",
    " 5100/99489 batches | batch/sec  1.58 | rem mins   999 | loss 3.02667 | ppl  20.6285\n",
    "Learning rate: [0.0001869088]\n",
    " 5200/99489 batches | batch/sec  1.57 | rem mins   998 | loss 3.04937 | ppl  21.1020\n",
    "Learning rate: [0.0001897888]\n",
    " 5300/99489 batches | batch/sec  1.57 | rem mins   998 | loss 3.03507 | ppl  20.8025\n",
    "Learning rate: [0.0001926688]\n",
    " 5400/99489 batches | batch/sec  1.58 | rem mins   995 | loss 3.02489 | ppl  20.5917\n",
    "Learning rate: [0.0001955488]\n",
    " 5500/99489 batches | batch/sec  1.58 | rem mins   994 | loss 3.03319 | ppl  20.7633\n",
    "Learning rate: [0.0001984288]\n",
    " 5600/99489 batches | batch/sec  1.57 | rem mins   994 | loss 3.04220 | ppl  20.9513\n",
    "Learning rate: [0.0002013088]\n",
    " 5700/99489 batches | batch/sec  1.57 | rem mins   994 | loss 3.03960 | ppl  20.8968\n",
    "Learning rate: [0.00020418880000000003]\n",
    " 5800/99489 batches | batch/sec  1.57 | rem mins   992 | loss 3.03581 | ppl  20.8179\n",
    "Learning rate: [0.00020706880000000003]\n",
    " 5900/99489 batches | batch/sec  1.58 | rem mins   990 | loss 3.04514 | ppl  21.0129\n",
    "Learning rate: [0.00020994880000000003]\n",
    " 6000/99489 batches | batch/sec  1.57 | rem mins   990 | loss 3.02850 | ppl  20.6662\n",
    "Learning rate: [0.00021282880000000003]\n",
    " 6100/99489 batches | batch/sec  1.58 | rem mins   988 | loss 3.04919 | ppl  21.0983\n",
    "Learning rate: [0.00021570880000000003]\n",
    " 6200/99489 batches | batch/sec  1.57 | rem mins   987 | loss 3.05216 | ppl  21.1611\n",
    "Learning rate: [0.00021858880000000003]\n",
    " 6300/99489 batches | batch/sec  1.58 | rem mins   985 | loss 3.04441 | ppl  20.9977\n",
    "Learning rate: [0.00022146880000000003]\n",
    " 6400/99489 batches | batch/sec  1.57 | rem mins   986 | loss 3.01872 | ppl  20.4651\n",
    "Learning rate: [0.00022434880000000003]\n",
    " 6500/99489 batches | batch/sec  1.57 | rem mins   985 | loss 3.04918 | ppl  21.0981\n",
    "Learning rate: [0.00022722880000000006]\n",
    " 6600/99489 batches | batch/sec  1.58 | rem mins   983 | loss 3.02609 | ppl  20.6164\n",
    "Learning rate: [0.00023010880000000006]\n",
    " 6700/99489 batches | batch/sec  1.57 | rem mins   982 | loss 3.01756 | ppl  20.4414\n",
    "Learning rate: [0.00023298880000000006]\n",
    " 6800/99489 batches | batch/sec  1.57 | rem mins   981 | loss 3.02822 | ppl  20.6605\n",
    "Learning rate: [0.00023586880000000005]\n",
    " 6900/99489 batches | batch/sec  1.58 | rem mins   980 | loss 3.04450 | ppl  20.9994\n",
    "Learning rate: [0.00023874880000000005]\n",
    " 7000/99489 batches | batch/sec  1.58 | rem mins   978 | loss 3.01636 | ppl  20.4168\n",
    "Learning rate: [0.00024162880000000005]\n",
    " 7100/99489 batches | batch/sec  1.58 | rem mins   977 | loss 3.03515 | ppl  20.8041\n",
    "Learning rate: [0.00024450880000000005]\n",
    " 7200/99489 batches | batch/sec  1.58 | rem mins   976 | loss 3.04261 | ppl  20.9598\n",
    "Learning rate: [0.0002473888000000001]\n",
    " 7300/99489 batches | batch/sec  1.58 | rem mins   975 | loss 3.02960 | ppl  20.6889\n",
    "Learning rate: [0.00025026880000000005]\n",
    " 7400/99489 batches | batch/sec  1.58 | rem mins   974 | loss 3.04064 | ppl  20.9187\n",
    "Learning rate: [0.0002531488000000001]\n",
    " 7500/99489 batches | batch/sec  1.58 | rem mins   973 | loss 3.06267 | ppl  21.3846\n",
    "Learning rate: [0.0002560288000000001]\n",
    " 7600/99489 batches | batch/sec  1.57 | rem mins   973 | loss 3.04423 | ppl  20.9939\n",
    "Learning rate: [0.0002589088000000001]\n",
    " 7700/99489 batches | batch/sec  1.58 | rem mins   971 | loss 3.07206 | ppl  21.5864\n",
    "Learning rate: [0.0002617888000000001]\n",
    " 7800/99489 batches | batch/sec  1.57 | rem mins   970 | loss 3.04298 | ppl  20.9676\n",
    "Learning rate: [0.0002646688000000001]\n",
    " 7900/99489 batches | batch/sec  1.57 | rem mins   970 | loss 3.03984 | ppl  20.9019\n",
    "Learning rate: [0.0002675488000000001]\n",
    " 8000/99489 batches | batch/sec  1.58 | rem mins   968 | loss 3.03335 | ppl  20.7668\n",
    "Learning rate: [0.0002704288000000001]\n",
    " 8100/99489 batches | batch/sec  1.57 | rem mins   967 | loss 3.04035 | ppl  20.9126\n",
    "Learning rate: [0.0002733088000000001]\n",
    " 8200/99489 batches | batch/sec  1.57 | rem mins   966 | loss 3.05636 | ppl  21.2501\n",
    "Learning rate: [0.00027618880000000013]\n",
    " 8300/99489 batches | batch/sec  1.57 | rem mins   966 | loss 3.05487 | ppl  21.2185\n",
    "Learning rate: [0.0002790688000000001]\n",
    " 8400/99489 batches | batch/sec  1.58 | rem mins   964 | loss 3.02947 | ppl  20.6863\n",
    "Learning rate: [0.00028194880000000013]\n",
    " 8500/99489 batches | batch/sec  1.57 | rem mins   963 | loss 3.03854 | ppl  20.8748\n",
    "Learning rate: [0.0002848288000000001]\n",
    " 8600/99489 batches | batch/sec  1.57 | rem mins   963 | loss 3.02846 | ppl  20.6655\n",
    "Learning rate: [0.00028770880000000013]\n",
    " 8700/99489 batches | batch/sec  1.57 | rem mins   961 | loss 3.04142 | ppl  20.9349\n",
    "Learning rate: [0.0002905888000000001]\n",
    " 8800/99489 batches | batch/sec  1.58 | rem mins   959 | loss 3.03323 | ppl  20.7643\n",
    "Learning rate: [0.0002934688000000001]\n",
    " 8900/99489 batches | batch/sec  1.58 | rem mins   958 | loss 3.06547 | ppl  21.4445\n",
    "Learning rate: [0.0002963488000000001]\n",
    " 9000/99489 batches | batch/sec  1.58 | rem mins   957 | loss 3.05161 | ppl  21.1494\n",
    "Learning rate: [0.0002992288000000001]\n",
    " 9100/99489 batches | batch/sec  1.58 | rem mins   956 | loss 3.04129 | ppl  20.9322\n",
    "Learning rate: [0.00030210879999999994]\n",
    " 9200/99489 batches | batch/sec  1.57 | rem mins   956 | loss 3.04471 | ppl  21.0040\n",
    "Learning rate: [0.00030498879999999996]\n",
    " 9300/99489 batches | batch/sec  1.58 | rem mins   954 | loss 3.06007 | ppl  21.3290\n",
    "Learning rate: [0.00030786879999999993]\n",
    " 9400/99489 batches | batch/sec  1.58 | rem mins   953 | loss 3.05090 | ppl  21.1343\n",
    "Learning rate: [0.00031074879999999996]\n",
    " 9500/99489 batches | batch/sec  1.57 | rem mins   952 | loss 3.06023 | ppl  21.3325\n",
    "Learning rate: [0.0003136288]\n",
    " 9600/99489 batches | batch/sec  1.58 | rem mins   951 | loss 3.05288 | ppl  21.1762\n",
    "Learning rate: [0.00031650879999999996]\n",
    " 9700/99489 batches | batch/sec  1.58 | rem mins   950 | loss 3.02620 | ppl  20.6188\n",
    "Learning rate: [0.0003193888]\n",
    " 9800/99489 batches | batch/sec  1.58 | rem mins   948 | loss 3.05475 | ppl  21.2158\n",
    "Learning rate: [0.00032226879999999996]\n",
    " 9900/99489 batches | batch/sec  1.58 | rem mins   948 | loss 3.03472 | ppl  20.7952\n",
    "Learning rate: [0.0003251488]\n",
    "10000/99489 batches | batch/sec  1.58 | rem mins   947 | loss 3.06065 | ppl  21.3414\n",
    "Learning rate: [0.00032802879999999996]\n",
    "10100/99489 batches | batch/sec  1.58 | rem mins   945 | loss 3.04824 | ppl  21.0782\n",
    "Learning rate: [0.0003309088]\n",
    "10200/99489 batches | batch/sec  1.58 | rem mins   944 | loss 3.05494 | ppl  21.2199\n",
    "Learning rate: [0.0003337888]\n",
    "10300/99489 batches | batch/sec  1.58 | rem mins   942 | loss 3.04929 | ppl  21.1003\n",
    "Learning rate: [0.0003366688]\n",
    "10400/99489 batches | batch/sec  1.58 | rem mins   942 | loss 3.04985 | ppl  21.1122\n",
    "Learning rate: [0.0003395488]\n",
    "10500/99489 batches | batch/sec  1.58 | rem mins   941 | loss 3.02429 | ppl  20.5794\n",
    "Learning rate: [0.0003424288]\n",
    "10600/99489 batches | batch/sec  1.58 | rem mins   939 | loss 3.04732 | ppl  21.0589\n",
    "Learning rate: [0.0003453088]\n",
    "10700/99489 batches | batch/sec  1.58 | rem mins   938 | loss 3.06266 | ppl  21.3843\n",
    "Learning rate: [0.0003481888]\n",
    "10800/99489 batches | batch/sec  1.58 | rem mins   937 | loss 3.06438 | ppl  21.4211\n",
    "Learning rate: [0.0003510688]\n",
    "10900/99489 batches | batch/sec  1.58 | rem mins   935 | loss 3.04285 | ppl  20.9648\n",
    "Learning rate: [0.0003539488]\n",
    "11000/99489 batches | batch/sec  1.58 | rem mins   935 | loss 3.05010 | ppl  21.1175\n",
    "Learning rate: [0.0003568288]\n",
    "11100/99489 batches | batch/sec  1.58 | rem mins   934 | loss 3.06314 | ppl  21.3947\n",
    "Learning rate: [0.00035970880000000003]\n",
    "11200/99489 batches | batch/sec  1.58 | rem mins   932 | loss 3.03137 | ppl  20.7256\n",
    "Learning rate: [0.0003625888]\n",
    "11300/99489 batches | batch/sec  1.58 | rem mins   932 | loss 3.05974 | ppl  21.3220\n",
    "Learning rate: [0.00036546880000000003]\n",
    "11400/99489 batches | batch/sec  1.58 | rem mins   932 | loss 3.07783 | ppl  21.7112\n",
    "Learning rate: [0.0003683488]\n",
    "11500/99489 batches | batch/sec  1.58 | rem mins   930 | loss 3.04664 | ppl  21.0445\n",
    "Learning rate: [0.00037122880000000003]\n",
    "11600/99489 batches | batch/sec  1.58 | rem mins   929 | loss 3.05464 | ppl  21.2136\n",
    "Learning rate: [0.0003741088]\n",
    "11700/99489 batches | batch/sec  1.58 | rem mins   929 | loss 3.06994 | ppl  21.5406\n",
    "Learning rate: [0.00037698880000000003]\n",
    "11800/99489 batches | batch/sec  1.58 | rem mins   927 | loss 3.05759 | ppl  21.2762\n",
    "Learning rate: [0.0003798688]\n",
    "11900/99489 batches | batch/sec  1.57 | rem mins   927 | loss 3.05263 | ppl  21.1709\n",
    "Learning rate: [0.00038274880000000003]\n",
    "12000/99489 batches | batch/sec  1.57 | rem mins   927 | loss 3.06384 | ppl  21.4095\n",
    "Learning rate: [0.00038562880000000006]\n",
    "12100/99489 batches | batch/sec  1.57 | rem mins   925 | loss 3.04384 | ppl  20.9856\n",
    "Learning rate: [0.00038850880000000003]\n",
    "12200/99489 batches | batch/sec  1.57 | rem mins   924 | loss 3.07561 | ppl  21.6630\n",
    "Learning rate: [0.00039138880000000006]\n",
    "12300/99489 batches | batch/sec  1.57 | rem mins   923 | loss 3.05374 | ppl  21.1944\n",
    "Learning rate: [0.00039426880000000003]\n",
    "12400/99489 batches | batch/sec  1.57 | rem mins   924 | loss 3.05767 | ppl  21.2780\n",
    "Learning rate: [0.00039714880000000006]\n",
    "12500/99489 batches | batch/sec  1.57 | rem mins   921 | loss 3.06178 | ppl  21.3656\n",
    "Learning rate: [0.0003999712]\n",
    "12600/99489 batches | batch/sec  1.57 | rem mins   921 | loss 3.05312 | ppl  21.1813\n",
    "Learning rate: [0.0003970912]\n",
    "12700/99489 batches | batch/sec  1.57 | rem mins   920 | loss 3.07439 | ppl  21.6367\n",
    "Learning rate: [0.0003942112]\n",
    "12800/99489 batches | batch/sec  1.57 | rem mins   920 | loss 3.05917 | ppl  21.3098\n",
    "Learning rate: [0.0003913312]\n",
    "12900/99489 batches | batch/sec  1.57 | rem mins   919 | loss 3.05712 | ppl  21.2663\n",
    "Learning rate: [0.00038845119999999996]\n",
    "13000/99489 batches | batch/sec  1.57 | rem mins   917 | loss 3.04948 | ppl  21.1044\n",
    "Learning rate: [0.00038557120000000015]\n",
    "13100/99489 batches | batch/sec  1.57 | rem mins   917 | loss 3.07613 | ppl  21.6744\n",
    "Learning rate: [0.0003826912000000001]\n",
    "13200/99489 batches | batch/sec  1.57 | rem mins   916 | loss 3.05646 | ppl  21.2521\n",
    "Learning rate: [0.00037981120000000015]\n",
    "13300/99489 batches | batch/sec  1.57 | rem mins   915 | loss 3.07489 | ppl  21.6476\n",
    "Learning rate: [0.0003769312000000001]\n",
    "13400/99489 batches | batch/sec  1.57 | rem mins   914 | loss 3.03786 | ppl  20.8605\n",
    "Learning rate: [0.00037405120000000015]\n",
    "13500/99489 batches | batch/sec  1.57 | rem mins   912 | loss 3.06986 | ppl  21.5389\n",
    "Learning rate: [0.0003711712000000001]\n",
    "13600/99489 batches | batch/sec  1.57 | rem mins   911 | loss 3.05018 | ppl  21.1192\n",
    "Learning rate: [0.0003682912000000001]\n",
    "13700/99489 batches | batch/sec  1.57 | rem mins   909 | loss 3.05517 | ppl  21.2247\n",
    "Learning rate: [0.0003654112000000001]\n",
    "13800/99489 batches | batch/sec  1.57 | rem mins   908 | loss 3.03548 | ppl  20.8109\n",
    "Learning rate: [0.0003625312000000001]\n",
    "13900/99489 batches | batch/sec  1.57 | rem mins   907 | loss 3.05231 | ppl  21.1642\n",
    "Learning rate: [0.0003596512000000001]\n",
    "14000/99489 batches | batch/sec  1.57 | rem mins   906 | loss 3.04224 | ppl  20.9521\n",
    "Learning rate: [0.0003567712000000001]\n",
    "14100/99489 batches | batch/sec  1.57 | rem mins   905 | loss 3.06125 | ppl  21.3542\n",
    "Learning rate: [0.0003538912000000001]\n",
    "14200/99489 batches | batch/sec  1.57 | rem mins   904 | loss 3.04563 | ppl  21.0233\n",
    "Learning rate: [0.0003510112000000001]\n",
    "14300/99489 batches | batch/sec  1.57 | rem mins   903 | loss 3.04691 | ppl  21.0502\n",
    "Learning rate: [0.0003481312000000001]\n",
    "14400/99489 batches | batch/sec  1.58 | rem mins   900 | loss 3.04306 | ppl  20.9693\n",
    "Learning rate: [0.0003452512000000001]\n",
    "14500/99489 batches | batch/sec  1.58 | rem mins   899 | loss 3.03796 | ppl  20.8627\n",
    "Learning rate: [0.0003423712000000001]\n",
    "14600/99489 batches | batch/sec  1.58 | rem mins   898 | loss 3.03271 | ppl  20.7534\n",
    "Learning rate: [0.0003394912000000001]\n",
    "14700/99489 batches | batch/sec  1.58 | rem mins   896 | loss 3.04386 | ppl  20.9861\n",
    "Learning rate: [0.0003366112000000001]\n",
    "14800/99489 batches | batch/sec  1.57 | rem mins   897 | loss 3.05623 | ppl  21.2473\n",
    "Learning rate: [0.0003337312000000001]\n",
    "14900/99489 batches | batch/sec  1.58 | rem mins   895 | loss 3.03616 | ppl  20.8252\n",
    "Learning rate: [0.0003308512000000001]\n",
    "15000/99489 batches | batch/sec  1.57 | rem mins   895 | loss 3.04840 | ppl  21.0815\n",
    "Learning rate: [0.0003279712000000001]\n",
    "15100/99489 batches | batch/sec  1.57 | rem mins   894 | loss 3.04412 | ppl  20.9916\n",
    "Learning rate: [0.0003250912000000001]\n",
    "15200/99489 batches | batch/sec  1.57 | rem mins   893 | loss 3.03257 | ppl  20.7505\n",
    "Learning rate: [0.00032221120000000005]\n",
    "15300/99489 batches | batch/sec  1.58 | rem mins   890 | loss 3.04870 | ppl  21.0880\n",
    "Learning rate: [0.0003193312000000001]\n",
    "15400/99489 batches | batch/sec  1.58 | rem mins   889 | loss 3.04297 | ppl  20.9674\n",
    "Learning rate: [0.00031645120000000005]\n",
    "15500/99489 batches | batch/sec  1.58 | rem mins   888 | loss 3.05317 | ppl  21.1825\n",
    "Learning rate: [0.0003135712000000001]\n",
    "15600/99489 batches | batch/sec  1.57 | rem mins   888 | loss 3.03841 | ppl  20.8721\n",
    "Learning rate: [0.00031069120000000005]\n",
    "15700/99489 batches | batch/sec  1.58 | rem mins   886 | loss 3.03643 | ppl  20.8308\n",
    "Learning rate: [0.0003078112000000001]\n",
    "15800/99489 batches | batch/sec  1.58 | rem mins   884 | loss 3.04120 | ppl  20.9303\n",
    "Learning rate: [0.00030493120000000005]\n",
    "15900/99489 batches | batch/sec  1.58 | rem mins   884 | loss 3.05452 | ppl  21.2110\n",
    "Learning rate: [0.0003020512000000001]\n",
    "16000/99489 batches | batch/sec  1.58 | rem mins   883 | loss 3.04046 | ppl  20.9149\n",
    "Learning rate: [0.00029917120000000005]\n",
    "16100/99489 batches | batch/sec  1.58 | rem mins   881 | loss 3.04276 | ppl  20.9630\n",
    "Learning rate: [0.00029629120000000003]\n",
    "16200/99489 batches | batch/sec  1.58 | rem mins   881 | loss 3.02564 | ppl  20.6073\n",
    "Learning rate: [0.00029341120000000005]\n",
    "16300/99489 batches | batch/sec  1.58 | rem mins   879 | loss 3.03379 | ppl  20.7758\n",
    "Learning rate: [0.00029053120000000003]\n",
    "16400/99489 batches | batch/sec  1.58 | rem mins   879 | loss 3.03719 | ppl  20.8465\n",
    "Learning rate: [0.00028765120000000006]\n",
    "16500/99489 batches | batch/sec  1.58 | rem mins   877 | loss 3.05069 | ppl  21.1299\n",
    "Learning rate: [0.00028477120000000003]\n",
    "16600/99489 batches | batch/sec  1.58 | rem mins   876 | loss 3.01702 | ppl  20.4303\n",
    "Learning rate: [0.00028189120000000006]\n",
    "16700/99489 batches | batch/sec  1.58 | rem mins   875 | loss 3.04158 | ppl  20.9384\n",
    "Learning rate: [0.00027901120000000003]\n",
    "16800/99489 batches | batch/sec  1.58 | rem mins   874 | loss 3.03716 | ppl  20.8459\n",
    "Learning rate: [0.00027613120000000006]\n",
    "16900/99489 batches | batch/sec  1.58 | rem mins   873 | loss 3.02332 | ppl  20.5595\n",
    "Learning rate: [0.00027325120000000003]\n",
    "17000/99489 batches | batch/sec  1.58 | rem mins   872 | loss 3.02929 | ppl  20.6825\n",
    "Learning rate: [0.00027037120000000006]\n",
    "17100/99489 batches | batch/sec  1.58 | rem mins   871 | loss 3.02344 | ppl  20.5620\n",
    "Learning rate: [0.00026749120000000003]\n",
    "17200/99489 batches | batch/sec  1.58 | rem mins   869 | loss 3.05259 | ppl  21.1702\n",
    "Learning rate: [0.00026461120000000006]\n",
    "17300/99489 batches | batch/sec  1.58 | rem mins   868 | loss 3.02256 | ppl  20.5439\n",
    "Learning rate: [0.00026173120000000003]\n",
    "17400/99489 batches | batch/sec  1.58 | rem mins   867 | loss 3.03590 | ppl  20.8198\n",
    "Learning rate: [0.0002588512]\n",
    "17500/99489 batches | batch/sec  1.58 | rem mins   866 | loss 3.03604 | ppl  20.8227\n",
    "Learning rate: [0.00025597120000000003]\n",
    "17600/99489 batches | batch/sec  1.58 | rem mins   864 | loss 3.01852 | ppl  20.4611\n",
    "Learning rate: [0.0002530912]\n",
    "17700/99489 batches | batch/sec  1.58 | rem mins   864 | loss 3.00882 | ppl  20.2635\n",
    "Learning rate: [0.00025021120000000003]\n",
    "17800/99489 batches | batch/sec  1.58 | rem mins   864 | loss 3.03817 | ppl  20.8669\n",
    "Learning rate: [0.0002473312]\n",
    "17900/99489 batches | batch/sec  1.58 | rem mins   862 | loss 3.03115 | ppl  20.7211\n",
    "Learning rate: [0.00024445120000000004]\n",
    "18000/99489 batches | batch/sec  1.58 | rem mins   862 | loss 3.00677 | ppl  20.2220\n",
    "Learning rate: [0.0002415712]\n",
    "18100/99489 batches | batch/sec  1.58 | rem mins   861 | loss 3.02588 | ppl  20.6122\n",
    "Learning rate: [0.0002386912]\n",
    "18200/99489 batches | batch/sec  1.58 | rem mins   859 | loss 3.01718 | ppl  20.4335\n",
    "Learning rate: [0.00023581119999999998]\n",
    "18300/99489 batches | batch/sec  1.58 | rem mins   859 | loss 3.01244 | ppl  20.3370\n",
    "Learning rate: [0.00023293119999999998]\n",
    "18400/99489 batches | batch/sec  1.58 | rem mins   857 | loss 3.02895 | ppl  20.6755\n",
    "Learning rate: [0.00023005119999999998]\n",
    "18500/99489 batches | batch/sec  1.57 | rem mins   857 | loss 3.02411 | ppl  20.5757\n",
    "Learning rate: [0.00022717119999999998]\n",
    "18600/99489 batches | batch/sec  1.57 | rem mins   856 | loss 3.02975 | ppl  20.6921\n",
    "Learning rate: [0.00022429119999999998]\n",
    "18700/99489 batches | batch/sec  1.59 | rem mins   847 | loss 2.99326 | ppl  19.9505\n",
    "Learning rate: [0.00022141119999999999]\n",
    "18800/99489 batches | batch/sec  1.67 | rem mins   804 | loss 3.02426 | ppl  20.5788\n",
    "Learning rate: [0.00021853119999999999]\n",
    "18900/99489 batches | batch/sec  1.67 | rem mins   803 | loss 3.00274 | ppl  20.1406\n",
    "Learning rate: [0.00021565119999999999]\n",
    "19000/99489 batches | batch/sec  1.67 | rem mins   803 | loss 3.00193 | ppl  20.1244\n",
    "Learning rate: [0.00021277119999999996]\n",
    "19100/99489 batches | batch/sec  1.67 | rem mins   801 | loss 2.99459 | ppl  19.9772\n",
    "Learning rate: [0.00020989119999999996]\n",
    "19200/99489 batches | batch/sec  1.67 | rem mins   801 | loss 2.99826 | ppl  20.0507\n",
    "Learning rate: [0.00020701119999999996]\n",
    "19300/99489 batches | batch/sec  1.67 | rem mins   800 | loss 2.99384 | ppl  19.9622\n",
    "Learning rate: [0.00020413119999999996]\n",
    "19400/99489 batches | batch/sec  1.67 | rem mins   799 | loss 3.01141 | ppl  20.3159\n",
    "Learning rate: [0.00020125119999999996]\n",
    "19500/99489 batches | batch/sec  1.67 | rem mins   798 | loss 2.99968 | ppl  20.0791\n",
    "Learning rate: [0.00019837119999999996]\n",
    "19600/99489 batches | batch/sec  1.67 | rem mins   797 | loss 2.98630 | ppl  19.8122\n",
    "Learning rate: [0.00019549119999999996]\n",
    "19700/99489 batches | batch/sec  1.67 | rem mins   797 | loss 3.00657 | ppl  20.2178\n",
    "Learning rate: [0.00019261119999999996]\n",
    "19800/99489 batches | batch/sec  1.67 | rem mins   795 | loss 3.00414 | ppl  20.1689\n",
    "Learning rate: [0.00018973119999999996]\n",
    "19900/99489 batches | batch/sec  1.67 | rem mins   794 | loss 2.99778 | ppl  20.0409\n",
    "Learning rate: [0.00018685119999999994]\n",
    "20000/99489 batches | batch/sec  1.67 | rem mins   794 | loss 2.98631 | ppl  19.8124\n",
    "Learning rate: [0.00018397119999999994]\n",
    "20100/99489 batches | batch/sec  1.67 | rem mins   793 | loss 3.01315 | ppl  20.3514\n",
    "Learning rate: [0.00018109119999999994]\n",
    "20200/99489 batches | batch/sec  1.67 | rem mins   792 | loss 3.00346 | ppl  20.1552\n",
    "Learning rate: [0.00017821119999999994]\n",
    "20300/99489 batches | batch/sec  1.67 | rem mins   791 | loss 3.01431 | ppl  20.3751\n",
    "Learning rate: [0.00017533119999999994]\n",
    "20400/99489 batches | batch/sec  1.67 | rem mins   790 | loss 3.00076 | ppl  20.1008\n",
    "Learning rate: [0.00017245119999999994]\n",
    "20500/99489 batches | batch/sec  1.67 | rem mins   789 | loss 2.99753 | ppl  20.0359\n",
    "Learning rate: [0.00016957119999999994]\n",
    "20600/99489 batches | batch/sec  1.67 | rem mins   789 | loss 2.99904 | ppl  20.0663\n",
    "Learning rate: [0.00016669119999999994]\n",
    "20700/99489 batches | batch/sec  1.67 | rem mins   787 | loss 3.00112 | ppl  20.1080\n",
    "Learning rate: [0.0001638111999999999]\n",
    "20800/99489 batches | batch/sec  1.67 | rem mins   786 | loss 3.01749 | ppl  20.4399\n",
    "Learning rate: [0.00016093119999999994]\n",
    "20900/99489 batches | batch/sec  1.67 | rem mins   785 | loss 3.00238 | ppl  20.1334\n",
    "Learning rate: [0.00015805119999999991]\n",
    "21000/99489 batches | batch/sec  1.67 | rem mins   784 | loss 3.01165 | ppl  20.3209\n",
    "Learning rate: [0.00015517119999999991]\n",
    "21100/99489 batches | batch/sec  1.67 | rem mins   783 | loss 3.00560 | ppl  20.1983\n",
    "Learning rate: [0.00015229119999999992]\n",
    "21200/99489 batches | batch/sec  1.67 | rem mins   781 | loss 2.99883 | ppl  20.0621\n",
    "Learning rate: [0.00014941119999999992]\n",
    "21300/99489 batches | batch/sec  1.67 | rem mins   780 | loss 3.00480 | ppl  20.1821\n",
    "Learning rate: [0.00014653119999999992]\n",
    "21400/99489 batches | batch/sec  1.67 | rem mins   779 | loss 2.99640 | ppl  20.0134\n",
    "Learning rate: [0.00014365119999999992]\n",
    "21500/99489 batches | batch/sec  1.67 | rem mins   777 | loss 3.01341 | ppl  20.3566\n",
    "Learning rate: [0.00014077119999999992]\n",
    "21600/99489 batches | batch/sec  1.67 | rem mins   776 | loss 3.00407 | ppl  20.1675\n",
    "Learning rate: [0.00013789119999999992]\n",
    "21700/99489 batches | batch/sec  1.67 | rem mins   775 | loss 2.99338 | ppl  19.9530\n",
    "Learning rate: [0.00013501119999999992]\n",
    "21800/99489 batches | batch/sec  1.67 | rem mins   775 | loss 2.99956 | ppl  20.0766\n",
    "Learning rate: [0.0001321311999999999]\n",
    "21900/99489 batches | batch/sec  1.67 | rem mins   772 | loss 3.00962 | ppl  20.2798\n",
    "Learning rate: [0.0001292511999999999]\n",
    "22000/99489 batches | batch/sec  1.67 | rem mins   772 | loss 3.00819 | ppl  20.2507\n",
    "Learning rate: [0.0001263711999999999]\n",
    "22100/99489 batches | batch/sec  1.68 | rem mins   770 | loss 3.00286 | ppl  20.1431\n",
    "Learning rate: [0.0001234911999999999]\n",
    "22200/99489 batches | batch/sec  1.68 | rem mins   768 | loss 2.99322 | ppl  19.9499\n",
    "Learning rate: [0.00012061119999999989]\n",
    "22300/99489 batches | batch/sec  1.68 | rem mins   767 | loss 3.01102 | ppl  20.3081\n",
    "Learning rate: [0.0001177311999999999]\n",
    "22400/99489 batches | batch/sec  1.68 | rem mins   766 | loss 3.01533 | ppl  20.3958\n",
    "Learning rate: [0.00011485120000000006]\n",
    "22500/99489 batches | batch/sec  1.68 | rem mins   765 | loss 2.99970 | ppl  20.0794\n",
    "Learning rate: [0.00011197120000000003]\n",
    "22600/99489 batches | batch/sec  1.68 | rem mins   764 | loss 3.00407 | ppl  20.1674\n",
    "Learning rate: [0.00010909120000000003]\n",
    "22700/99489 batches | batch/sec  1.68 | rem mins   763 | loss 2.99802 | ppl  20.0457\n",
    "Learning rate: [0.00010621120000000003]\n",
    "22800/99489 batches | batch/sec  1.68 | rem mins   762 | loss 2.98946 | ppl  19.8749\n",
    "Learning rate: [0.00010333120000000003]\n",
    "22900/99489 batches | batch/sec  1.68 | rem mins   761 | loss 2.98839 | ppl  19.8537\n",
    "Learning rate: [0.00010045120000000003]\n",
    "23000/99489 batches | batch/sec  1.68 | rem mins   760 | loss 3.00709 | ppl  20.2284\n",
    "Learning rate: [9.757120000000003e-05]\n",
    "23100/99489 batches | batch/sec  1.68 | rem mins   759 | loss 3.01880 | ppl  20.4667\n",
    "Learning rate: [9.469120000000003e-05]\n",
    "23200/99489 batches | batch/sec  1.68 | rem mins   758 | loss 2.99033 | ppl  19.8922\n",
    "Learning rate: [9.181120000000003e-05]\n",
    "23300/99489 batches | batch/sec  1.68 | rem mins   757 | loss 2.99670 | ppl  20.0195\n",
    "Learning rate: [8.893120000000002e-05]\n",
    "23400/99489 batches | batch/sec  1.68 | rem mins   756 | loss 2.99313 | ppl  19.9481\n",
    "Learning rate: [8.605120000000002e-05]\n",
    "23500/99489 batches | batch/sec  1.68 | rem mins   755 | loss 2.97948 | ppl  19.6776\n",
    "Learning rate: [8.317120000000001e-05]\n",
    "23600/99489 batches | batch/sec  1.68 | rem mins   754 | loss 2.99944 | ppl  20.0743\n",
    "Learning rate: [8.029120000000001e-05]\n",
    "23700/99489 batches | batch/sec  1.68 | rem mins   754 | loss 2.99656 | ppl  20.0165\n",
    "Learning rate: [7.741120000000001e-05]\n",
    "23800/99489 batches | batch/sec  1.68 | rem mins   752 | loss 3.00522 | ppl  20.1908\n",
    "Learning rate: [7.453120000000001e-05]\n",
    "23900/99489 batches | batch/sec  1.68 | rem mins   750 | loss 3.00363 | ppl  20.1587\n",
    "Learning rate: [7.165120000000001e-05]\n",
    "24000/99489 batches | batch/sec  1.68 | rem mins   750 | loss 3.01209 | ppl  20.3299\n",
    "Learning rate: [6.877120000000001e-05]\n",
    "24100/99489 batches | batch/sec  1.68 | rem mins   749 | loss 2.99595 | ppl  20.0044\n",
    "Learning rate: [6.58912e-05]\n",
    "24200/99489 batches | batch/sec  1.68 | rem mins   748 | loss 2.99344 | ppl  19.9542\n",
    "Learning rate: [6.30112e-05]\n",
    "24300/99489 batches | batch/sec  1.68 | rem mins   747 | loss 3.00987 | ppl  20.2847\n",
    "Learning rate: [6.01312e-05]\n",
    "24400/99489 batches | batch/sec  1.68 | rem mins   746 | loss 3.01977 | ppl  20.4866\n",
    "Learning rate: [5.725119999999999e-05]\n",
    "24500/99489 batches | batch/sec  1.68 | rem mins   745 | loss 2.99504 | ppl  19.9862\n",
    "Learning rate: [5.4371199999999985e-05]\n",
    "24600/99489 batches | batch/sec  1.68 | rem mins   743 | loss 2.99626 | ppl  20.0105\n",
    "Learning rate: [5.1491199999999986e-05]\n",
    "24700/99489 batches | batch/sec  1.68 | rem mins   744 | loss 2.99823 | ppl  20.0501\n",
    "Learning rate: [4.8611199999999986e-05]\n",
    "24800/99489 batches | batch/sec  1.68 | rem mins   742 | loss 3.01117 | ppl  20.3112\n",
    "Learning rate: [4.573119999999998e-05]\n",
    "24900/99489 batches | batch/sec  1.68 | rem mins   741 | loss 3.02134 | ppl  20.5187\n",
    "Learning rate: [4.285119999999998e-05]\n",
    "25000/99489 batches | batch/sec  1.68 | rem mins   741 | loss 2.99734 | ppl  20.0322\n",
    "Learning rate: [4.0028800000000195e-05]\n",
    "25100/99489 batches | batch/sec  1.68 | rem mins   740 | loss 2.99182 | ppl  19.9219\n",
    "Learning rate: [4.2908799999999876e-05]\n",
    "25200/99489 batches | batch/sec  1.68 | rem mins   739 | loss 3.00483 | ppl  20.1827\n",
    "Learning rate: [4.5788800000000194e-05]\n",
    "25300/99489 batches | batch/sec  1.67 | rem mins   738 | loss 2.99914 | ppl  20.0683\n",
    "Learning rate: [4.866879999999988e-05]\n",
    "25400/99489 batches | batch/sec  1.68 | rem mins   737 | loss 2.99849 | ppl  20.0552\n",
    "Learning rate: [5.154880000000021e-05]\n",
    "25500/99489 batches | batch/sec  1.67 | rem mins   737 | loss 3.00279 | ppl  20.1416\n",
    "Learning rate: [5.442879999999989e-05]\n",
    "25600/99489 batches | batch/sec  1.67 | rem mins   736 | loss 3.00862 | ppl  20.2594\n",
    "Learning rate: [5.7308800000000206e-05]\n",
    "25700/99489 batches | batch/sec  1.67 | rem mins   735 | loss 3.00326 | ppl  20.1512\n",
    "Learning rate: [6.0188799999999894e-05]\n",
    "25800/99489 batches | batch/sec  1.67 | rem mins   734 | loss 2.99489 | ppl  19.9831\n",
    "Learning rate: [6.306880000000022e-05]\n",
    "25900/99489 batches | batch/sec  1.67 | rem mins   733 | loss 2.99968 | ppl  20.0792\n",
    "Learning rate: [6.594879999999989e-05]\n",
    "26000/99489 batches | batch/sec  1.67 | rem mins   732 | loss 2.99798 | ppl  20.0451\n",
    "Learning rate: [6.882880000000022e-05]\n",
    "26100/99489 batches | batch/sec  1.67 | rem mins   732 | loss 3.01063 | ppl  20.3002\n",
    "Learning rate: [7.17087999999999e-05]\n",
    "26200/99489 batches | batch/sec  1.67 | rem mins   730 | loss 2.99548 | ppl  19.9950\n",
    "Learning rate: [7.458880000000022e-05]\n",
    "26300/99489 batches | batch/sec  1.67 | rem mins   730 | loss 3.01166 | ppl  20.3211\n",
    "Learning rate: [7.74687999999999e-05]\n",
    "26400/99489 batches | batch/sec  1.67 | rem mins   729 | loss 3.01127 | ppl  20.3131\n",
    "Learning rate: [8.034880000000023e-05]\n",
    "26500/99489 batches | batch/sec  1.67 | rem mins   728 | loss 3.00708 | ppl  20.2283\n",
    "Learning rate: [8.322879999999992e-05]\n",
    "26600/99489 batches | batch/sec  1.67 | rem mins   728 | loss 2.98933 | ppl  19.8723\n",
    "Learning rate: [8.610880000000024e-05]\n",
    "26700/99489 batches | batch/sec  1.67 | rem mins   727 | loss 3.02440 | ppl  20.5817\n",
    "Learning rate: [8.898879999999992e-05]\n",
    "26800/99489 batches | batch/sec  1.67 | rem mins   725 | loss 2.99793 | ppl  20.0441\n",
    "Learning rate: [9.186880000000024e-05]\n",
    "26900/99489 batches | batch/sec  1.67 | rem mins   725 | loss 3.01121 | ppl  20.3120\n",
    "Learning rate: [9.474879999999992e-05]\n",
    "27000/99489 batches | batch/sec  1.67 | rem mins   725 | loss 3.00122 | ppl  20.1100\n",
    "Learning rate: [9.762879999999993e-05]\n",
    "27100/99489 batches | batch/sec  1.67 | rem mins   723 | loss 2.99634 | ppl  20.0121\n",
    "Learning rate: [0.00010050879999999993]\n",
    "27200/99489 batches | batch/sec  1.67 | rem mins   723 | loss 3.01558 | ppl  20.4010\n",
    "Learning rate: [0.00010338879999999994]\n",
    "27300/99489 batches | batch/sec  1.67 | rem mins   722 | loss 2.99766 | ppl  20.0387\n",
    "Learning rate: [0.00010626879999999994]\n",
    "27400/99489 batches | batch/sec  1.67 | rem mins   720 | loss 3.02564 | ppl  20.6071\n",
    "Learning rate: [0.00010914879999999994]\n",
    "27500/99489 batches | batch/sec  1.67 | rem mins   720 | loss 3.02039 | ppl  20.4992\n",
    "Learning rate: [0.00011202879999999994]\n",
    "27600/99489 batches | batch/sec  1.67 | rem mins   719 | loss 3.00218 | ppl  20.1294\n",
    "Learning rate: [0.00011490879999999994]\n",
    "27700/99489 batches | batch/sec  1.67 | rem mins   717 | loss 3.01510 | ppl  20.3911\n",
    "Learning rate: [0.00011778879999999994]\n",
    "27800/99489 batches | batch/sec  1.67 | rem mins   716 | loss 2.99808 | ppl  20.0471\n",
    "Learning rate: [0.00012066879999999994]\n",
    "27900/99489 batches | batch/sec  1.67 | rem mins   716 | loss 3.02994 | ppl  20.6959\n",
    "Learning rate: [0.00012354879999999996]\n",
    "28000/99489 batches | batch/sec  1.67 | rem mins   715 | loss 2.99974 | ppl  20.0803\n",
    "Learning rate: [0.00012642879999999996]\n",
    "28100/99489 batches | batch/sec  1.67 | rem mins   713 | loss 2.99911 | ppl  20.0676\n",
    "Learning rate: [0.00012930879999999996]\n",
    "28200/99489 batches | batch/sec  1.67 | rem mins   712 | loss 3.00817 | ppl  20.2503\n",
    "Learning rate: [0.00013218879999999996]\n",
    "28300/99489 batches | batch/sec  1.67 | rem mins   710 | loss 2.97923 | ppl  19.6727\n",
    "Learning rate: [0.00013506879999999996]\n",
    "28400/99489 batches | batch/sec  1.67 | rem mins   709 | loss 2.99272 | ppl  19.9398\n",
    "Learning rate: [0.00013794879999999996]\n",
    "28500/99489 batches | batch/sec  1.67 | rem mins   709 | loss 2.98510 | ppl  19.7885\n",
    "Learning rate: [0.00014082879999999996]\n",
    "28600/99489 batches | batch/sec  1.67 | rem mins   707 | loss 3.00639 | ppl  20.2143\n",
    "Learning rate: [0.00014370879999999996]\n",
    "28700/99489 batches | batch/sec  1.67 | rem mins   706 | loss 2.98676 | ppl  19.8213\n",
    "Learning rate: [0.00014658879999999996]\n",
    "28800/99489 batches | batch/sec  1.67 | rem mins   704 | loss 2.98328 | ppl  19.7524\n",
    "Learning rate: [0.0001494688]\n",
    "28900/99489 batches | batch/sec  1.67 | rem mins   703 | loss 2.98694 | ppl  19.8249\n",
    "Learning rate: [0.0001523488]\n",
    "29000/99489 batches | batch/sec  1.67 | rem mins   702 | loss 3.01412 | ppl  20.3712\n",
    "Learning rate: [0.0001552288]\n",
    "29100/99489 batches | batch/sec  1.67 | rem mins   701 | loss 2.98592 | ppl  19.8048\n",
    "Learning rate: [0.00015810879999999999]\n",
    "29200/99489 batches | batch/sec  1.67 | rem mins   700 | loss 3.00339 | ppl  20.1537\n",
    "Learning rate: [0.00016098879999999999]\n",
    "29300/99489 batches | batch/sec  1.67 | rem mins   699 | loss 3.00225 | ppl  20.1308\n",
    "Learning rate: [0.00016386879999999999]\n",
    "29400/99489 batches | batch/sec  1.67 | rem mins   698 | loss 3.00843 | ppl  20.2556\n",
    "Learning rate: [0.00016674879999999998]\n",
    "29500/99489 batches | batch/sec  1.67 | rem mins   696 | loss 3.00535 | ppl  20.1932\n",
    "Learning rate: [0.00016962879999999998]\n",
    "29600/99489 batches | batch/sec  1.68 | rem mins   695 | loss 3.00907 | ppl  20.2685\n",
    "Learning rate: [0.00017250879999999998]\n",
    "29700/99489 batches | batch/sec  1.67 | rem mins   694 | loss 3.01846 | ppl  20.4597\n",
    "Learning rate: [0.00017538879999999998]\n",
    "29800/99489 batches | batch/sec  1.67 | rem mins   694 | loss 3.02782 | ppl  20.6522\n",
    "Learning rate: [0.0001782688]\n",
    "29900/99489 batches | batch/sec  1.67 | rem mins   693 | loss 2.99067 | ppl  19.8989\n",
    "Learning rate: [0.0001811488]\n",
    "30000/99489 batches | batch/sec  1.67 | rem mins   692 | loss 3.02044 | ppl  20.5003\n",
    "Learning rate: [0.0001840288]\n",
    "30100/99489 batches | batch/sec  1.67 | rem mins   692 | loss 3.01446 | ppl  20.3781\n",
    "Learning rate: [0.0001869088]\n",
    "30200/99489 batches | batch/sec  1.67 | rem mins   690 | loss 2.99230 | ppl  19.9315\n",
    "Learning rate: [0.0001897888]\n",
    "30300/99489 batches | batch/sec  1.67 | rem mins   689 | loss 2.99336 | ppl  19.9527\n",
    "Learning rate: [0.0001926688]\n",
    "30400/99489 batches | batch/sec  1.67 | rem mins   689 | loss 3.00173 | ppl  20.1204\n",
    "Learning rate: [0.0001955488]\n",
    "30500/99489 batches | batch/sec  1.67 | rem mins   687 | loss 3.00403 | ppl  20.1666\n",
    "Learning rate: [0.0001984288]\n",
    "30600/99489 batches | batch/sec  1.67 | rem mins   686 | loss 3.01305 | ppl  20.3494\n",
    "Learning rate: [0.0002013088]\n",
    "30700/99489 batches | batch/sec  1.68 | rem mins   684 | loss 3.00005 | ppl  20.0866\n",
    "Learning rate: [0.00020418880000000003]\n",
    "30800/99489 batches | batch/sec  1.68 | rem mins   683 | loss 2.98225 | ppl  19.7321\n",
    "Learning rate: [0.00020706880000000003]\n",
    "30900/99489 batches | batch/sec  1.68 | rem mins   682 | loss 2.99840 | ppl  20.0535\n",
    "Learning rate: [0.00020994880000000003]\n",
    "31000/99489 batches | batch/sec  1.68 | rem mins   681 | loss 2.99225 | ppl  19.9304\n",
    "Learning rate: [0.00021282880000000003]\n",
    "31100/99489 batches | batch/sec  1.68 | rem mins   680 | loss 3.00525 | ppl  20.1912\n",
    "Learning rate: [0.00021570880000000003]\n",
    "31200/99489 batches | batch/sec  1.68 | rem mins   679 | loss 3.01668 | ppl  20.4233\n",
    "Learning rate: [0.00021858880000000003]\n",
    "31300/99489 batches | batch/sec  1.68 | rem mins   678 | loss 2.99582 | ppl  20.0019\n",
    "Learning rate: [0.00022146880000000003]\n",
    "31400/99489 batches | batch/sec  1.68 | rem mins   677 | loss 2.99068 | ppl  19.8993\n",
    "Learning rate: [0.00022434880000000003]\n",
    "31500/99489 batches | batch/sec  1.68 | rem mins   676 | loss 2.99647 | ppl  20.0148\n",
    "Learning rate: [0.00022722880000000006]\n",
    "31600/99489 batches | batch/sec  1.67 | rem mins   676 | loss 3.00720 | ppl  20.2307\n",
    "Learning rate: [0.00023010880000000006]\n",
    "31700/99489 batches | batch/sec  1.68 | rem mins   674 | loss 2.99479 | ppl  19.9812\n",
    "Learning rate: [0.00023298880000000006]\n",
    "31800/99489 batches | batch/sec  1.68 | rem mins   673 | loss 3.00829 | ppl  20.2527\n",
    "Learning rate: [0.00023586880000000005]\n",
    "31900/99489 batches | batch/sec  1.68 | rem mins   672 | loss 2.99187 | ppl  19.9230\n",
    "Learning rate: [0.00023874880000000005]\n",
    "32000/99489 batches | batch/sec  1.68 | rem mins   671 | loss 2.99863 | ppl  20.0580\n",
    "Learning rate: [0.00024162880000000005]\n",
    "32100/99489 batches | batch/sec  1.68 | rem mins   670 | loss 3.00124 | ppl  20.1105\n",
    "Learning rate: [0.00024450880000000005]\n",
    "32200/99489 batches | batch/sec  1.68 | rem mins   669 | loss 3.01374 | ppl  20.3635\n",
    "Learning rate: [0.0002473888000000001]\n",
    "32300/99489 batches | batch/sec  1.67 | rem mins   669 | loss 3.01195 | ppl  20.3269\n",
    "Learning rate: [0.00025026880000000005]\n",
    "32400/99489 batches | batch/sec  1.68 | rem mins   667 | loss 3.01647 | ppl  20.4191\n",
    "Learning rate: [0.0002531488000000001]\n",
    "32500/99489 batches | batch/sec  1.68 | rem mins   666 | loss 3.00425 | ppl  20.1710\n",
    "Learning rate: [0.0002560288000000001]\n",
    "32600/99489 batches | batch/sec  1.68 | rem mins   665 | loss 3.00382 | ppl  20.1624\n",
    "Learning rate: [0.0002589088000000001]\n",
    "32700/99489 batches | batch/sec  1.68 | rem mins   664 | loss 3.00692 | ppl  20.2251\n",
    "Learning rate: [0.0002617888000000001]\n",
    "32800/99489 batches | batch/sec  1.68 | rem mins   663 | loss 3.00790 | ppl  20.2449\n",
    "Learning rate: [0.0002646688000000001]\n",
    "32900/99489 batches | batch/sec  1.67 | rem mins   663 | loss 3.01220 | ppl  20.3320\n",
    "Learning rate: [0.0002675488000000001]\n",
    "33000/99489 batches | batch/sec  1.68 | rem mins   661 | loss 3.01281 | ppl  20.3446\n",
    "Learning rate: [0.0002704288000000001]\n",
    "33100/99489 batches | batch/sec  1.68 | rem mins   660 | loss 3.00432 | ppl  20.1726\n",
    "Learning rate: [0.0002733088000000001]\n",
    "33200/99489 batches | batch/sec  1.67 | rem mins   660 | loss 2.99111 | ppl  19.9077\n",
    "Learning rate: [0.00027618880000000013]\n",
    "33300/99489 batches | batch/sec  1.68 | rem mins   658 | loss 3.01064 | ppl  20.3004\n",
    "Learning rate: [0.0002790688000000001]\n",
    "33400/99489 batches | batch/sec  1.68 | rem mins   657 | loss 3.01399 | ppl  20.3685\n",
    "Learning rate: [0.0002819487999999998]\n",
    "33500/99489 batches | batch/sec  1.68 | rem mins   656 | loss 3.00042 | ppl  20.0939\n",
    "Learning rate: [0.0002848288000000001]\n",
    "33600/99489 batches | batch/sec  1.68 | rem mins   655 | loss 3.02769 | ppl  20.6495\n",
    "Learning rate: [0.0002877087999999998]\n",
    "33700/99489 batches | batch/sec  1.68 | rem mins   654 | loss 2.97167 | ppl  19.5245\n",
    "Learning rate: [0.0002905888000000001]\n",
    "33800/99489 batches | batch/sec  1.68 | rem mins   653 | loss 2.99575 | ppl  20.0004\n",
    "Learning rate: [0.0002934687999999998]\n",
    "33900/99489 batches | batch/sec  1.68 | rem mins   652 | loss 2.98987 | ppl  19.8831\n",
    "Learning rate: [0.0002963488000000001]\n",
    "34000/99489 batches | batch/sec  1.68 | rem mins   651 | loss 2.99739 | ppl  20.0333\n",
    "Learning rate: [0.0002992287999999998]\n",
    "34100/99489 batches | batch/sec  1.68 | rem mins   650 | loss 3.00851 | ppl  20.2572\n",
    "Learning rate: [0.0003021088000000001]\n",
    "34200/99489 batches | batch/sec  1.67 | rem mins   650 | loss 3.00851 | ppl  20.2573\n",
    "Learning rate: [0.0003049887999999998]\n",
    "34300/99489 batches | batch/sec  1.67 | rem mins   649 | loss 3.00349 | ppl  20.1558\n",
    "Learning rate: [0.0003078688000000001]\n",
    "34400/99489 batches | batch/sec  1.68 | rem mins   648 | loss 3.00334 | ppl  20.1528\n",
    "Learning rate: [0.0003107487999999998]\n",
    "34500/99489 batches | batch/sec  1.67 | rem mins   647 | loss 3.02160 | ppl  20.5241\n",
    "Learning rate: [0.00031362880000000015]\n",
    "34600/99489 batches | batch/sec  1.68 | rem mins   646 | loss 2.99677 | ppl  20.0207\n",
    "Learning rate: [0.0003165087999999998]\n",
    "34700/99489 batches | batch/sec  1.67 | rem mins   645 | loss 2.99685 | ppl  20.0224\n",
    "Learning rate: [0.00031938880000000015]\n",
    "34800/99489 batches | batch/sec  1.67 | rem mins   644 | loss 2.99833 | ppl  20.0520\n",
    "Learning rate: [0.0003222687999999998]\n",
    "34900/99489 batches | batch/sec  1.67 | rem mins   643 | loss 2.98146 | ppl  19.7167\n",
    "Learning rate: [0.00032514880000000015]\n",
    "35000/99489 batches | batch/sec  1.67 | rem mins   642 | loss 3.00147 | ppl  20.1151\n",
    "Learning rate: [0.0003280287999999998]\n",
    "35100/99489 batches | batch/sec  1.67 | rem mins   641 | loss 3.01671 | ppl  20.4241\n",
    "Learning rate: [0.00033090880000000015]\n",
    "35200/99489 batches | batch/sec  1.67 | rem mins   640 | loss 3.02141 | ppl  20.5201\n",
    "Learning rate: [0.00033378879999999985]\n",
    "35300/99489 batches | batch/sec  1.67 | rem mins   639 | loss 3.01815 | ppl  20.4534\n",
    "Learning rate: [0.00033666880000000015]\n",
    "35400/99489 batches | batch/sec  1.67 | rem mins   638 | loss 3.01121 | ppl  20.3120\n",
    "Learning rate: [0.00033954879999999985]\n",
    "35500/99489 batches | batch/sec  1.67 | rem mins   637 | loss 3.00146 | ppl  20.1148\n",
    "Learning rate: [0.00034242880000000015]\n",
    "35600/99489 batches | batch/sec  1.67 | rem mins   636 | loss 3.01323 | ppl  20.3530\n",
    "Learning rate: [0.00034530879999999985]\n",
    "35700/99489 batches | batch/sec  1.67 | rem mins   635 | loss 2.99524 | ppl  19.9902\n",
    "Learning rate: [0.00034818880000000014]\n",
    "35800/99489 batches | batch/sec  1.67 | rem mins   634 | loss 3.00303 | ppl  20.1464\n",
    "Learning rate: [0.00035106879999999985]\n",
    "35900/99489 batches | batch/sec  1.67 | rem mins   633 | loss 3.01000 | ppl  20.2875\n",
    "Learning rate: [0.00035394880000000014]\n",
    "36000/99489 batches | batch/sec  1.67 | rem mins   632 | loss 3.00417 | ppl  20.1694\n",
    "Learning rate: [0.00035682879999999985]\n",
    "36100/99489 batches | batch/sec  1.67 | rem mins   631 | loss 2.98463 | ppl  19.7791\n",
    "Learning rate: [0.00035970880000000014]\n",
    "36200/99489 batches | batch/sec  1.67 | rem mins   630 | loss 3.01208 | ppl  20.3297\n",
    "Learning rate: [0.00036258879999999984]\n",
    "36300/99489 batches | batch/sec  1.67 | rem mins   629 | loss 2.99278 | ppl  19.9410\n",
    "Learning rate: [0.0003654688000000002]\n",
    "36400/99489 batches | batch/sec  1.67 | rem mins   629 | loss 3.00426 | ppl  20.1712\n",
    "Learning rate: [0.00036834879999999984]\n",
    "36500/99489 batches | batch/sec  1.67 | rem mins   627 | loss 3.00324 | ppl  20.1508\n",
    "Learning rate: [0.0003712288000000002]\n",
    "36600/99489 batches | batch/sec  1.67 | rem mins   626 | loss 2.98820 | ppl  19.8499\n",
    "Learning rate: [0.00037410879999999984]\n",
    "36700/99489 batches | batch/sec  1.67 | rem mins   625 | loss 3.00771 | ppl  20.2411\n",
    "Learning rate: [0.0003769888000000002]\n",
    "36800/99489 batches | batch/sec  1.67 | rem mins   624 | loss 3.00171 | ppl  20.1198\n",
    "Learning rate: [0.0003798687999999999]\n",
    "36900/99489 batches | batch/sec  1.67 | rem mins   623 | loss 3.02352 | ppl  20.5636\n",
    "Learning rate: [0.0003827488000000002]\n",
    "37000/99489 batches | batch/sec  1.67 | rem mins   623 | loss 3.00425 | ppl  20.1710\n",
    "Learning rate: [0.0003856287999999999]\n",
    "37100/99489 batches | batch/sec  1.67 | rem mins   621 | loss 2.99964 | ppl  20.0783\n",
    "Learning rate: [0.0003885088000000002]\n",
    "37200/99489 batches | batch/sec  1.67 | rem mins   620 | loss 2.99455 | ppl  19.9763\n",
    "Learning rate: [0.0003913887999999999]\n",
    "37300/99489 batches | batch/sec  1.67 | rem mins   619 | loss 2.99723 | ppl  20.0300\n",
    "Learning rate: [0.0003942688000000002]\n",
    "37400/99489 batches | batch/sec  1.67 | rem mins   618 | loss 2.99016 | ppl  19.8889\n",
    "Learning rate: [0.0003971487999999999]\n",
    "37500/99489 batches | batch/sec  1.67 | rem mins   617 | loss 3.01110 | ppl  20.3096\n",
    "Learning rate: [0.00039997119999999985]\n",
    "37600/99489 batches | batch/sec  1.68 | rem mins   616 | loss 3.00177 | ppl  20.1211\n",
    "Learning rate: [0.00039709120000000015]\n",
    "37700/99489 batches | batch/sec  1.67 | rem mins   615 | loss 2.99427 | ppl  19.9707\n",
    "Learning rate: [0.00039421119999999985]\n",
    "37800/99489 batches | batch/sec  1.67 | rem mins   614 | loss 2.99758 | ppl  20.0370\n",
    "Learning rate: [0.00039133120000000015]\n",
    "37900/99489 batches | batch/sec  1.67 | rem mins   613 | loss 3.00634 | ppl  20.2133\n",
    "Learning rate: [0.0003884511999999998]\n",
    "38000/99489 batches | batch/sec  1.67 | rem mins   613 | loss 3.00813 | ppl  20.2495\n",
    "Learning rate: [0.00038557120000000015]\n",
    "38100/99489 batches | batch/sec  1.67 | rem mins   611 | loss 3.00297 | ppl  20.1453\n",
    "Learning rate: [0.0003826911999999998]\n",
    "38200/99489 batches | batch/sec  1.67 | rem mins   611 | loss 3.00473 | ppl  20.1807\n",
    "Learning rate: [0.00037981120000000015]\n",
    "38300/99489 batches | batch/sec  1.67 | rem mins   609 | loss 3.00474 | ppl  20.1811\n",
    "Learning rate: [0.0003769311999999998]\n",
    "38400/99489 batches | batch/sec  1.67 | rem mins   608 | loss 2.99676 | ppl  20.0206\n",
    "Learning rate: [0.00037405120000000015]\n",
    "38500/99489 batches | batch/sec  1.67 | rem mins   607 | loss 3.00408 | ppl  20.1677\n",
    "Learning rate: [0.0003711711999999998]\n",
    "38600/99489 batches | batch/sec  1.67 | rem mins   606 | loss 3.02143 | ppl  20.5206\n",
    "Learning rate: [0.0003682912000000001]\n",
    "38700/99489 batches | batch/sec  1.67 | rem mins   606 | loss 2.99425 | ppl  19.9704\n",
    "Learning rate: [0.0003654111999999998]\n",
    "38800/99489 batches | batch/sec  1.67 | rem mins   604 | loss 3.00683 | ppl  20.2232\n",
    "Learning rate: [0.0003625312000000001]\n",
    "38900/99489 batches | batch/sec  1.67 | rem mins   604 | loss 3.00694 | ppl  20.2254\n",
    "Learning rate: [0.0003596511999999998]\n",
    "39000/99489 batches | batch/sec  1.67 | rem mins   602 | loss 3.02083 | ppl  20.5084\n",
    "Learning rate: [0.0003567712000000001]\n",
    "39100/99489 batches | batch/sec  1.67 | rem mins   601 | loss 3.01219 | ppl  20.3319\n",
    "Learning rate: [0.0003538911999999998]\n",
    "39200/99489 batches | batch/sec  1.67 | rem mins   600 | loss 3.00208 | ppl  20.1273\n",
    "Learning rate: [0.0003510112000000001]\n",
    "39300/99489 batches | batch/sec  1.67 | rem mins   599 | loss 3.01087 | ppl  20.3050\n",
    "Learning rate: [0.0003481311999999998]\n",
    "39400/99489 batches | batch/sec  1.67 | rem mins   598 | loss 2.99192 | ppl  19.9238\n",
    "Learning rate: [0.0003452512000000001]\n",
    "39500/99489 batches | batch/sec  1.67 | rem mins   597 | loss 3.01226 | ppl  20.3333\n",
    "Learning rate: [0.0003423712000000001]\n",
    "39600/99489 batches | batch/sec  1.67 | rem mins   596 | loss 2.99622 | ppl  20.0098\n",
    "Learning rate: [0.0003394912000000001]\n",
    "39700/99489 batches | batch/sec  1.67 | rem mins   596 | loss 3.01225 | ppl  20.3332\n",
    "Learning rate: [0.0003366112000000001]\n",
    "39800/99489 batches | batch/sec  1.67 | rem mins   594 | loss 2.99780 | ppl  20.0413\n",
    "Learning rate: [0.0003337312000000001]\n",
    "39900/99489 batches | batch/sec  1.67 | rem mins   594 | loss 3.00226 | ppl  20.1310\n",
    "Learning rate: [0.0003308512000000001]\n",
    "40000/99489 batches | batch/sec  1.67 | rem mins   592 | loss 2.99222 | ppl  19.9298\n",
    "Learning rate: [0.0003279712000000001]\n",
    "40100/99489 batches | batch/sec  1.67 | rem mins   591 | loss 3.00486 | ppl  20.1834\n",
    "Learning rate: [0.0003250912000000001]\n",
    "40200/99489 batches | batch/sec  1.67 | rem mins   590 | loss 3.00035 | ppl  20.0926\n",
    "Learning rate: [0.00032221120000000005]\n",
    "40300/99489 batches | batch/sec  1.67 | rem mins   589 | loss 3.00988 | ppl  20.2849\n",
    "Learning rate: [0.0003193312000000001]\n",
    "40400/99489 batches | batch/sec  1.67 | rem mins   588 | loss 2.99946 | ppl  20.0748\n",
    "Learning rate: [0.00031645120000000005]\n",
    "40500/99489 batches | batch/sec  1.67 | rem mins   587 | loss 3.00245 | ppl  20.1348\n",
    "Learning rate: [0.0003135712000000001]\n",
    "40600/99489 batches | batch/sec  1.68 | rem mins   586 | loss 3.01027 | ppl  20.2929\n",
    "Learning rate: [0.00031069120000000005]\n",
    "40700/99489 batches | batch/sec  1.67 | rem mins   585 | loss 3.00250 | ppl  20.1358\n",
    "Learning rate: [0.0003078112000000001]\n",
    "40800/99489 batches | batch/sec  1.67 | rem mins   585 | loss 3.00175 | ppl  20.1207\n",
    "Learning rate: [0.00030493120000000005]\n",
    "40900/99489 batches | batch/sec  1.67 | rem mins   583 | loss 3.01936 | ppl  20.4781\n",
    "Learning rate: [0.0003020512000000001]\n",
    "41000/99489 batches | batch/sec  1.67 | rem mins   582 | loss 3.00461 | ppl  20.1783\n",
    "Learning rate: [0.00029917120000000005]\n",
    "41100/99489 batches | batch/sec  1.67 | rem mins   581 | loss 3.00943 | ppl  20.2757\n",
    "Learning rate: [0.00029629120000000003]\n",
    "41200/99489 batches | batch/sec  1.67 | rem mins   580 | loss 3.02570 | ppl  20.6084\n",
    "Learning rate: [0.00029341120000000005]\n",
    "41300/99489 batches | batch/sec  1.67 | rem mins   579 | loss 3.00547 | ppl  20.1957\n",
    "Learning rate: [0.00029053120000000003]\n",
    "41400/99489 batches | batch/sec  1.67 | rem mins   579 | loss 2.98896 | ppl  19.8650\n",
    "Learning rate: [0.00028765120000000006]\n",
    "41500/99489 batches | batch/sec  1.67 | rem mins   577 | loss 3.00012 | ppl  20.0879\n",
    "Learning rate: [0.00028477120000000003]\n",
    "41600/99489 batches | batch/sec  1.67 | rem mins   577 | loss 3.00662 | ppl  20.2190\n",
    "Learning rate: [0.00028189120000000006]\n",
    "41700/99489 batches | batch/sec  1.67 | rem mins   576 | loss 2.99154 | ppl  19.9164\n",
    "Learning rate: [0.00027901120000000003]\n",
    "41800/99489 batches | batch/sec  1.67 | rem mins   575 | loss 3.00563 | ppl  20.1990\n",
    "Learning rate: [0.00027613120000000006]\n",
    "41900/99489 batches | batch/sec  1.67 | rem mins   574 | loss 3.00711 | ppl  20.2288\n",
    "Learning rate: [0.00027325120000000003]\n",
    "42000/99489 batches | batch/sec  1.67 | rem mins   573 | loss 3.00717 | ppl  20.2301\n",
    "Learning rate: [0.00027037120000000006]\n",
    "42100/99489 batches | batch/sec  1.67 | rem mins   572 | loss 3.00371 | ppl  20.1603\n",
    "Learning rate: [0.00026749120000000003]\n",
    "42200/99489 batches | batch/sec  1.67 | rem mins   571 | loss 2.99716 | ppl  20.0286\n",
    "Learning rate: [0.00026461120000000006]\n",
    "42300/99489 batches | batch/sec  1.67 | rem mins   570 | loss 3.00364 | ppl  20.1587\n",
    "Learning rate: [0.00026173120000000003]\n",
    "42400/99489 batches | batch/sec  1.67 | rem mins   569 | loss 3.01454 | ppl  20.3797\n",
    "Learning rate: [0.0002588512]\n",
    "42500/99489 batches | batch/sec  1.67 | rem mins   568 | loss 3.00740 | ppl  20.2348\n",
    "Learning rate: [0.00025597120000000003]\n",
    "42600/99489 batches | batch/sec  1.67 | rem mins   567 | loss 2.99997 | ppl  20.0849\n",
    "Learning rate: [0.0002530912]\n",
    "42700/99489 batches | batch/sec  1.67 | rem mins   567 | loss 2.98507 | ppl  19.7879\n",
    "Learning rate: [0.00025021120000000003]\n",
    "42800/99489 batches | batch/sec  1.67 | rem mins   565 | loss 3.01259 | ppl  20.3400\n",
    "Learning rate: [0.0002473312]\n",
    "42900/99489 batches | batch/sec  1.67 | rem mins   564 | loss 3.00287 | ppl  20.1432\n",
    "Learning rate: [0.00024445120000000004]\n",
    "43000/99489 batches | batch/sec  1.67 | rem mins   563 | loss 3.00872 | ppl  20.2614\n",
    "Learning rate: [0.0002415712]\n",
    "43100/99489 batches | batch/sec  1.67 | rem mins   563 | loss 3.01705 | ppl  20.4310\n",
    "Learning rate: [0.0002386912]\n",
    "43200/99489 batches | batch/sec  1.67 | rem mins   561 | loss 2.99901 | ppl  20.0657\n",
    "Learning rate: [0.00023581119999999998]\n",
    "43300/99489 batches | batch/sec  1.67 | rem mins   560 | loss 3.02478 | ppl  20.5894\n",
    "Learning rate: [0.00023293119999999998]\n",
    "43400/99489 batches | batch/sec  1.67 | rem mins   559 | loss 3.00521 | ppl  20.1905\n",
    "Learning rate: [0.00023005119999999998]\n",
    "43500/99489 batches | batch/sec  1.67 | rem mins   558 | loss 3.02299 | ppl  20.5526\n",
    "Learning rate: [0.00022717119999999998]\n",
    "43600/99489 batches | batch/sec  1.67 | rem mins   558 | loss 2.99202 | ppl  19.9259\n",
    "Learning rate: [0.00022429119999999998]\n",
    "43700/99489 batches | batch/sec  1.67 | rem mins   557 | loss 2.99846 | ppl  20.0546\n",
    "Learning rate: [0.00022141119999999999]\n",
    "43800/99489 batches | batch/sec  1.67 | rem mins   555 | loss 3.00221 | ppl  20.1300\n",
    "Learning rate: [0.00021853119999999999]\n",
    "43900/99489 batches | batch/sec  1.67 | rem mins   554 | loss 3.00271 | ppl  20.1400\n",
    "Learning rate: [0.00021565119999999999]\n",
    "44000/99489 batches | batch/sec  1.67 | rem mins   554 | loss 3.00424 | ppl  20.1709\n",
    "Learning rate: [0.00021277119999999996]\n",
    "44100/99489 batches | batch/sec  1.67 | rem mins   552 | loss 3.01786 | ppl  20.4474\n",
    "Learning rate: [0.00020989119999999996]\n",
    "44200/99489 batches | batch/sec  1.67 | rem mins   551 | loss 2.99714 | ppl  20.0282\n",
    "Learning rate: [0.00020701119999999996]\n",
    "44300/99489 batches | batch/sec  1.67 | rem mins   550 | loss 3.01904 | ppl  20.4715\n",
    "Learning rate: [0.00020413119999999996]\n",
    "44400/99489 batches | batch/sec  1.67 | rem mins   549 | loss 2.99413 | ppl  19.9679\n",
    "Learning rate: [0.00020125119999999996]\n",
    "44500/99489 batches | batch/sec  1.67 | rem mins   549 | loss 3.00500 | ppl  20.1862\n",
    "Learning rate: [0.00019837119999999996]\n",
    "44600/99489 batches | batch/sec  1.67 | rem mins   548 | loss 3.00521 | ppl  20.1904\n",
    "Learning rate: [0.00019549119999999996]\n",
    "44700/99489 batches | batch/sec  1.67 | rem mins   546 | loss 2.99797 | ppl  20.0448\n",
    "Learning rate: [0.00019261119999999996]\n",
    "44800/99489 batches | batch/sec  1.67 | rem mins   545 | loss 3.01523 | ppl  20.3938\n",
    "Learning rate: [0.00018973119999999996]\n",
    "44900/99489 batches | batch/sec  1.67 | rem mins   544 | loss 3.01560 | ppl  20.4013\n",
    "Learning rate: [0.00018685119999999994]\n",
    "45000/99489 batches | batch/sec  1.67 | rem mins   543 | loss 3.01410 | ppl  20.3707\n",
    "Learning rate: [0.00018397119999999994]\n",
    "45100/99489 batches | batch/sec  1.67 | rem mins   542 | loss 2.99734 | ppl  20.0322\n",
    "Learning rate: [0.00018109119999999994]\n",
    "45200/99489 batches | batch/sec  1.67 | rem mins   542 | loss 2.99227 | ppl  19.9309\n",
    "Learning rate: [0.00017821119999999994]\n",
    "45300/99489 batches | batch/sec  1.67 | rem mins   540 | loss 3.00946 | ppl  20.2764\n",
    "Learning rate: [0.00017533119999999994]\n",
    "45400/99489 batches | batch/sec  1.67 | rem mins   540 | loss 2.99757 | ppl  20.0369\n",
    "Learning rate: [0.00017245119999999994]\n",
    "45500/99489 batches | batch/sec  1.67 | rem mins   539 | loss 3.00827 | ppl  20.2523\n",
    "Learning rate: [0.00016957119999999994]\n",
    "45600/99489 batches | batch/sec  1.67 | rem mins   538 | loss 3.01992 | ppl  20.4896\n",
    "Learning rate: [0.00016669119999999994]\n",
    "45700/99489 batches | batch/sec  1.67 | rem mins   536 | loss 3.00105 | ppl  20.1067\n",
    "Learning rate: [0.0001638111999999999]\n",
    "45800/99489 batches | batch/sec  1.67 | rem mins   535 | loss 3.03499 | ppl  20.8008\n",
    "Learning rate: [0.00016093119999999994]\n",
    "45900/99489 batches | batch/sec  1.67 | rem mins   535 | loss 3.01315 | ppl  20.3515\n",
    "Learning rate: [0.00015805120000000024]\n",
    "46000/99489 batches | batch/sec  1.67 | rem mins   533 | loss 3.01341 | ppl  20.3566\n",
    "Learning rate: [0.00015517119999999991]\n",
    "46100/99489 batches | batch/sec  1.67 | rem mins   533 | loss 3.00432 | ppl  20.1726\n",
    "Learning rate: [0.00015229120000000024]\n",
    "46200/99489 batches | batch/sec  1.67 | rem mins   531 | loss 2.99762 | ppl  20.0377\n",
    "Learning rate: [0.00014941119999999992]\n",
    "46300/99489 batches | batch/sec  1.67 | rem mins   531 | loss 3.01105 | ppl  20.3087\n",
    "Learning rate: [0.00014653120000000024]\n",
    "46400/99489 batches | batch/sec  1.67 | rem mins   529 | loss 3.00122 | ppl  20.1101\n",
    "Learning rate: [0.00014365119999999992]\n",
    "46500/99489 batches | batch/sec  1.67 | rem mins   529 | loss 3.00132 | ppl  20.1121\n",
    "Learning rate: [0.00014077120000000024]\n",
    "46600/99489 batches | batch/sec  1.67 | rem mins   527 | loss 2.99682 | ppl  20.0218\n",
    "Learning rate: [0.00013789119999999992]\n",
    "46700/99489 batches | batch/sec  1.67 | rem mins   526 | loss 3.00485 | ppl  20.1832\n",
    "Learning rate: [0.00013501120000000022]\n",
    "46800/99489 batches | batch/sec  1.67 | rem mins   525 | loss 3.00151 | ppl  20.1158\n",
    "Learning rate: [0.0001321311999999999]\n",
    "46900/99489 batches | batch/sec  1.67 | rem mins   524 | loss 2.99778 | ppl  20.0411\n",
    "Learning rate: [0.00012925120000000022]\n",
    "47000/99489 batches | batch/sec  1.67 | rem mins   524 | loss 3.00742 | ppl  20.2352\n",
    "Learning rate: [0.0001263711999999999]\n",
    "47100/99489 batches | batch/sec  1.67 | rem mins   522 | loss 3.00531 | ppl  20.1924\n",
    "Learning rate: [0.00012349120000000022]\n",
    "47200/99489 batches | batch/sec  1.67 | rem mins   521 | loss 3.00855 | ppl  20.2580\n",
    "Learning rate: [0.00012061119999999989]\n",
    "47300/99489 batches | batch/sec  1.67 | rem mins   520 | loss 2.99250 | ppl  19.9355\n",
    "Learning rate: [0.00011773120000000022]\n",
    "47400/99489 batches | batch/sec  1.67 | rem mins   519 | loss 3.01933 | ppl  20.4777\n",
    "Learning rate: [0.0001148511999999999]\n",
    "47500/99489 batches | batch/sec  1.67 | rem mins   519 | loss 3.01195 | ppl  20.3271\n",
    "Learning rate: [0.00011197120000000019]\n",
    "47600/99489 batches | batch/sec  1.67 | rem mins   518 | loss 2.98684 | ppl  19.8229\n",
    "Learning rate: [0.00010909119999999987]\n",
    "47700/99489 batches | batch/sec  1.67 | rem mins   516 | loss 3.01025 | ppl  20.2925\n",
    "Learning rate: [0.0001062112000000002]\n",
    "47800/99489 batches | batch/sec  1.67 | rem mins   516 | loss 3.00136 | ppl  20.1128\n",
    "Learning rate: [0.00010333119999999987]\n",
    "47900/99489 batches | batch/sec  1.67 | rem mins   514 | loss 3.00461 | ppl  20.1783\n",
    "Learning rate: [0.0001004512000000002]\n",
    "48000/99489 batches | batch/sec  1.67 | rem mins   514 | loss 3.01098 | ppl  20.3073\n",
    "Learning rate: [9.757119999999987e-05]\n",
    "48100/99489 batches | batch/sec  1.67 | rem mins   512 | loss 3.00262 | ppl  20.1382\n",
    "Learning rate: [9.46912000000002e-05]\n",
    "48200/99489 batches | batch/sec  1.67 | rem mins   511 | loss 3.03976 | ppl  20.9001\n",
    "Learning rate: [9.181119999999987e-05]\n",
    "48300/99489 batches | batch/sec  1.67 | rem mins   510 | loss 3.01353 | ppl  20.3591\n",
    "Learning rate: [8.893120000000018e-05]\n",
    "48400/99489 batches | batch/sec  1.67 | rem mins   510 | loss 2.99551 | ppl  19.9955\n",
    "Learning rate: [8.605119999999986e-05]\n",
    "48500/99489 batches | batch/sec  1.67 | rem mins   508 | loss 3.00342 | ppl  20.1544\n",
    "Learning rate: [8.317120000000017e-05]\n",
    "48600/99489 batches | batch/sec  1.67 | rem mins   507 | loss 2.99305 | ppl  19.9463\n",
    "Learning rate: [8.029119999999985e-05]\n",
    "48700/99489 batches | batch/sec  1.67 | rem mins   507 | loss 2.98034 | ppl  19.6944\n",
    "Learning rate: [7.741120000000017e-05]\n",
    "48800/99489 batches | batch/sec  1.67 | rem mins   506 | loss 2.99592 | ppl  20.0038\n",
    "Learning rate: [7.453119999999985e-05]\n",
    "48900/99489 batches | batch/sec  1.67 | rem mins   505 | loss 3.00385 | ppl  20.1630\n",
    "Learning rate: [7.165120000000017e-05]\n",
    "49000/99489 batches | batch/sec  1.67 | rem mins   503 | loss 2.99430 | ppl  19.9714\n",
    "Learning rate: [6.877119999999985e-05]\n",
    "49100/99489 batches | batch/sec  1.67 | rem mins   503 | loss 3.01374 | ppl  20.3633\n",
    "Learning rate: [6.589120000000016e-05]\n",
    "49200/99489 batches | batch/sec  1.67 | rem mins   502 | loss 2.99201 | ppl  19.9257\n",
    "Learning rate: [6.301119999999983e-05]\n",
    "49300/99489 batches | batch/sec  1.67 | rem mins   501 | loss 3.00361 | ppl  20.1582\n",
    "Learning rate: [6.0131200000000154e-05]\n",
    "49400/99489 batches | batch/sec  1.67 | rem mins   500 | loss 2.98420 | ppl  19.7706\n",
    "Learning rate: [5.7251199999999836e-05]\n",
    "49500/99489 batches | batch/sec  1.67 | rem mins   498 | loss 2.98923 | ppl  19.8705\n",
    "Learning rate: [5.437120000000015e-05]\n",
    "49600/99489 batches | batch/sec  1.67 | rem mins   498 | loss 3.00641 | ppl  20.2147\n",
    "Learning rate: [5.149119999999982e-05]\n",
    "49700/99489 batches | batch/sec  1.67 | rem mins   496 | loss 3.01005 | ppl  20.2884\n",
    "Learning rate: [4.861120000000014e-05]\n",
    "50000/99489 batches | batch/sec  1.67 | rem mins   493 | loss 3.00357 | ppl  20.1574\n",
    "Learning rate: [4.002879999999987e-05]\n",
    "50100/99489 batches | batch/sec  1.67 | rem mins   492 | loss 3.01549 | ppl  20.3990\n",
    "Learning rate: [4.2908799999999876e-05]\n",
    "50200/99489 batches | batch/sec  1.67 | rem mins   491 | loss 2.99915 | ppl  20.0684\n",
    "Learning rate: [4.5788799999999876e-05]\n",
    "50300/99489 batches | batch/sec  1.67 | rem mins   491 | loss 3.03219 | ppl  20.7426\n",
    "Learning rate: [4.866879999999988e-05]\n",
    "50400/99489 batches | batch/sec  1.67 | rem mins   490 | loss 3.01144 | ppl  20.3166\n",
    "Learning rate: [5.154879999999988e-05]\n",
    "50500/99489 batches | batch/sec  1.67 | rem mins   489 | loss 3.00632 | ppl  20.2129\n",
    "Learning rate: [5.442879999999989e-05]\n",
    "50600/99489 batches | batch/sec  1.67 | rem mins   487 | loss 3.01502 | ppl  20.3894\n",
    "Learning rate: [5.730879999999989e-05]\n",
    "50700/99489 batches | batch/sec  1.67 | rem mins   486 | loss 3.01122 | ppl  20.3121\n",
    "Learning rate: [6.0188799999999894e-05]\n",
    "50800/99489 batches | batch/sec  1.67 | rem mins   486 | loss 3.01616 | ppl  20.4127\n",
    "Learning rate: [6.30687999999999e-05]\n",
    "50900/99489 batches | batch/sec  1.67 | rem mins   484 | loss 3.00491 | ppl  20.1845\n",
    "Learning rate: [6.594879999999989e-05]\n",
    "51000/99489 batches | batch/sec  1.67 | rem mins   483 | loss 2.98963 | ppl  19.8783\n",
    "Learning rate: [6.882879999999989e-05]\n",
    "51100/99489 batches | batch/sec  1.67 | rem mins   483 | loss 3.00897 | ppl  20.2665\n",
    "Learning rate: [7.17087999999999e-05]\n",
    "51200/99489 batches | batch/sec  1.67 | rem mins   482 | loss 3.00639 | ppl  20.2144\n",
    "Learning rate: [7.45887999999999e-05]\n",
    "51300/99489 batches | batch/sec  1.67 | rem mins   481 | loss 2.99435 | ppl  19.9724\n",
    "Learning rate: [7.74687999999999e-05]\n",
    "51400/99489 batches | batch/sec  1.67 | rem mins   479 | loss 3.00621 | ppl  20.2107\n",
    "Learning rate: [8.034879999999992e-05]\n",
    "51500/99489 batches | batch/sec  1.67 | rem mins   479 | loss 2.99953 | ppl  20.0762\n",
    "Learning rate: [8.322879999999992e-05]\n",
    "51600/99489 batches | batch/sec  1.67 | rem mins   478 | loss 2.99639 | ppl  20.0131\n",
    "Learning rate: [8.610879999999992e-05]\n",
    "51700/99489 batches | batch/sec  1.67 | rem mins   477 | loss 3.00662 | ppl  20.2190\n",
    "Learning rate: [8.898879999999992e-05]\n",
    "51800/99489 batches | batch/sec  1.67 | rem mins   475 | loss 3.00979 | ppl  20.2830\n",
    "Learning rate: [9.186879999999992e-05]\n",
    "51900/99489 batches | batch/sec  1.67 | rem mins   475 | loss 3.01357 | ppl  20.3600\n",
    "Learning rate: [9.474879999999992e-05]\n",
    "52000/99489 batches | batch/sec  1.67 | rem mins   473 | loss 3.01693 | ppl  20.4285\n",
    "Learning rate: [9.762879999999993e-05]\n",
    "52100/99489 batches | batch/sec  1.67 | rem mins   473 | loss 2.98086 | ppl  19.7047\n",
    "Learning rate: [0.00010050879999999993]\n",
    "52200/99489 batches | batch/sec  1.67 | rem mins   472 | loss 3.01030 | ppl  20.2935\n",
    "Learning rate: [0.00010338879999999994]\n",
    "52300/99489 batches | batch/sec  1.67 | rem mins   471 | loss 2.99370 | ppl  19.9593\n",
    "Learning rate: [0.00010626879999999994]\n",
    "52400/99489 batches | batch/sec  1.67 | rem mins   469 | loss 2.98565 | ppl  19.7994\n",
    "Learning rate: [0.00010914879999999994]\n",
    "52500/99489 batches | batch/sec  1.67 | rem mins   468 | loss 2.99246 | ppl  19.9346\n",
    "Learning rate: [0.00011202879999999994]\n",
    "52600/99489 batches | batch/sec  1.67 | rem mins   467 | loss 2.98440 | ppl  19.7746\n",
    "Learning rate: [0.00011490879999999994]\n",
    "52700/99489 batches | batch/sec  1.67 | rem mins   467 | loss 2.99824 | ppl  20.0503\n",
    "Learning rate: [0.00011778879999999994]\n",
    "52800/99489 batches | batch/sec  1.67 | rem mins   466 | loss 3.03378 | ppl  20.7756\n",
    "Learning rate: [0.00012066879999999994]\n",
    "53000/99489 batches | batch/sec  1.67 | rem mins   464 | loss 3.00709 | ppl  20.2285\n",
    "Learning rate: [0.00012642879999999996]\n",
    "53100/99489 batches | batch/sec  1.67 | rem mins   463 | loss 2.99580 | ppl  20.0014\n",
    "Learning rate: [0.00012930879999999996]\n",
    "53200/99489 batches | batch/sec  1.67 | rem mins   462 | loss 2.99692 | ppl  20.0237\n",
    "Learning rate: [0.00013218879999999996]\n",
    "53300/99489 batches | batch/sec  1.67 | rem mins   461 | loss 3.01226 | ppl  20.3332\n",
    "Learning rate: [0.00013506879999999996]\n",
    "53400/99489 batches | batch/sec  1.67 | rem mins   460 | loss 2.99438 | ppl  19.9731\n",
    "Learning rate: [0.00013794879999999996]\n",
    "53500/99489 batches | batch/sec  1.67 | rem mins   458 | loss 3.00358 | ppl  20.1576\n",
    "Learning rate: [0.00014082879999999996]\n",
    "53600/99489 batches | batch/sec  1.67 | rem mins   458 | loss 3.01528 | ppl  20.3948\n",
    "Learning rate: [0.00014370879999999996]\n",
    "53700/99489 batches | batch/sec  1.67 | rem mins   457 | loss 3.00669 | ppl  20.2203\n",
    "Learning rate: [0.00014658879999999996]\n",
    "53800/99489 batches | batch/sec  1.67 | rem mins   456 | loss 2.97889 | ppl  19.6660\n",
    "Learning rate: [0.0001494688]\n",
    "53900/99489 batches | batch/sec  1.67 | rem mins   455 | loss 2.98899 | ppl  19.8656\n",
    "Learning rate: [0.0001523488]\n",
    "54000/99489 batches | batch/sec  1.67 | rem mins   454 | loss 3.00450 | ppl  20.1761\n",
    "Learning rate: [0.0001552288]\n",
    "54100/99489 batches | batch/sec  1.67 | rem mins   453 | loss 3.01449 | ppl  20.3787\n",
    "Learning rate: [0.00015810879999999999]\n",
    "54200/99489 batches | batch/sec  1.67 | rem mins   452 | loss 2.99346 | ppl  19.9545\n",
    "Learning rate: [0.00016098879999999999]\n",
    "54300/99489 batches | batch/sec  1.67 | rem mins   451 | loss 2.98811 | ppl  19.8481\n",
    "Learning rate: [0.00016386879999999999]\n",
    "54400/99489 batches | batch/sec  1.67 | rem mins   450 | loss 3.00499 | ppl  20.1861\n",
    "Learning rate: [0.00016674879999999998]\n",
    "54500/99489 batches | batch/sec  1.67 | rem mins   449 | loss 3.00710 | ppl  20.2286\n",
    "Learning rate: [0.00016962879999999998]\n",
    "54800/99489 batches | batch/sec  1.67 | rem mins   446 | loss 2.99305 | ppl  19.9463\n",
    "Learning rate: [0.0001782688]\n",
    "54900/99489 batches | batch/sec  1.67 | rem mins   444 | loss 2.99696 | ppl  20.0246\n",
    "Learning rate: [0.0001811488]\n",
    "55000/99489 batches | batch/sec  1.67 | rem mins   444 | loss 3.01798 | ppl  20.4499\n",
    "Learning rate: [0.0001840288]\n",
    "55100/99489 batches | batch/sec  1.67 | rem mins   443 | loss 2.99254 | ppl  19.9363\n",
    "Learning rate: [0.0001869088]\n",
    "55200/99489 batches | batch/sec  1.67 | rem mins   442 | loss 3.00583 | ppl  20.2030\n",
    "Learning rate: [0.0001897888]\n",
    "55300/99489 batches | batch/sec  1.67 | rem mins   441 | loss 3.02683 | ppl  20.6317\n",
    "Learning rate: [0.0001926688]\n",
    "55400/99489 batches | batch/sec  1.67 | rem mins   440 | loss 2.99401 | ppl  19.9657\n",
    "Learning rate: [0.0001955488]\n",
    "55500/99489 batches | batch/sec  1.67 | rem mins   439 | loss 3.01723 | ppl  20.4345\n",
    "Learning rate: [0.0001984288]\n",
    "55600/99489 batches | batch/sec  1.67 | rem mins   438 | loss 3.02214 | ppl  20.5353\n",
    "Learning rate: [0.0002013088]\n",
    "55700/99489 batches | batch/sec  1.67 | rem mins   437 | loss 3.01990 | ppl  20.4893\n",
    "Learning rate: [0.00020418880000000003]\n",
    "55800/99489 batches | batch/sec  1.67 | rem mins   436 | loss 2.99990 | ppl  20.0835\n",
    "Learning rate: [0.00020706880000000003]\n",
    "55900/99489 batches | batch/sec  1.67 | rem mins   435 | loss 2.99570 | ppl  19.9994\n",
    "Learning rate: [0.00020994880000000003]\n",
    "56000/99489 batches | batch/sec  1.67 | rem mins   434 | loss 3.03290 | ppl  20.7573\n",
    "Learning rate: [0.00021282880000000003]\n",
    "56100/99489 batches | batch/sec  1.67 | rem mins   432 | loss 3.00581 | ppl  20.2026\n",
    "Learning rate: [0.00021570880000000003]\n",
    "56200/99489 batches | batch/sec  1.67 | rem mins   431 | loss 3.01144 | ppl  20.3166\n",
    "Learning rate: [0.00021858880000000003]\n",
    "56300/99489 batches | batch/sec  1.67 | rem mins   431 | loss 3.00867 | ppl  20.2605\n",
    "Learning rate: [0.00022146880000000003]\n",
    "56600/99489 batches | batch/sec  1.67 | rem mins   428 | loss 2.99318 | ppl  19.9490\n",
    "Learning rate: [0.00023010880000000006]\n",
    "56700/99489 batches | batch/sec  1.67 | rem mins   427 | loss 3.00391 | ppl  20.1642\n",
    "Learning rate: [0.00023298880000000006]\n",
    "56800/99489 batches | batch/sec  1.67 | rem mins   426 | loss 3.02512 | ppl  20.5965\n",
    "Learning rate: [0.00023586880000000005]\n",
    "56900/99489 batches | batch/sec  1.67 | rem mins   425 | loss 3.00823 | ppl  20.2516\n",
    "Learning rate: [0.00023874880000000005]\n",
    "57000/99489 batches | batch/sec  1.67 | rem mins   424 | loss 2.99372 | ppl  19.9597\n",
    "Learning rate: [0.00024162880000000005]\n",
    "57100/99489 batches | batch/sec  1.67 | rem mins   423 | loss 3.01390 | ppl  20.3667\n",
    "Learning rate: [0.00024450880000000005]\n",
    "57200/99489 batches | batch/sec  1.67 | rem mins   422 | loss 3.00005 | ppl  20.0866\n",
    "Learning rate: [0.0002473888000000001]\n",
    "57300/99489 batches | batch/sec  1.67 | rem mins   421 | loss 3.01766 | ppl  20.4433\n",
    "Learning rate: [0.00025026880000000005]\n",
    "57400/99489 batches | batch/sec  1.67 | rem mins   420 | loss 2.99660 | ppl  20.0174\n",
    "Learning rate: [0.0002531488000000001]\n",
    "57500/99489 batches | batch/sec  1.67 | rem mins   419 | loss 2.99501 | ppl  19.9856\n",
    "Learning rate: [0.0002560288000000001]\n",
    "57600/99489 batches | batch/sec  1.67 | rem mins   418 | loss 3.01851 | ppl  20.4609\n",
    "Learning rate: [0.0002589088000000001]\n",
    "57700/99489 batches | batch/sec  1.67 | rem mins   417 | loss 3.01179 | ppl  20.3238\n",
    "Learning rate: [0.0002617888000000001]\n",
    "57800/99489 batches | batch/sec  1.67 | rem mins   416 | loss 2.98976 | ppl  19.8808\n",
    "Learning rate: [0.0002646688000000001]\n",
    "57900/99489 batches | batch/sec  1.67 | rem mins   415 | loss 3.00998 | ppl  20.2870\n",
    "Learning rate: [0.0002675488000000001]\n",
    "58000/99489 batches | batch/sec  1.67 | rem mins   414 | loss 3.03420 | ppl  20.7843\n",
    "Learning rate: [0.0002704288000000001]\n",
    "\"\"\".split('\\n')\n",
    "\n",
    "losses, learning_rates = parse_loss(training_log_lines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stable-disco",
   "language": "python",
   "name": "stable-disco"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
