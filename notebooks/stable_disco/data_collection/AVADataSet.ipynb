{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47a69fad-6dab-4c19-95e9-6057e704d146",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "sys.path.insert(0, os.path.abspath('../..'))\n",
    "\n",
    "import importlib\n",
    "\n",
    "import contextlib\n",
    "\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas_streaming\n",
    "from collections import defaultdict\n",
    "from fileutils import get_default_path\n",
    "\n",
    "\n",
    "from automation.automationmanager import make_default_manager\n",
    "from automation.crawler.midjourneycrawl import crawl_gallery_user, crawl_gallery_feed\n",
    "from automation.midjourney.midjourneyutils import FeedType\n",
    "\n",
    "from storage.data.image.remoteimageinfo import imgs_to_cmds\n",
    "from storage.data.image.crawledimagegroups import CrawledImageGroups\n",
    "from storage.data.command import Command\n",
    "from storage.data.command.commandbuilder import CommandBuilder\n",
    "from storage.data.user.userids import MJ_USER_TO_ID\n",
    "from storage.data.user.mjuser import MJUser\n",
    "import time\n",
    "from util import Stopwatch\n",
    "import datetime\n",
    "\n",
    "import ai.stabledisco as sd\n",
    "import ai.torchmodules as torchmodules\n",
    "import ai.torchmodules.data as torchdata\n",
    "import ai.torchmodules.utils as torchutils\n",
    "import ai.stabledisco.utils as sdutils\n",
    "import clip
import open_clip\n",
    "import ai.nlp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from storage.data.command.stablediscoprompt import arg_prompt_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "743b8e20-3c46-41d3-aaa3-fdae213256fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/ubuntu/datasets/AVA.txt\", 'r') as ava_file:\n",
    "    ava_lines = ava_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a4a1c96-f14b-420a-95fd-3f508d95ae60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "\n",
    "def get_url_for_img(img_id):\n",
    "    return fr'http://www.dpchallenge.com/image.php?IMAGE_ID={img_id}'\n",
    "\n",
    "img_ids = []\n",
    "img_ratings = []\n",
    "for line in ava_lines:\n",
    "    split_lines = line.split()\n",
    "    img_id = split_lines[1]\n",
    "    ratings = [int(x) for x in split_lines[2:12]]\n",
    "    num_ratings = sum(ratings)\n",
    "    if num_ratings < 5:\n",
    "        continue\n",
    "        \n",
    "    avg_rating = sum([(idx+1)*cnt for idx, cnt in enumerate(ratings)])/num_ratings\n",
    "    \n",
    "    img_ids.append(img_id)\n",
    "    img_ratings.append(avg_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd292191-8c13-4e2c-aa86-efc608b0a17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ava_df = pd.DataFrame.from_dict({\"id\": img_ids, \"rating\": img_ratings})\n",
    "ava_df[\"img_features\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08298255-25b5-4819-bba3-1502ef0b135a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ava_df_path = get_default_path(\"ava\", \"ava.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9019b4df-bf5b-4377-a8c0-8355a11adcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ava_df = pd.read_feather(ava_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bbcce50-7191-4143-a76e-71bd6d63eba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ava_df = ava_df.sample(frac=1).reset_index(drop=True)\n",
    "ava_df.to_feather(ava_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "789c37b5-1b2f-4332-9b0b-eea1d1c07a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torchutils.get_default_device()\n",
    "vit14_clip_model, preprocessor = clip.load('ViT-L/14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "925a402c-764d-4e88-a5d2-1a9621882ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ava_df = pd.read_feather(ava_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81d507b2-1810-4f03-9ff7-6cf1be10053e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "import PIL\n",
    "img_to_tensor = T.ToTensor()\n",
    "def imgs_to_tensor(imgs):\n",
    "    if isinstance(imgs, PIL.Image.Image):\n",
    "        return img_to_tensor(imgs).cuda()\n",
    "    return torch.stack(tuple((img_to_tensor(img) for img in imgs))).cuda()\n",
    "preprocess = T.Compose([\n",
    "        T.Resize(vit14_clip_model.visual.input_resolution, interpolation=T.InterpolationMode.BICUBIC),\n",
    "        T.CenterCrop(vit14_clip_model.visual.input_resolution),\n",
    "        T.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da74a7f5-2691-49a4-b728-9a4e6f107422",
   "metadata": {},
   "outputs": [],
   "source": [
    "ava_df[\"img_features\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10292b67-8198-4489-8415-856da2978f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>Attention</h1><p>Page cannot be served due to suspicious activity detected from your address.</p>\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 53>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m row\u001b[38;5;241m.\u001b[39mimg_features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     56\u001b[0m     imgs_paths_to_process\u001b[38;5;241m.\u001b[39mappend((idx, row\u001b[38;5;241m.\u001b[39murl))\n\u001b[0;32m---> 58\u001b[0m display(\u001b[43mget_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(imgs_paths_to_process) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(imgs_paths_to_process) \u001b[38;5;241m%\u001b[39m per_df_write \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36mget_img\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(html)\n\u001b[1;32m     43\u001b[0m imglist \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124mfr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages.dpchallenge.com.*\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, html)\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sdutils\u001b[38;5;241m.\u001b[39mload_img(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimglist[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import contextlib\n",
    "import requests\n",
    "import re\n",
    "\n",
    "def get_path_for_idx(img_id):\n",
    "    base_path = \"/home/ubuntu/datasets/AVA_dataset/images/\"\n",
    "    return os.path.join(base_path, f\"{img_id}.jpg\")\n",
    "\n",
    "def save_features(data_frame, idxes):\n",
    "    if len(idx_paths) == 0:\n",
    "        print(\"No paths\")\n",
    "        return\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        to_process = []\n",
    "        img_to_size = defaultdict(list)\n",
    "        for idx in idxes:\n",
    "            try:\n",
    "                img_path = get_path_for_idx(idx)\n",
    "                img = sdutils.load_img(img_path)\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "            img_to_size[img.size].append((idx, img))\n",
    "\n",
    "        written = 0\n",
    "        for size, lst in img_to_size.items():\n",
    "            idxs = [x[0] for x in lst]\n",
    "            imgs = [x[1] for x in lst]\n",
    "            img_tensors = imgs_to_tensor(imgs)\n",
    "            del imgs\n",
    "            \n",
    "            preprocessed_tensors = preprocess(img_tensors)\n",
    "            del img_tensors\n",
    "            \n",
    "            features = vit14_clip_model.encode_image(preprocessed_tensors).cpu().numpy().tolist()\n",
    "            for idx, feature in zip(idxs, features):\n",
    "                data_frame.at[idx, \"img_features\"] = feature    \n",
    "            del features\n",
    "            \n",
    "            written += len(lst)\n",
    "            \n",
    "        del img_to_size\n",
    "        return written\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "imgs_paths_to_process = []\n",
    "per_df_write = 500\n",
    "start = time.perf_counter()\n",
    "written = 0\n",
    "per_save = 20000\n",
    "\n",
    "for row in ava_df.itertuples():\n",
    "    idx = row[0]\n",
    "    if row.img_features is None:\n",
    "        imgs_paths_to_process.append(idx)\n",
    "        \n",
    "    if len(imgs_paths_to_process) > 0 and len(imgs_paths_to_process) % per_df_write == 0:\n",
    "        print(\"Saving features\")\n",
    "        written += save_features(ava_df, imgs_paths_to_process)\n",
    "        imgs_paths_to_process = []\n",
    "        \n",
    "        if written >= per_save:\n",
    "            print(f\"Writting {written}\")\n",
    "            written = 0\n",
    "            ava_df.to_feather(ava_df_path)\n",
    "        \n",
    "        end = time.perf_counter()\n",
    "        diff = end - start\n",
    "        start = end\n",
    "        \n",
    "        per_entry = diff/per_df_write\n",
    "        rem_rows = len(ava_df[ava_df[\"img_features\"].isna()])\n",
    "        print(f\"Time per entry {per_entry}. Rem time {per_entry*rem_rows/60} minutes for {rem_rows} rows\")\n",
    "        print(f\"Completed rows {len(ava_df) - rem_rows}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stable-disco",
   "language": "python",
   "name": "stable-disco"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
